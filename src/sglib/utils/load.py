import h5py
import pandas as pd

from .directories import example_data_dir, data_dir
from .ensemble_manager import Ensemble


# Load example data
def load_example_data():
    """
    Loads example data from the package.

    Returns:
        pd.DataFrame: Example data.
    """
    data = pd.read_csv(f'{example_data_dir}/usgs_daily_streamflow_cms.csv', 
                       index_col=0, parse_dates=True)
    return data



class HDF5Manager:
    """
    Class for saving and loading synthetic time series data to/from HDF5 files.
    Handles both numpy array format and dictionary of DataFrames format.
    """
    def __init__(self):
        return
    
    def export_ensemble_to_hdf5(self,
                                dict, 
                                output_file):
        """
        Export a dictionary of ensemble data to an HDF5 file.
        Data is stored in the dictionary as {realization number (int): pd.DataFrame}.
        
        Args:
            dict (dict): A dictionary of ensemble data.
            output_file (str): Full output file path & name to write HDF5.
            
        Returns:
            None    
        """
        
        dict_keys = list(dict.keys())
        N = len(dict)
        T, M = dict[dict_keys[0]].shape
        column_labels = dict[dict_keys[0]].columns.to_list()
        
        with h5py.File(output_file, 'w') as f:
            for key in dict_keys:
                data = dict[key]
                datetime = data.index.astype(str).tolist() #.strftime('%Y-%m-%d').tolist()
                
                grp = f.create_group(key)
                        
                # Store column labels as an attribute
                grp.attrs['column_labels'] = column_labels

                # Create dataset for dates
                grp.create_dataset('date', data=datetime)
                
                # Create datasets for each array subset from the group
                for j in range(M):
                    dataset = grp.create_dataset(column_labels[j], 
                                                data=data[column_labels[j]].to_list())
        return


    def get_hdf5_realization_numbers(self, 
                                     filename):
        """
        Checks the contents of an hdf5 file, and returns a list 
        of the realization ID numbers contained.
        Realizations have key 'realization_i' in the HDF5.

        Args:
            filename (str): The HDF5 file of interest

        Returns:
            list: Containing realizations ID numbers; realizations have key 'realization_i' in the HDF5.
        """
        realization_numbers = []
        with h5py.File(filename, 'r') as file:
            # Get the keys in the HDF5 file
            keys = list(file.keys())

            # Get the df using a specific node key
            node_data = file[keys[0]]
            column_labels = node_data.attrs['column_labels']
            
            # Iterate over the columns and extract the realization numbers
            for col in column_labels:
                
                # handle different types of column labels
                if type(col) == str:
                    if col.startswith('realization_'):
                        # Extract the realization number from the key
                        realization_numbers.append(int(col.split('_')[1]))
                    else:
                        realization_numbers.append(col)
                elif type(col) == int:
                    realization_numbers.append(col)
                else:
                    err_msg = f'Unexpected type {type(col)} for column label {col}.'
                    err_msg +=  f'in HDF5 file {filename}'
                    raise ValueError(err_msg)
        
        return realization_numbers


    def extract_realization_from_hdf5(self, 
                                      hdf5_file, 
                                      realization, 
                                      stored_by_node=True):
        """
        Pull a single inflow realization from an HDF5 file of inflows.

        Parameters
        ----------
        hdf5_file : str
                Path to the HDF5 file.
        realization : str or int
                The realization number or name to extract.
        stored_by_node : bool, optional
                    If True, assumes that the data keys are node names. If False, keys are realizations. Default is False.
                    
        Returns
        -------
        pd.DataFrame
            A DataFrame containing the extracted realization data, with datetime as the index.
        """

        with h5py.File(hdf5_file, "r") as f:
            if stored_by_node:
                # Extract timeseries data from realization for each node
                data = {}

                # Get keys in the HDF5 file
                keys = list(f.keys())

                for node in keys:
                    node_data = f[node]
                    column_labels = node_data.attrs["column_labels"]

                    err_msg = f"The specified realization {realization} is not available in the HDF file."
                    assert realization in column_labels, (
                        err_msg + f" Realizations available: {column_labels}"
                    )
                    data[node] = node_data[realization][:]

                dates = node_data["date"][:].tolist()

            else:
                realization_group = f[realization]

                # Extract column labels
                column_labels = realization_group.attrs["column_labels"]
                # Extract timeseries data for each location
                data = {}
                for label in column_labels:
                    dataset = realization_group[label]
                    data[label] = dataset[:]

                # Get date indices
                dates = realization_group["date"][:].tolist()
            data["datetime"] = dates

        # Combine into dataframe
        df = pd.DataFrame(data, index=dates)
        df.index = pd.to_datetime(df.index.astype(str))
        return df
    
    def extract_many_realizations_from_hdf5(self, 
                                        hdf5_file, 
                                        realization_list, 
                                        stored_by_node=True):
        """
        Extract multiple realizations from an HDF5 file in a single pass.
        
        Parameters
        ----------
        hdf5_file : str
            Path to the HDF5 file.
        realization_list : list
            List of realization numbers/names to extract.
        stored_by_node : bool, optional
            If True, assumes data keys are node names. Default is True.
            
        Returns
        -------
        dict
            Dictionary mapping realization indices to DataFrames.
        """
        
        with h5py.File(hdf5_file, "r") as f:
            if stored_by_node:
                # Get structure info from first node
                keys = list(f.keys())
                first_node = f[keys[0]]
                column_labels = first_node.attrs["column_labels"]
                dates = first_node["date"][:].tolist()
                
                # Validate all requested realizations exist
                missing_realizations = [r for r in realization_list if r not in column_labels]
                if missing_realizations:
                    raise ValueError(f"Realizations {missing_realizations} not found in HDF5 file")
                
                # Load all data for all realizations at once
                ensemble_dict = {}
                for i, realization in enumerate(realization_list):
                    data = {}
                    # Extract data for this realization across all nodes
                    for node in keys:
                        node_data = f[node]
                        data[node] = node_data[realization][:]
                    
                    # Create DataFrame
                    df = pd.DataFrame(data, index=dates)
                    df.index = pd.to_datetime(df.index.astype(str))
                    df.index.name = 'datetime'
                    ensemble_dict[i] = df
                    
            else:
                # Data stored by realization
                ensemble_dict = {}
                for i, realization in enumerate(realization_list):
                    if str(realization) not in f:
                        raise ValueError(f"Realization {realization} not found in HDF5 file")
                    
                    realization_group = f[str(realization)]
                    column_labels = realization_group.attrs["column_labels"]
                    dates = realization_group["date"][:].tolist()
                    
                    # Load all columns for this realization
                    data = {}
                    for label in column_labels:
                        data[label] = realization_group[label][:]
                    
                    # Create DataFrame
                    df = pd.DataFrame(data, index=dates)
                    df.index = pd.to_datetime(df.index.astype(str))
                    df.index.name = 'datetime'
                    ensemble_dict[i] = df
        
        return ensemble_dict


    def load_ensemble(self, hdf5_file, 
                            realization_subset=None):
        """
        Optimized ensemble loading using batch extraction.
        
        Args:
            hdf5_file (str): The filename for the hdf5 file
            realization_subset (list, optional): If specified, load only these realizations.
        
        Returns:
            Ensemble: An Ensemble object containing the loaded data.
        """
        
        realization_ids = self.get_hdf5_realization_numbers(hdf5_file)
        
        if realization_subset is not None:
            missing = [r for r in realization_subset if r not in realization_ids]
            if missing:
                raise ValueError(f'Realizations {missing} not found in HDF5 file {hdf5_file}')
            realization_ids = realization_subset
        
        print(f'Loading {len(realization_ids)} realizations from {hdf5_file}')
        
        # Load all realizations in single file operation
        ensemble_dict = self.extract_many_realizations_from_hdf5(
            hdf5_file, realization_ids, stored_by_node=True
        )
        
        return Ensemble(ensemble_dict)


    # Alternative: Memory-efficient vectorized approach for large ensembles
    def load_ensemble_vectorized(self, hdf5_file, realization_subset=None):
        """
        Vectorized loading using numpy operations for maximum efficiency.
        Best for large ensembles where memory allows.
        """
        
        realization_ids = self.get_hdf5_realization_numbers(hdf5_file)
        
        if realization_subset is not None:
            missing = [r for r in realization_subset if r not in realization_ids]
            if missing:
                raise ValueError(f'Realizations {missing} not found in HDF5 file {hdf5_file}')
            realization_ids = realization_subset
        
        print(f'Loading {len(realization_ids)} realizations from {hdf5_file}')
        
        with h5py.File(hdf5_file, "r") as f:
            keys = list(f.keys())
            first_node = f[keys[0]]
            column_labels = first_node.attrs["column_labels"]
            dates = first_node["date"][:].tolist()
            
            # Get indices of requested realizations
            realization_indices = [list(column_labels).index(r) for r in realization_ids]
            
            ensemble_dict = {}
            for i, realization_idx in enumerate(realization_indices):
                data = {}
                # Use fancy indexing to load data efficiently
                for node in keys:
                    node_data = f[node]
                    # Load specific realization column
                    data[node] = node_data[column_labels[realization_idx]][:]
                
                df = pd.DataFrame(data, index=pd.to_datetime(dates))
                ensemble_dict[i] = df
        
        return Ensemble(ensemble_dict)