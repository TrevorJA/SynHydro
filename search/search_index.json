{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SynHydro","text":"<p>Synthetic Generation Library \u2014 stochastic streamflow generation for hydrologic analysis.</p> <p> </p> <p>SynHydro provides parametric, nonparametric, and machine-learning stochastic generation methods under a unified API. All generators share the same <code>preprocessing() \u2192 fit() \u2192 generate()</code> workflow.</p>"},{"location":"#generators","title":"Generators","text":"Class Type Frequency Sites Reference <code>KirschGenerator</code> Nonparametric Monthly Multi Kirsch et al. (2013) <code>PhaseRandomizationGenerator</code> Nonparametric Daily Single Brunner et al. (2019) <code>ThomasFieringGenerator</code> Parametric AR(1) Monthly Single Thomas &amp; Fiering (1962) <code>MATALASGenerator</code> Parametric MAR(1) Monthly Multi Matalas (1967) <code>MultiSiteHMMGenerator</code> Hidden Markov Model Annual Multi Gold et al. (2025) <code>WARMGenerator</code> Wavelet AR Annual Single Nowak et al. (2011)"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import synhydro\n\nQ_obs = synhydro.load_example_data()                       # daily DataFrame\nQ_monthly = Q_obs.resample(\"MS\").mean()                 # resample to monthly\n\ngen = synhydro.KirschGenerator(Q_monthly)\ngen.preprocessing()\ngen.fit()\nensemble = gen.generate(n_realizations=50, n_years=30, seed=42)\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install git+https://github.com/TrevorJA/SynHydro.git\n</code></pre> <p>See Getting Started for full setup and data format details.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<p>SynHydro is not yet published on PyPI. Install directly from GitHub:</p> <pre><code>pip install git+https://github.com/TrevorJA/SynHydro.git\n</code></pre> <p>For development (editable install with dev extras):</p> <pre><code>git clone https://github.com/TrevorJA/SynHydro.git\ncd SynHydro\npip install -e \".[dev]\"\n</code></pre>"},{"location":"getting-started/#data-format","title":"Data Format","text":"<p>All generators expect a <code>pd.DataFrame</code> with a <code>DatetimeIndex</code>:</p> Property Requirement Index <code>DatetimeIndex</code> Monthly data <code>freq='MS'</code> (month-start) Daily data <code>freq='D'</code> Columns Site names (one column per gauge) Units cfs, MGD, or cms (consistent) <pre><code>import pandas as pd\n\n# Minimal example: single site, monthly\ndates = pd.date_range(\"1980-01\", periods=480, freq=\"MS\")\nQ_obs = pd.DataFrame({\"site_A\": [...]}, index=dates)\n</code></pre> <p>Use <code>synhydro.load_example_data()</code> to get a ready-to-use daily dataset:</p> <pre><code>import synhydro\n\nQ_daily = synhydro.load_example_data()                 # USGS daily streamflow (cms)\nQ_monthly = Q_daily.resample(\"MS\").mean()           # aggregate to monthly\n</code></pre>"},{"location":"getting-started/#choosing-a-generator","title":"Choosing a Generator","text":"Need Generator Monthly, single-site, parametric <code>ThomasFieringGenerator</code> Monthly, multi-site, parametric <code>MATALASGenerator</code> Monthly, multi-site, nonparametric <code>KirschGenerator</code> Daily, single-site <code>PhaseRandomizationGenerator</code> Annual, single-site <code>WARMGenerator</code> Annual, multi-site, drought-aware <code>MultiSiteHMMGenerator</code> Monthly\u2192Daily disaggregation <code>NowakDisaggregator</code> (or use a Pipeline)"},{"location":"getting-started/#basic-workflow","title":"Basic Workflow","text":"<p>Every generator follows the same three-step pattern:</p> <pre><code>gen = synhydro.ThomasFieringGenerator(Q_obs)\ngen.preprocessing()                                 # validate and prepare data\ngen.fit()                                           # estimate parameters\nensemble = gen.generate(n_realizations=10,          # synthetic flows\n                        n_years=30,\n                        seed=42)\n</code></pre> <p>See the Tutorials for worked examples.</p>"},{"location":"algorithms/","title":"Algorithms","text":"<p>SynHydro implements the following stochastic generation and disaggregation methods.</p>"},{"location":"algorithms/#generation-methods","title":"Generation Methods","text":"Algorithm Class Type Frequency Sites Thomas-Fiering AR(1) <code>ThomasFieringGenerator</code> Parametric Monthly Single Kirsch Bootstrap <code>KirschGenerator</code> Nonparametric Monthly Multi Matalas MAR(1) <code>MATALASGenerator</code> Parametric Monthly Multi Phase Randomization <code>PhaseRandomizationGenerator</code> Nonparametric Daily Single WARM <code>WARMGenerator</code> Parametric Annual Single Multi-Site HMM <code>MultiSiteHMMGenerator</code> Parametric Annual Multi"},{"location":"algorithms/#disaggregation-methods","title":"Disaggregation Methods","text":"Algorithm Class Type Frequency Nowak KNN <code>NowakDisaggregator</code> Nonparametric Monthly\u2192Daily"},{"location":"algorithms/#key-properties-preserved","title":"Key Properties Preserved","text":"Property Thomas-Fiering Kirsch Matalas Phase Random WARM HMM Monthly means/stds \u2713 \u2713 \u2713 \u2014 \u2014 \u2014 Temporal correlation \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 Spatial correlation \u2014 \u2713 \u2713 \u2014 \u2014 \u2713 Non-stationarity \u2014 \u2014 \u2014 \u2014 \u2713 \u2014 Drought states \u2014 \u2014 \u2014 \u2014 \u2014 \u2713 Power spectrum \u2014 \u2014 \u2014 \u2713 \u2713 \u2014"},{"location":"algorithms/ALGO_TEMPLATE/","title":"[Algorithm Name]","text":"<p>Classification: [Parametric/Nonparametric/Machine Learning] Temporal Resolution: [Daily/Monthly/Annual] Site Compatibility: [Univariate/Multisite]</p>"},{"location":"algorithms/ALGO_TEMPLATE/#technical-specifications","title":"Technical Specifications","text":"Property Specification Input data [e.g., \"Daily streamflow, minimum 2 years\", \"Monthly flows, complete water years\"] Output frequency [D/MS/AS] Distributional assumption [e.g., \"Normal after transformation\", \"Nonparametric\", \"Kappa\"] Correlation structure [e.g., \"Lag-1 AR\", \"Full spectrum\", \"Spatial + temporal\"]"},{"location":"algorithms/ALGO_TEMPLATE/#algorithm-description","title":"Algorithm Description","text":""},{"location":"algorithms/ALGO_TEMPLATE/#preprocessing","title":"Preprocessing","text":"<ol> <li>[Step name]</li> <li>[Technical description]</li> <li> <p>[Mathematical formulation if applicable]</p> </li> <li> <p>[Step name]</p> </li> <li>[Technical description]</li> </ol>"},{"location":"algorithms/ALGO_TEMPLATE/#fittingcalibration","title":"Fitting/Calibration","text":"<ol> <li>[Step name]</li> <li>[Technical description]</li> <li> <p>Mathematical form: [equation or description]</p> </li> <li> <p>[Step name]</p> </li> <li>[Technical description]</li> </ol>"},{"location":"algorithms/ALGO_TEMPLATE/#generation","title":"Generation","text":"<ol> <li>[Step name]</li> <li> <p>[Technical description]</p> </li> <li> <p>[Step name]</p> </li> <li> <p>[Technical description]</p> </li> <li> <p>[Step name]</p> </li> <li>[Technical description]</li> </ol>"},{"location":"algorithms/ALGO_TEMPLATE/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>parameter_name</code>: [Description and role in algorithm]</li> <li>Type: [dtype]</li> <li>Default: [value]</li> <li>Notes: [when/how to adjust]</li> </ul>"},{"location":"algorithms/ALGO_TEMPLATE/#algorithmic-details","title":"Algorithmic Details","text":""},{"location":"algorithms/ALGO_TEMPLATE/#specific-techniquetransformation-name","title":"[Specific technique/transformation name]","text":"<p>[Detailed technical explanation of key algorithmic component]</p> <p>Mathematical formulation: <pre><code>[equation or pseudocode]\n</code></pre></p>"},{"location":"algorithms/ALGO_TEMPLATE/#another-key-component","title":"[Another key component]","text":"<p>[Technical details]</p>"},{"location":"algorithms/ALGO_TEMPLATE/#algorithm-variations","title":"Algorithm Variations","text":"<ul> <li>[Variant 1]: [What differs technically]</li> <li>[Variant 2]: [What differs technically]</li> </ul>"},{"location":"algorithms/ALGO_TEMPLATE/#implementation-notes","title":"Implementation Notes","text":""},{"location":"algorithms/ALGO_TEMPLATE/#computational-complexity","title":"Computational complexity","text":"<ul> <li>[Time and space complexity or qualitative description]</li> </ul>"},{"location":"algorithms/ALGO_TEMPLATE/#limitations","title":"Limitations","text":"<ul> <li>[Technical limitations]</li> <li>[Edge cases or failure modes]</li> </ul>"},{"location":"algorithms/ALGO_TEMPLATE/#special-handling","title":"Special handling","text":"<ul> <li>[Negative values, missing data, boundary conditions, etc.]</li> </ul>"},{"location":"algorithms/ALGO_TEMPLATE/#references","title":"References","text":"<p>Primary: [Full citation of main algorithm paper]</p> <p>Implementation details: [Citations for specific techniques used, e.g., normalization methods]</p> <p>Implementation: [src/synhydro/methods/generation/category/file.py]</p>"},{"location":"algorithms/kirsch/","title":"Kirsch Monthly Bootstrap Generator","text":"<p>Classification: Nonparametric Temporal Resolution: Monthly Site Compatibility: Multisite</p>"},{"location":"algorithms/kirsch/#technical-specifications","title":"Technical Specifications","text":"Property Specification Input data Monthly streamflow, multisite capable, aggregated from any finer resolution Output frequency MS (month start) Distributional assumption Nonparametric (empirical) Correlation structure Spatial (cross-site) and temporal (intra-annual) via Cholesky decomposition"},{"location":"algorithms/kirsch/#algorithm-description","title":"Algorithm Description","text":""},{"location":"algorithms/kirsch/#preprocessing","title":"Preprocessing","text":"<ol> <li>Data aggregation to monthly resolution</li> <li>Group input data by (year, month) and sum</li> <li>Create MultiIndex DataFrame with levels: ['year', 'month']</li> <li> <p>Store as <code>Qm</code> with shape (n_years \u00d7 12, n_sites)</p> </li> <li> <p>Optional log-transformation</p> </li> <li>If <code>generate_using_log_flow=True</code>: Apply <code>log(Qm)</code> with clipping at 1e-6 to prevent log(0)</li> <li>This improves handling of skewed distributions and prevents bias in back-transformation</li> </ol>"},{"location":"algorithms/kirsch/#fittingcalibration","title":"Fitting/Calibration","text":"<ol> <li>Compute monthly statistics</li> <li> <p>For each month m \u2208 {1, 2, ..., 12} and site s:</p> <ul> <li><code>mean_month[m, s]</code> = mean of all month-m values across years</li> <li><code>std_month[m, s]</code> = standard deviation of all month-m values</li> </ul> </li> <li> <p>Create standardized residuals</p> </li> <li>For each year y, month m, site s:      <pre><code>Z_h[y, m, s] = (Qm[y, m, s] - mean_month[m, s]) / std_month[m, s]\n</code></pre></li> <li> <p>Shape: (n_years, 12, n_sites)</p> </li> <li> <p>Apply normal score transform (conditional on log-flow option)</p> </li> <li>If <code>generate_using_log_flow=True</code>:<ul> <li>For each month m and site s:</li> <li>Sort <code>Z_h[:, m, s]</code> to get empirical CDF</li> <li>Compute plotting positions: <code>pp = (rank - 0.5) / n_years</code> (Hazen formula)</li> <li>Map to normal quantiles: <code>nscores = \u03a6\u207b\u00b9(pp)</code></li> <li>Store sorted values and normal scores for inverse mapping</li> <li>Create <code>Y</code> by interpolating <code>Z_h</code> onto normal scores</li> </ul> </li> <li>Else: <code>Y = Z_h</code></li> <li> <p>Purpose: Prevents bias from interaction between non-Gaussian residuals and exp() back-transform</p> </li> <li> <p>Create cross-year shifted matrix Y_prime</p> </li> <li>Preserves correlations between late months of year y and early months of year y+1</li> <li> <p>Construction (shape: n_years-1 \u00d7 12 \u00d7 n_sites):      <pre><code>Y_prime[:, 0:6, :] = Y[:-1, 6:12, :]   # Jul-Dec of year i \u2192 Jan-Jun position\nY_prime[:, 6:12, :] = Y[1:, 0:6, :]     # Jan-Jun of year i+1 \u2192 Jul-Dec position\n</code></pre></p> </li> <li> <p>Compute correlation matrices and Cholesky decomposition (per site)</p> </li> <li>For each site s:<ul> <li>Compute 12\u00d712 correlation matrix from <code>Y[:, :, s]</code> (shape: n_years \u00d7 12)</li> <li><code>corr_s = np.corrcoef(Y[:, :, s].T)</code></li> <li>Compute 12\u00d712 correlation matrix from <code>Y_prime[:, :, s]</code></li> <li><code>corr_prime_s = np.corrcoef(Y_prime[:, :, s].T)</code></li> <li>Apply matrix repair if not positive semi-definite (spectral method by default)</li> <li>Compute Cholesky: <code>U_site[s] = cholesky(corr_s).T</code></li> <li>Compute Cholesky: <code>U_prime_site[s] = cholesky(corr_prime_s).T</code></li> </ul> </li> </ol>"},{"location":"algorithms/kirsch/#generation","title":"Generation","text":"<ol> <li>Bootstrap sampling of indices</li> <li>Generate random year indices <code>M</code> with shape (n_years+1, 12)</li> <li>Each <code>M[i, m]</code> is a random integer in [0, n_historic_years)</li> <li> <p>Generate separate indices <code>M_prime</code> for Y_prime (max index = n_historic_years - 1)</p> </li> <li> <p>Create bootstrap tensors</p> </li> <li>For standard tensor:      <pre><code>X[i, m, s] = Y[M[i, m], m, s]\n</code></pre></li> <li> <p>For shifted tensor:      <pre><code>X_prime[i, m, s] = Y_prime[M_prime[i, m], m, s]\n</code></pre></p> </li> <li> <p>Apply Cholesky mixing (per site)</p> </li> <li>For each site s:      <pre><code>Z[:, :, s] = X[:, :, s] @ U_site[s]\nZ_prime[:, :, s] = X_prime[:, :, s] @ U_prime_site[s]\n</code></pre></li> <li> <p>This imposes the fitted correlation structure on the bootstrap samples</p> </li> <li> <p>Combine Z and Z_prime to preserve intra-year correlations</p> </li> <li>For years 0 to n_years-1:      <pre><code>ZC[i, 0:6, :] = Z_prime[i, 6:12, :]    # Late months from shifted\nZC[i, 6:12, :] = Z[i+1, 6:12, :]       # Late months from regular\n</code></pre></li> <li> <p>This ensures the second half of each synthetic year has proper correlation with the first half</p> </li> <li> <p>Inverse normal score transform (conditional)</p> </li> <li> <p>If log-flow option was used:</p> <ul> <li>For each month m, site s:</li> <li>Use stored sorted values and normal scores</li> <li>Linear extrapolation at tails for out-of-sample values</li> <li>Map <code>ZC[:, m, s]</code> back to original standardized space</li> </ul> </li> <li> <p>Destandardize</p> </li> <li> <p>For each month m:      <pre><code>Q_syn[:, m, :] = ZC[:, m, :] * std_month[m, :] + mean_month[m, :]\n</code></pre></p> </li> <li> <p>Back-transform from log space (conditional)</p> </li> <li> <p>If log-flow: <code>Q_syn = exp(Q_syn)</code></p> </li> <li> <p>Reshape and return</p> </li> <li>Flatten to (n_years \u00d7 12, n_sites) with DatetimeIndex</li> </ol>"},{"location":"algorithms/kirsch/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>generate_using_log_flow</code>: Apply log transformation before processing</li> <li>Type: bool</li> <li>Default: <code>True</code></li> <li> <p>Notes: Improves handling of skewed distributions; prevents bias when using normal score transform with exp() back-transform. Set to <code>False</code> for symmetric or normally-distributed flows.</p> </li> <li> <p><code>matrix_repair_method</code>: Method for repairing non-positive-definite correlation matrices</p> </li> <li>Type: str</li> <li>Default: <code>'spectral'</code></li> <li>Options: <code>'spectral'</code> (eigenvalue adjustment)</li> <li>Notes: Required when sample correlations yield non-PSD matrices; may cause correlation inflation</li> </ul>"},{"location":"algorithms/kirsch/#algorithmic-details","title":"Algorithmic Details","text":""},{"location":"algorithms/kirsch/#normal-score-transform-nst","title":"Normal Score Transform (NST)","text":"<p>Applied when generating in log-space to prevent bias. Without NST, standardized residuals that are non-Gaussian would interact poorly with the exp() back-transformation, creating systematic bias.</p> <p>Forward transform (during fitting): <pre><code>For each month m, site s:\n  1. Sort Z_h[:, m, s] to get sorted_vals\n  2. Compute plotting positions: pp[k] = (k - 0.5) / n_years\n  3. Map to normal quantiles: nscores[k] = \u03a6\u207b\u00b9(pp[k])\n  4. Store {sorted_vals, nscores} for month-site pair\n  5. Y[:, m, s] = interp(Z_h[:, m, s], sorted_vals, nscores)\n</code></pre></p> <p>Inverse transform (during generation): <pre><code>For each month m, site s:\n  1. Retrieve {sorted_vals, nscores} for month-site pair\n  2. Extend with linear extrapolation at tails:\n     - Lower tail slope: (sorted[1] - sorted[0]) / (nscore[1] - nscore[0])\n     - Upper tail slope: (sorted[-1] - sorted[-2]) / (nscore[-1] - nscore[-2])\n  3. ZC_orig[:, m, s] = interp(ZC[:, m, s], extended_nscores, extended_sorted)\n</code></pre></p>"},{"location":"algorithms/kirsch/#cross-year-correlation-preservation","title":"Cross-Year Correlation Preservation","text":"<p>The Y_prime tensor enables preservation of correlations between successive years (e.g., December to January).</p> <p>Construction logic: - Y contains standardized flows in calendar order - Y_prime contains the same data but with 6-month phase shift - When Y and Y_prime are sampled independently and combined, the result has proper within-year correlation without artificially coupling all 12 months to the same historic year</p> <p>Combination in generation: - First 6 months of synthetic year i: Use months 7-12 from Y_prime sample i - Last 6 months of synthetic year i: Use months 7-12 from Y sample i+1 - This creates a \"seam\" at mid-year where cross-year correlation is preserved</p>"},{"location":"algorithms/kirsch/#matrix-repair-for-non-psd-correlation-matrices","title":"Matrix Repair for Non-PSD Correlation Matrices","text":"<p>Sample correlation matrices may not be positive semi-definite, especially with limited data.</p> <p>Spectral method: 1. Eigendecomposition: <code>corr = Q \u039b Q^T</code> 2. Clip negative eigenvalues: <code>\u039b_fixed = max(\u039b, \u03b5)</code> where \u03b5 is small positive value 3. Reconstruct: <code>corr_repaired = Q \u039b_fixed Q^T</code> 4. Rescale to unit diagonal: <code>corr_repaired[i,i] = 1</code></p>"},{"location":"algorithms/kirsch/#algorithm-variations","title":"Algorithm Variations","text":"<ul> <li>Standard (log-space with NST): <code>generate_using_log_flow=True</code> - Recommended for typical skewed streamflow data</li> <li>Linear-space: <code>generate_using_log_flow=False</code> - Appropriate for symmetric distributions or when log-transform is inappropriate</li> </ul>"},{"location":"algorithms/kirsch/#implementation-notes","title":"Implementation Notes","text":""},{"location":"algorithms/kirsch/#computational-complexity","title":"Computational complexity","text":"<ul> <li>Fitting: O(n_sites \u00d7 n_years \u00d7 12\u00b2) for correlation computation and Cholesky decomposition</li> <li>Generation: O(n_sites \u00d7 n_synthetic \u00d7 12\u00b2) for Cholesky mixing per realization</li> </ul>"},{"location":"algorithms/kirsch/#limitations","title":"Limitations","text":"<ul> <li>Requires complete years (all 12 months present for each year)</li> <li>Cannot handle missing months within a year</li> <li>Y_prime construction loses one year of data (n_years - 1 available for Y_prime)</li> <li>Bootstrap resampling cannot generate values outside observed range (except via extrapolation in NST)</li> </ul>"},{"location":"algorithms/kirsch/#special-handling","title":"Special handling","text":"<ul> <li>Negative values after generation: Clipped to minimum observed value per month</li> <li>Non-PSD matrices: Automatic repair with user warning about potential correlation inflation</li> <li>Index bounds: M_prime indices limited to Y_prime.shape[0] to prevent out-of-bounds access</li> </ul>"},{"location":"algorithms/kirsch/#references","title":"References","text":"<p>Primary: Kirsch, B.R., Characklis, G.W., and Zeff, H.B. (2013). Evaluating the impact of alternative hydro-climate scenarios on transfer agreements: A practical improvement for generating synthetic streamflows. Journal of Water Resources Planning and Management, 139(4), 396-406.</p> <p>Implementation details: - Normal score transform: Prevents bias in log-normal generation - Matrix repair: Uses spectral method from <code>synhydro.core.statistics.repair_correlation_matrix</code> - Monthly statistics: Computed via <code>synhydro.core.statistics.compute_monthly_statistics</code></p> <p>SynHydro Implementation: <code>src/synhydro/methods/generation/nonparametric/kirsch.py</code></p>"},{"location":"algorithms/matalas/","title":"Matalas (1967) Multi-Site MAR(1)","text":""},{"location":"algorithms/matalas/#technical-specifications","title":"Technical Specifications","text":"Property Value Class <code>MATALASGenerator</code> Type Parametric, Stochastic Frequency Monthly Sites Multi-site Reference Matalas (1967)"},{"location":"algorithms/matalas/#overview","title":"Overview","text":"<p>The Matalas MAR(1) model is the classical parametric baseline for multi-site stochastic streamflow generation. It extends the univariate Thomas-Fiering model to \\(n\\) sites by fitting a matrix autoregressive model to the standardized monthly flows. A separate pair of coefficient matrices is estimated for each of the 12 calendar-month transitions.</p>"},{"location":"algorithms/matalas/#algorithm-description","title":"Algorithm Description","text":""},{"location":"algorithms/matalas/#preprocessing","title":"Preprocessing","text":"<ol> <li>Validate input; resample to monthly if daily data are provided.</li> <li>Clip values to \\(10^{-6}\\) (avoid log of zero).</li> <li>Optionally apply \\(\\log(Q + 1)\\) transformation to reduce skewness.</li> </ol>"},{"location":"algorithms/matalas/#fitting","title":"Fitting","text":"<p>Standardize observed flows by monthly means \\(\\mu_m\\) and standard deviations \\(\\sigma_m\\):</p> \\[Z(t) = \\frac{Q(t) - \\mu_m}{\\sigma_m}, \\quad m = \\text{month}(t)\\] <p>Estimate cross-correlation matrices for each monthly transition \\(m \\to m+1\\):</p> \\[S_0(m) = \\frac{1}{n-1} \\mathbf{Z}(m)^T \\mathbf{Z}(m)\\] \\[S_1(m) = \\frac{1}{n-1} \\mathbf{Z}(m+1)^T \\mathbf{Z}(m)\\] <p>where rows of \\(\\mathbf{Z}(m)\\) are the standardized flow vectors across all sites for month \\(m\\) across all observed years.</p> <p>Solve for coefficient matrices:</p> \\[A(m) = S_1(m) \\cdot S_0(m)^{-1}\\] \\[M(m) = S_0(m+1) - A(m) \\cdot S_0(m) \\cdot A(m)^T\\] \\[B(m) = \\text{chol}\\!\\left(M(m)\\right) \\quad \\text{(lower Cholesky factor)}\\] <p>Numerical stability</p> <p>If \\(M(m)\\) is not positive semi-definite (due to finite-sample noise), it is first projected to the nearest PSD matrix via eigenvalue clipping before Cholesky decomposition.</p> <p>The December\u2192January transition wraps across the year boundary: \\(Z\\)(Dec, year \\(y\\)) is paired with \\(Z\\)(Jan, year \\(y+1\\)).</p>"},{"location":"algorithms/matalas/#generation","title":"Generation","text":"<p>Initialize \\(Z_0 \\sim \\mathcal{N}(\\mathbf{0}, I)\\), then recurse:</p> \\[Z(t+1) = A(m) \\cdot Z(t) + B(m) \\cdot \\varepsilon(t+1), \\quad \\varepsilon \\sim \\mathcal{N}(\\mathbf{0}, I)\\] <p>Back-transform to flow space:</p> \\[Q(t) = \\sigma_m \\cdot Z(t) + \\mu_m\\] <p>If <code>log_transform=True</code>, apply \\(Q \\leftarrow e^Q - 1\\).</p>"},{"location":"algorithms/matalas/#key-parameters","title":"Key Parameters","text":"Parameter Default Description <code>log_transform</code> <code>True</code> Apply \\(\\log(Q+1)\\) before standardization"},{"location":"algorithms/matalas/#properties-preserved","title":"Properties Preserved","text":"<ul> <li>Monthly means and standard deviations at each site</li> <li>Lag-1 serial correlation at each site</li> <li>Contemporaneous cross-site correlations</li> </ul>"},{"location":"algorithms/matalas/#references","title":"References","text":"<p>Matalas, N. C. (1967). Mathematical assessment of synthetic hydrology. Water Resources Research, 3(4), 937\u2013945.</p> <p>Salas, J. D., Delleur, J. W., Yevjevich, V., &amp; Lane, W. L. (1980). Applied Modeling of Hydrologic Time Series. Water Resources Publications.</p> <p>SynHydro Implementation: <code>src/synhydro/methods/generation/parametric/matalas.py</code></p>"},{"location":"algorithms/multisite_hmm/","title":"Multi-Site Hidden Markov Model (Gold et al. 2025)","text":"<p>Classification: Parametric Temporal Resolution: Annual Site Compatibility: Multisite</p>"},{"location":"algorithms/multisite_hmm/#technical-specifications","title":"Technical Specifications","text":"Property Specification Input data Annual streamflow for multiple sites, minimum 2 years recommended Output frequency AS (Annual Start) or user-specified annual frequency Distributional assumption Multivariate Gaussian emissions per hidden state (after log transformation) Correlation structure Full covariance matrices per state (preserves spatial correlations) + temporal structure via state transitions Temporal dependence Markov chain (first-order) with hidden states representing hydrologic regimes"},{"location":"algorithms/multisite_hmm/#algorithm-description","title":"Algorithm Description","text":"<p>The Multi-Site Hidden Markov Model (HMM) generator uses a Gaussian Mixture Model HMM to generate synthetic streamflow across multiple sites simultaneously. The method models temporal dependencies through hidden states (e.g., dry/wet regimes) and spatial correlations through state-specific multivariate Gaussian emissions with full covariance matrices.</p> <p>This approach is particularly effective for capturing drought dynamics and spatially compounding water scarcity across multiple basins, as demonstrated in Gold et al. (2025) for Colorado's West Slope river basins.</p>"},{"location":"algorithms/multisite_hmm/#preprocessing","title":"Preprocessing","text":"<ol> <li>Data validation</li> <li>Validate input as pandas DataFrame with multiple sites (columns)</li> <li>Check for minimum sample size (recommended: 10+ years)</li> <li> <p>Allow site subset selection</p> </li> <li> <p>Offset application</p> </li> <li>Add small offset to handle zero flows: <code>Q_adj = Q + offset</code></li> <li>Default offset: 1.0 (in flow units)</li> <li> <p>Prevents log(0) issues</p> </li> <li> <p>Log transformation</p> </li> <li>Apply natural logarithm: <code>Q_log = log(Q_adj)</code></li> <li>Transform to log-space for Gaussian modeling</li> <li>Store transformed data for fitting</li> </ol>"},{"location":"algorithms/multisite_hmm/#fittingcalibration","title":"Fitting/Calibration","text":"<ol> <li>GMMHMM initialization</li> <li>Use <code>hmmlearn.hmm.GMMHMM</code> with:<ul> <li><code>n_components = n_states</code> (default: 2 for dry/wet)</li> <li><code>covariance_type = 'full'</code> (default, captures all spatial correlations)</li> <li>Alternative: 'diag' (site-independent) or 'spherical' (single variance)</li> </ul> </li> <li> <p>Set maximum iterations for Expectation-Maximization convergence</p> </li> <li> <p>Model fitting</p> </li> <li>Fit GMMHMM to log-transformed flows: <code>model.fit(Q_log)</code></li> <li>Estimate via Baum-Welch algorithm (EM):<ul> <li>E-step: Compute state posteriors given parameters</li> <li>M-step: Update parameters given state posteriors</li> </ul> </li> <li> <p>Iterate until convergence or max iterations</p> </li> <li> <p>Parameter extraction</p> </li> <li>Extract state means: \u03bc\u209b \u2208 \u211d\u207f\u02e2\u2071\u1d57\u1d49\u02e2 for each state s</li> <li>Extract covariance matrices: \u03a3\u209b \u2208 \u211d\u207f\u02e2\u2071\u1d57\u1d49\u02e2 \u02e3 \u207f\u02e2\u2071\u1d57\u1d49\u02e2 for each state s</li> <li> <p>Extract transition matrix: P \u2208 \u211d\u207f\u02e2\u1d57\u1d43\u1d57\u1d49\u02e2 \u02e3 \u207f\u02e2\u1d57\u1d43\u1d57\u1d49\u02e2</p> </li> <li> <p>State ordering</p> </li> <li>Order states by mean of first site (ascending)</li> <li>State 0 = driest, State (n_states-1) = wettest</li> <li> <p>Ensures consistent state interpretation</p> </li> <li> <p>Stationary distribution computation</p> </li> <li>Solve for stationary distribution \u03c0:<ul> <li>\u03c0 is left eigenvector of P with eigenvalue 1</li> <li>\u03c0 \u00b7 P = \u03c0</li> <li>\u03a3\u03c0\u1d62 = 1</li> </ul> </li> <li>Used for initial state sampling in generation</li> </ol>"},{"location":"algorithms/multisite_hmm/#generation","title":"Generation","text":"<ol> <li>State trajectory generation</li> <li>Sample initial state from stationary distribution:      <pre><code>s\u2080 ~ Categorical(\u03c0)\n</code></pre></li> <li>For each subsequent timestep t = 1, ..., T:      <pre><code>s\u209c ~ Categorical(P[s\u209c\u208b\u2081, :])\n</code></pre></li> <li> <p>Creates temporally coherent state sequence</p> </li> <li> <p>Emission sampling</p> </li> <li>For each timestep t with state s\u209c:      <pre><code>Q_log[t, :] ~ MultivariateNormal(\u03bc_s\u209c, \u03a3_s\u209c)\n</code></pre></li> <li> <p>Samples preserve spatial correlations (via \u03a3\u209b)</p> </li> <li> <p>Back-transformation</p> </li> <li>Inverse log transform:      <pre><code>Q_syn = exp(Q_log) - offset\n</code></pre></li> <li> <p>Ensures positive flows</p> </li> <li> <p>Non-negativity enforcement</p> </li> <li>Apply floor: <code>Q_syn = max(Q_syn, 0)</code></li> <li> <p>Handles rare numerical issues from back-transformation</p> </li> <li> <p>Time index creation</p> </li> <li>Generate dates starting from observed data start</li> <li>Use inferred frequency (typically 'AS' or 'YS')</li> <li>Return as pandas DataFrame with proper DatetimeIndex</li> </ol>"},{"location":"algorithms/multisite_hmm/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>n_states</code>: Number of hidden states</li> <li>Type: int</li> <li>Default: 2</li> <li> <p>Notes: 2 states (dry/wet) is typical; 3+ states can model intermediate regimes. More states require more data for reliable estimation.</p> </li> <li> <p><code>offset</code>: Value added before log transformation</p> </li> <li>Type: float</li> <li>Default: 1.0</li> <li> <p>Notes: Should be small relative to typical flows. Too small risks numerical issues with zeros; too large biases the distribution.</p> </li> <li> <p><code>max_iterations</code>: Maximum EM iterations for fitting</p> </li> <li>Type: int</li> <li>Default: 1000</li> <li> <p>Notes: Increase if convergence warnings occur. Typical convergence: 50-200 iterations.</p> </li> <li> <p><code>covariance_type</code>: Structure of state covariance matrices</p> </li> <li>Type: str</li> <li>Default: 'full'</li> <li>Options:<ul> <li>'full': Full covariance (all correlations preserved) - recommended</li> <li>'diag': Diagonal (sites independent within states)</li> <li>'spherical': Single variance (spherical clusters)</li> </ul> </li> <li>Notes: 'full' is essential for preserving spatial correlations but requires n_sites\u00b2 parameters per state.</li> </ul>"},{"location":"algorithms/multisite_hmm/#algorithmic-details","title":"Algorithmic Details","text":""},{"location":"algorithms/multisite_hmm/#gaussian-mixture-model-hmm","title":"Gaussian Mixture Model HMM","text":"<p>The GMMHMM combines: - Hidden Markov Model: Temporal structure via state transitions - Gaussian Mixture: Multivariate emissions from each state</p> <p>Joint probability: <pre><code>P(Q, S) = \u03c0(s\u2080) \u00b7 \u220f\u209c P(s\u209c|s\u209c\u208b\u2081) \u00b7 P(Q\u209c|s\u209c)\n</code></pre></p> <p>Where: - S = {s\u2080, s\u2081, ..., s\u209c}: Hidden state sequence - Q = {Q\u2080, Q\u2081, ..., Q\u209c}: Observed flows (log-space) - \u03c0: Stationary distribution - P(s\u209c|s\u209c\u208b\u2081): Transition probabilities - P(Q\u209c|s\u209c) = \ud835\udca9(Q\u209c; \u03bc\u209b\u209c, \u03a3\u209b\u209c): Multivariate normal emissions</p>"},{"location":"algorithms/multisite_hmm/#multivariate-gaussian-emissions","title":"Multivariate Gaussian Emissions","text":"<p>For state s, emissions follow: <pre><code>Q_log ~ \ud835\udca9(\u03bc\u209b, \u03a3\u209b)\n</code></pre></p> <p>Mean vector: \u03bc\u209b \u2208 \u211d\u207f where n = number of sites</p> <p>Covariance matrix (for 'full' type): <pre><code>\u03a3\u209b = [\n  \u03c3\u2081\u2081  \u03c3\u2081\u2082  ...  \u03c3\u2081\u2099\n  \u03c3\u2082\u2081  \u03c3\u2082\u2082  ...  \u03c3\u2082\u2099\n  ...\n  \u03c3\u2099\u2081  \u03c3\u2099\u2082  ...  \u03c3\u2099\u2099\n]\n</code></pre></p> <p>Where \u03c3\u1d62\u2c7c captures correlation between sites i and j in state s.</p> <p>Probability density: <pre><code>p(Q) = (2\u03c0)^(-n/2) |\u03a3\u209b|^(-1/2) exp[-0.5(Q - \u03bc\u209b)\u1d40 \u03a3\u209b\u207b\u00b9 (Q - \u03bc\u209b)]\n</code></pre></p>"},{"location":"algorithms/multisite_hmm/#stationary-distribution-computation","title":"Stationary Distribution Computation","text":"<p>Solve for eigenvector of transition matrix transpose: <pre><code>P\u1d40 \u00b7 \u03c0 = 1 \u00b7 \u03c0\n</code></pre></p> <p>Algorithm: 1. Compute eigendecomposition: <code>P\u1d40 = V \u00b7 \u039b \u00b7 V\u207b\u00b9</code> 2. Find eigenvector v\u1d62 corresponding to \u03bb\u1d62 \u2248 1 3. Normalize: <code>\u03c0 = v\u1d62 / \u03a3v\u1d62</code></p>"},{"location":"algorithms/multisite_hmm/#baum-welch-em-algorithm","title":"Baum-Welch (EM) Algorithm","text":"<p>Expectation (E) step: Compute forward-backward probabilities <pre><code>Forward: \u03b1(s\u209c) = P(Q\u2081:\u209c, s\u209c)\nBackward: \u03b2(s\u209c) = P(Q\u209c\u208a\u2081:\u209c | s\u209c)\nPosterior: \u03b3(s\u209c) = P(s\u209c | Q) = \u03b1(s\u209c)\u03b2(s\u209c) / P(Q)\n</code></pre></p> <p>Maximization (M) step: Update parameters <pre><code>\u03c0\u209b = \u03b3(s\u2080)\nP\u1d62\u2c7c = \u03a3\u209c \u03be(s\u209c=i, s\u209c\u208a\u2081=j) / \u03a3\u209c \u03b3(s\u209c=i)\n\u03bc\u209b = \u03a3\u209c \u03b3(s\u209c=s) Q\u209c / \u03a3\u209c \u03b3(s\u209c=s)\n\u03a3\u209b = \u03a3\u209c \u03b3(s\u209c=s) (Q\u209c - \u03bc\u209b)(Q\u209c - \u03bc\u209b)\u1d40 / \u03a3\u209c \u03b3(s\u209c=s)\n</code></pre></p>"},{"location":"algorithms/multisite_hmm/#algorithm-variations","title":"Algorithm Variations","text":"<ul> <li>Variable number of states: n_states &gt; 2 can model additional regimes (e.g., dry/normal/wet)</li> <li>Diagonal covariance: Faster fitting but ignores spatial correlations</li> <li>Tied covariance: Single \u03a3 shared across states (more parsimonious)</li> <li>Non-parametric emissions: Replace Gaussian with histograms or kernel density estimates</li> <li>Seasonal HMM: Separate models per season or use time-varying transition matrices</li> <li>Continuous-time HMM: Model sub-annual dynamics with continuous-time Markov processes</li> </ul>"},{"location":"algorithms/multisite_hmm/#implementation-notes","title":"Implementation Notes","text":""},{"location":"algorithms/multisite_hmm/#computational-complexity","title":"Computational complexity","text":"<ul> <li>Time complexity: O(n_states\u00b2 \u00b7 n_timesteps \u00b7 n_sites\u00b3) per EM iteration</li> <li>Dominated by covariance matrix operations</li> <li>Typical: 50-200 EM iterations for convergence</li> <li>Space complexity: O(n_states \u00b7 n_sites\u00b2) for covariance storage</li> <li>Scalability:</li> <li>Efficient for typical applications: 2-10 sites, 10-100 years, 2-3 states</li> <li>Full covariance becomes expensive for n_sites &gt; 20</li> <li>Consider diagonal covariance for large n_sites</li> </ul>"},{"location":"algorithms/multisite_hmm/#limitations","title":"Limitations","text":"<ul> <li>Sample size: Requires sufficient data for reliable parameter estimation</li> <li>Minimum: ~10 years</li> <li>Recommended: 20+ years for 2-3 states, 50+ years for more states</li> <li>First-order Markov: Only captures one-timestep memory</li> <li>May miss multi-year persistence (e.g., droughts spanning 3+ years)</li> <li>Consider higher-order HMMs or AR-HMM hybrids for longer memory</li> <li>Stationarity assumption: Assumes transition probabilities are time-invariant</li> <li>Not suitable for data with trends or regime shifts</li> <li>Consider time-varying or non-stationary HMM variants</li> <li>Gaussian assumption: Emissions assumed Gaussian in log-space</li> <li>May not capture extreme tail behavior perfectly</li> <li>Consider mixture models or Student-t emissions for heavy tails</li> <li>Annual timestep: Designed for annual data</li> <li>Can handle monthly/daily but computationally expensive</li> <li>State interpretation may differ at finer resolutions</li> </ul>"},{"location":"algorithms/multisite_hmm/#special-handling","title":"Special handling","text":"<ul> <li>Zeros and negative flows: Offset prevents log(0); negatives from back-transform are floored to 0</li> <li>Covariance matrix: May be non-positive-definite if sample size is small</li> <li>hmmlearn handles regularization internally</li> <li>Increase sample size or reduce n_states if fitting fails</li> <li>State label switching: HMM likelihood is invariant to state label permutation</li> <li>State ordering by mean ensures consistent interpretation</li> <li>Still, different random seeds may converge to different local optima</li> <li>EM convergence: May converge to local optimum</li> <li>Use multiple random initializations and select best by likelihood</li> <li>Check convergence warnings; increase max_iterations if needed</li> <li>Degenerate states: One state may \"absorb\" most observations</li> <li>Indicates n_states too large for data</li> <li>Reduce n_states or increase sample size</li> </ul>"},{"location":"algorithms/multisite_hmm/#hydrologic-properties-preserved","title":"Hydrologic properties preserved","text":"<p>Explicitly preserved: - Spatial correlations (via full covariance matrices \u03a3\u209b) - Temporal persistence (via transition matrix P) - Regime-dependent distributions (dry vs wet states have different \u03bc\u209b, \u03a3\u209b) - Marginal distributions in log-space (Gaussian mixture)</p> <p>Implicitly preserved (approximately): - Drought frequency (via state persistence) - Drought spatial extent (via spatial correlations in dry state) - Flow magnitudes per regime (via state-specific means)</p> <p>Not preserved: - Exact observed autocorrelation at lags &gt; 1 (first-order Markov) - Non-Gaussian marginal distributions (log-transformation imposes log-normality) - Trends or non-stationarity - Sub-annual seasonality (annual timestep)</p>"},{"location":"algorithms/multisite_hmm/#references","title":"References","text":"<p>Primary: Gold, D.F., Reed, P.M., &amp; Gupta, R.S. (In Revision). Exploring the Spatially Compounding Multi-sectoral Drought Vulnerabilities in Colorado's West Slope River Basins. Earth's Future.</p> <p>Methodological foundations: - Hidden Markov Models: Rabiner, L.R. (1989). A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2), 257-286. - Gaussian Mixture Models: Reynolds, D.A., &amp; Rose, R.C. (1995). Robust text-independent speaker identification using Gaussian mixture speaker models. IEEE Transactions on Speech and Audio Processing, 3(1), 72-83. - GMMHMM for hydrology: Akintug, B., &amp; Rasmussen, P.F. (2005). A Markov switching model for annual hydrologic time series. Water Resources Research, 41(9). - Baum-Welch algorithm: Bilmes, J.A. (1998). A gentle tutorial of the EM algorithm and its application to parameter estimation for Gaussian mixture and hidden Markov models. International Computer Science Institute, 4(510), 126.</p> <p>Python implementation: - hmmlearn: https://hmmlearn.readthedocs.io/</p> <p>Original application: - Gold et al. GitHub repository: https://github.com/TrevorJA/Multisite_GMMHMM</p> <p>SynHydro Implementation: <code>src/synhydro/methods/generation/parametric/multisite_hmm.py</code></p> <p>Tests: <code>tests/test_multisite_hmm_generator.py</code></p>"},{"location":"algorithms/multisite_hmm/#usage-example","title":"Usage Example","text":"<pre><code>import pandas as pd\nfrom synhydro.methods.generation.parametric import MultiSiteHMMGenerator\n\n# Load annual streamflow data for multiple sites\nQ_annual = pd.read_csv('annual_flows.csv', index_col=0, parse_dates=True)\n# Expected format: DatetimeIndex with annual frequency, columns = sites\n\n# Initialize generator with 2 states (dry/wet)\ngen = MultiSiteHMMGenerator(\n    Q_annual,\n    n_states=2,              # Dry and wet states\n    offset=1.0,              # Offset for log transform\n    covariance_type='full'   # Preserve spatial correlations\n)\n\n# Preprocess: apply log transformation\ngen.preprocessing()\n\n# Fit: estimate HMM parameters\ngen.fit(random_state=42)\n\n# Examine fitted parameters\nprint(f\"State means (log-space):\\n{gen.means_}\")\nprint(f\"Transition matrix:\\n{gen.transition_matrix_}\")\nprint(f\"Stationary distribution: {gen.stationary_distribution_}\")\n\n# Generate 100 realizations of 50 years each\nensemble = gen.generate(n_realizations=100, n_years=50, seed=42)\n\n# Access results\nprint(f\"Generated {ensemble.metadata.n_realizations} realizations\")\nprint(f\"Each has {len(ensemble.data_by_realization[0])} years\")\n\n# Get first realization\nfirst_real = ensemble.data_by_realization[0]\nprint(first_real.head())\n\n# Get all realizations for a specific site\nsite_data = ensemble.data_by_site['site_1']\nprint(f\"Site 1 data shape: {site_data.shape}\")  # (n_years, n_realizations)\n</code></pre>"},{"location":"algorithms/multisite_hmm/#advanced-usage","title":"Advanced Usage","text":""},{"location":"algorithms/multisite_hmm/#multi-state-model-for-finer-regime-resolution","title":"Multi-state model for finer regime resolution","text":"<pre><code># 3-state model: dry, normal, wet\ngen = MultiSiteHMMGenerator(Q_annual, n_states=3)\ngen.preprocessing()\ngen.fit(random_state=42)\n\n# Interpret states (ordered by mean)\nprint(\"State 0 (Dry):\", gen.means_[0])\nprint(\"State 1 (Normal):\", gen.means_[1])\nprint(\"State 2 (Wet):\", gen.means_[2])\n</code></pre>"},{"location":"algorithms/multisite_hmm/#diagonal-covariance-for-faster-fitting","title":"Diagonal covariance for faster fitting","text":"<pre><code># When spatial correlations are less important\ngen = MultiSiteHMMGenerator(\n    Q_annual,\n    n_states=2,\n    covariance_type='diag'  # Faster, but ignores correlations\n)\ngen.preprocessing()\ngen.fit()\n</code></pre>"},{"location":"algorithms/multisite_hmm/#site-subset-selection","title":"Site subset selection","text":"<pre><code># Generate only for subset of sites\ngen = MultiSiteHMMGenerator(Q_annual)\ngen.preprocessing(sites=['site_A', 'site_B', 'site_C'])\ngen.fit()\nensemble = gen.generate(n_realizations=50, n_years=30)\n</code></pre>"},{"location":"algorithms/multisite_hmm/#verification-checklist","title":"Verification Checklist","text":"<p>When implementing or validating Multi-Site HMM:</p> <ul> <li>[ ] Parameter shapes correct: means (n_states, n_sites), covariances (n_states, n_sites, n_sites)</li> <li>[ ] Transition matrix valid: rows sum to 1, all entries in [0, 1]</li> <li>[ ] Stationary distribution valid: sums to 1, is left eigenvector of P</li> <li>[ ] State ordering: states ordered by mean (dry to wet)</li> <li>[ ] Covariance matrices positive semi-definite: all eigenvalues \u2265 0</li> <li>[ ] Generation reproducible: same seed gives same results</li> <li>[ ] Non-negative flows: no negative values in synthetic output</li> <li>[ ] Spatial correlations preserved: synthetic corr \u2248 observed corr (ensemble average)</li> <li>[ ] Temporal persistence: state autocorrelation matches transition probabilities</li> <li>[ ] Ensemble structure: proper Ensemble object with by-site and by-realization views</li> <li>[ ] Drought characteristics: frequency and spatial extent similar to observed (in dry state)</li> </ul>"},{"location":"algorithms/multisite_hmm/#comparison-to-other-methods","title":"Comparison to Other Methods","text":"Aspect Multi-Site HMM Kirsch-Nowak Phase Randomization Temporal resolution Annual Monthly Daily Spatial Multisite Multisite Univariate Correlation Full spatial + temporal Full spatial + temporal Temporal only (full spectrum) Distributional Log-normal mixture Normal (transformed) Kappa or empirical Regime modeling Explicit (hidden states) Implicit (correlations) None Drought dynamics Excellent (state-based) Good (via correlations) Good (via persistence) Computational Moderate (EM iterations) Fast Fast (FFT) Sample size 20+ years recommended 10+ years 10+ years Extrapolation Yes (beyond observed) Yes (via distributions) Depends on marginal choice"},{"location":"algorithms/nowak_disaggregation/","title":"Nowak (2010) KNN Temporal Disaggregation","text":""},{"location":"algorithms/nowak_disaggregation/#technical-specifications","title":"Technical Specifications","text":"Property Value Class <code>NowakDisaggregator</code> Type Nonparametric Input Frequency Monthly Output Frequency Daily Sites Single or Multi Reference Nowak et al. (2010)"},{"location":"algorithms/nowak_disaggregation/#overview","title":"Overview","text":"<p>The Nowak disaggregator converts synthetic monthly flows to daily flows by borrowing within-month daily patterns from the closest historic analogs. For each synthetic month, it identifies the \\(K\\) nearest historic months (by total flow), randomly selects one, and applies its daily proportions to the synthetic total.</p>"},{"location":"algorithms/nowak_disaggregation/#algorithm-description","title":"Algorithm Description","text":""},{"location":"algorithms/nowak_disaggregation/#preprocessing","title":"Preprocessing","text":"<ol> <li>Validate and store daily observed flows \\(\\{q^*_d\\}\\).</li> <li>Build historic monthly totals \\(Q^*_m = \\sum_{d \\in m} q^*_d\\) at the index gauge    (sum across all sites for multi-site disaggregation).</li> </ol>"},{"location":"algorithms/nowak_disaggregation/#fitting","title":"Fitting","text":"<p>For each calendar month \\(m \\in \\{1, \\ldots, 12\\}\\), fit a <code>sklearn</code> <code>NearestNeighbors</code> model on the scalar historic monthly totals. Only historic months within \\(\\pm\\)<code>max_month_shift</code> calendar days of month \\(m\\)'s center are included in the pool.</p>"},{"location":"algorithms/nowak_disaggregation/#disaggregation","title":"Disaggregation","text":"<p>For each synthetic monthly flow \\(Q_{\\text{syn},m}\\):</p> <ol> <li>Find neighbors. Query the fitted KNN model to retrieve the \\(K\\) nearest historic    months \\(\\{m^*_1, \\ldots, m^*_K\\}\\) by Euclidean distance on total flow:</li> </ol> <p>$\\(d_k = \\left| Q_{\\text{syn},m} - Q^*_{m^*_k} \\right|\\)$</p> <ol> <li>Select one neighbor. Draw index \\(k^*\\) with probability proportional to    \\(1/d_k\\) (Lall-Sharma kernel):</li> </ol> <p>$\\(P(k^*= k) \\propto \\frac{1}{k}\\)$</p> <p>(ranks are used if distances are tied).</p> <ol> <li>Disaggregate. Apply the selected month's daily proportions to the synthetic total:</li> </ol> <p>$\\(q_d = Q_{\\text{syn},m} \\cdot \\frac{q^*_d}{\\displaystyle\\sum_{d' \\in m^*_{k^*}} q^*_{d'}}\\)$</p> <p>For multi-site data, each site is disaggregated independently using the same selected    analog month.</p>"},{"location":"algorithms/nowak_disaggregation/#key-parameters","title":"Key Parameters","text":"Parameter Default Description <code>n_neighbors</code> <code>5</code> \\(K\\) \u2014 number of candidate neighbors <code>max_month_shift</code> <code>7</code> Days of calendar flexibility around each month"},{"location":"algorithms/nowak_disaggregation/#notes","title":"Notes","text":"<ul> <li>Leap year handling: if the synthetic month spans a leap day and the analog month does   not (or vice versa), flow is proportionally adjusted.</li> <li>For multi-site data, the index gauge (sum of all sites) is used for KNN search;   the same analog is then applied to all sites.</li> </ul>"},{"location":"algorithms/nowak_disaggregation/#references","title":"References","text":"<p>Nowak, K., Prairie, J., Rajagopalan, B., &amp; Lall, U. (2010). A nonparametric stochastic approach for multisite disaggregation of annual to daily streamflow. Water Resources Research, 46(8).</p> <p>SynHydro Implementation: <code>src/synhydro/methods/disaggregation/temporal/nowak.py</code></p>"},{"location":"algorithms/phase_randomization/","title":"Phase Randomization (Brunner et al. 2019)","text":"<p>Classification: Nonparametric Temporal Resolution: Daily Site Compatibility: Univariate</p>"},{"location":"algorithms/phase_randomization/#technical-specifications","title":"Technical Specifications","text":"Property Specification Input data Daily streamflow, minimum 730 days (2 years), must be complete (no missing days) Output frequency Daily (D) Distributional assumption Four-parameter kappa distribution (or empirical for no extrapolation) Correlation structure Full power spectrum preserved via Fourier transform Temporal dependence Both short-range (daily autocorrelation) and long-range (Hurst phenomenon)"},{"location":"algorithms/phase_randomization/#algorithm-description","title":"Algorithm Description","text":"<p>Phase randomization (PR) is a nonparametric method that generates synthetic streamflow time series by randomizing the Fourier phase spectrum while preserving the amplitude (power) spectrum. This approach maintains both short- and long-range temporal dependence structures present in observed data.</p>"},{"location":"algorithms/phase_randomization/#preprocessing","title":"Preprocessing","text":"<ol> <li>Leap day removal</li> <li>February 29 observations are removed to ensure consistent 365-day years</li> <li> <p>Facilitates day-of-year indexing and distribution fitting</p> </li> <li> <p>Day-of-year indexing</p> </li> <li>Create index mapping each observation to day-of-year (1-365)</li> <li> <p>Accounts for leap year adjustments in original calendar</p> </li> <li> <p>Data validation</p> </li> <li>Minimum 730 days (2 full years) required</li> <li>Total length must be multiple of 365 after removing leap days</li> <li>No missing observations allowed</li> </ol>"},{"location":"algorithms/phase_randomization/#fittingcalibration","title":"Fitting/Calibration","text":"<ol> <li>Marginal distribution fitting (if <code>marginal='kappa'</code>)</li> <li>For each day d \u2208 {1, ..., 365}:<ul> <li>Define moving window: days within \u00b1<code>win_h_length</code> around day d (circular)</li> <li>Extract all observations for window days across all years</li> <li>Compute L-moments from window data</li> <li>Fit four-parameter kappa distribution using L-moment matching</li> </ul> </li> <li> <p>Parameters: \u03be (location), \u03b1 (scale), k (shape 1), h (shape 2)</p> </li> <li> <p>Normal score transformation</p> </li> <li>For each day d \u2208 {1, ..., 365}:<ul> <li>Rank all observations for day d across years</li> <li>Generate standard normal sample of same size</li> <li>Map ranked observations to ranked normal values</li> </ul> </li> <li> <p>Creates normalized series with standard normal marginals per day</p> </li> <li> <p>Fourier transform</p> </li> <li>Compute FFT of normalized series: <code>FT = FFT(norm)</code></li> <li>Extract modulus (amplitude spectrum): <code>M = |FT|</code></li> <li>Extract phases (argument): <code>\u03c6 = arg(FT)</code></li> <li>Store first half indices (positive frequencies) and mirror indices</li> </ol>"},{"location":"algorithms/phase_randomization/#generation","title":"Generation","text":"<ol> <li>Phase randomization</li> <li>Keep DC component (index 0, mean): <code>FT_new[0] = FT[0]</code></li> <li>For first half (positive frequencies):<ul> <li>Generate random phases from Uniform(-\u03c0, \u03c0)</li> <li>Construct: <code>FT_new[k] = M[k] * exp(i * \u03c6_random[k])</code></li> </ul> </li> <li>For second half (negative frequencies):<ul> <li>Apply conjugate symmetry: <code>FT_new[-k] = conj(FT_new[k])</code></li> </ul> </li> <li> <p>For Nyquist frequency (if n even): keep real-valued</p> </li> <li> <p>Inverse Fourier transform</p> </li> <li>Apply inverse FFT: <code>norm_new = real(IFFT(FT_new))</code></li> <li> <p>Result: phase-randomized series in normalized domain</p> </li> <li> <p>Back-transformation to original distribution</p> </li> <li> <p>For each day d \u2208 {1, ..., 365}:</p> <ul> <li>If kappa marginal:</li> <li>Generate kappa sample using fitted parameters for day d</li> <li>Rank both <code>norm_new</code> values and kappa sample for day d</li> <li>Map normalized ranks to kappa-distributed values via rank matching</li> <li>If empirical marginal:</li> <li>Rank <code>norm_new</code> values for day d</li> <li>Map ranks directly to observed data for day d (no extrapolation)</li> </ul> </li> <li> <p>Negative value handling</p> </li> <li>If any values &lt; 0:<ul> <li>For day d with negative values:</li> <li>Find minimum observed value for day d: <code>min_obs</code></li> <li>Replace negatives with <code>Uniform(0, min_obs)</code> samples</li> </ul> </li> <li>Ensures physical validity (non-negative flows)</li> </ol>"},{"location":"algorithms/phase_randomization/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>marginal</code>: Marginal distribution type for back-transformation</li> <li>Type: str</li> <li>Options: <code>'kappa'</code> (default), <code>'empirical'</code></li> <li> <p>Notes: Kappa allows extrapolation beyond observed range; empirical does not</p> </li> <li> <p><code>win_h_length</code>: Half-window length for daily distribution fitting</p> </li> <li>Type: int</li> <li>Default: 15</li> <li>Total window: <code>2 * win_h_length + 1</code> days (e.g., 31 days for default)</li> <li>Notes: Larger windows smooth seasonal transitions; smaller windows capture sharper variability</li> </ul>"},{"location":"algorithms/phase_randomization/#algorithmic-details","title":"Algorithmic Details","text":""},{"location":"algorithms/phase_randomization/#l-moments-estimation","title":"L-Moments Estimation","text":"<p>L-moments are linear combinations of order statistics used for robust distribution fitting:</p> <pre><code>Given sorted sample x[1] \u2264 x[2] \u2264 ... \u2264 x[n]:\n\nProbability weighted moments:\n  b\u2080 = mean(x)\n  b\u2081 = mean(p\u2081 * x)  where p\u2081 = i/(n-1)\n  b\u2082 = mean(p\u2082 * x)  where p\u2082 = p\u2081 * (i-1)/(n-1)\n  b\u2083 = mean(p\u2083 * x)  where p\u2083 = p\u2082 * (i-2)/(n-1)\n\nL-moments:\n  \u03bb\u2081 = b\u2080                           (L-mean, equals sample mean)\n  \u03bb\u2082 = 2b\u2081 - b\u2080                     (L-scale)\n  \u03c4\u2083 = 2(3b\u2082 - b\u2080)/(2b\u2081 - b\u2080) - 3  (L-skewness)\n  \u03c4\u2084 = 5(2(2b\u2083 - 3b\u2082) + b\u2080)/(2b\u2081 - b\u2080) + 6  (L-kurtosis)\n</code></pre>"},{"location":"algorithms/phase_randomization/#kappa-distribution","title":"Kappa Distribution","text":"<p>Four-parameter kappa distribution CDF: <pre><code>For h \u2260 0:\n  F(x) = {1 - h[1 - k(x-\u03be)/\u03b1]^(1/k)}^(1/h)\n\nFor h = 0 (GEV case):\n  F(x) = exp{-[1 - k(x-\u03be)/\u03b1]^(1/k)}\n</code></pre></p> <p>Inverse CDF (quantile function): <pre><code>For h \u2260 0:\n  x(F) = \u03be + (\u03b1/k)[1 - ((1-F^h)/h)^k]\n\nFor h = 0 (GEV case):\n  x(F) = \u03be + (\u03b1/k)[1 - (-log F)^k]\n</code></pre></p> <p>Parameters fitted by minimizing: <pre><code>minimize (\u03c4\u2083_observed - \u03c4\u2083_theoretical(k,h))\u00b2 + (\u03c4\u2084_observed - \u03c4\u2084_theoretical(k,h))\u00b2\n</code></pre></p>"},{"location":"algorithms/phase_randomization/#fourier-phase-spectrum","title":"Fourier Phase Spectrum","text":"<p>The phase spectrum \u03c6(f) determines the temporal alignment of frequency components. Randomizing phases while preserving amplitudes maintains:</p> <ul> <li>Power spectrum: <code>S(f) = |FT(x)|\u00b2</code> (unchanged)</li> <li>Autocorrelation: R(\u03c4) = IFFT(S(f)) (preserved in expectation)</li> <li>Long-range dependence: Power-law decay in S(f) maintained</li> </ul> <p>Conjugate symmetry ensures real-valued output: <pre><code>FT[-k] = conj(FT[k]) for k = 1, ..., floor(n/2)\n</code></pre></p>"},{"location":"algorithms/phase_randomization/#algorithm-variations","title":"Algorithm Variations","text":"<ul> <li>Wavelet-based PR: Replace Fourier with wavelet transform (better for non-stationary signals)</li> <li>Amplitude-Adjusted PR: Also perturb amplitudes slightly for increased ensemble spread</li> <li>Multivariate PR: Extend to preserve cross-site correlations</li> </ul>"},{"location":"algorithms/phase_randomization/#implementation-notes","title":"Implementation Notes","text":""},{"location":"algorithms/phase_randomization/#computational-complexity","title":"Computational complexity","text":"<ul> <li>Time: O(n log n) dominated by FFT operations</li> <li>Space: O(365 \u00d7 4) for kappa parameters + O(n) for time series storage</li> <li>Efficient for typical hydrologic records (10-100 years of daily data)</li> </ul>"},{"location":"algorithms/phase_randomization/#limitations","title":"Limitations","text":"<ul> <li>Univariate only: Cannot preserve spatial correlations between sites</li> <li>Stationarity assumption: Assumes temporal structure is time-invariant</li> <li>Length constraint: Generated series has same length as observed (no extrapolation in time)</li> <li>Leap day handling: Output excludes Feb 29 dates</li> <li>Data requirements: Minimum 2 years; works best with 10+ years</li> <li>Seasonality: Daily fitting can be noisy with limited data; window smooths but reduces flexibility</li> </ul>"},{"location":"algorithms/phase_randomization/#special-handling","title":"Special handling","text":"<ul> <li>Negative values: Replaced via uniform sampling between 0 and daily minimum</li> <li>Kappa fitting failures: If optimization fails for day d, use parameters from day d-1 (or d+1 if d=1)</li> <li>Nyquist frequency: Forced to be real-valued for even-length series</li> <li>Circular window: Days wrap around year boundaries (e.g., day 1 window includes days 351-365 from previous year)</li> </ul>"},{"location":"algorithms/phase_randomization/#hydrologic-properties-preserved","title":"Hydrologic properties preserved","text":"<p>Explicitly preserved: - Marginal distributions (via kappa or empirical) - Power spectrum (all temporal autocorrelations in expectation) - Long-range dependence (Hurst coefficient) - Seasonal patterns (day-of-year distributions)</p> <p>Implicitly preserved (approximately): - Mean and standard deviation - Skewness and kurtosis (via kappa parameters) - Drought duration distributions (via autocorrelation structure)</p> <p>Not preserved: - Exact observed autocorrelations (only in expectation) - Phase coherence (by design - randomized) - Specific drought event timing</p>"},{"location":"algorithms/phase_randomization/#references","title":"References","text":"<p>Primary: Brunner, M.I., B\u00e1rdossy, A., and Furrer, R. (2019). Technical note: Stochastic simulation of streamflow time series using phase randomization. Hydrology and Earth System Sciences, 23, 3175-3187. https://doi.org/10.5194/hess-23-3175-2019</p> <p>Methodological foundations: - Phase randomization: Theiler, J., Eubank, S., Longtin, A., Galdrikian, B., and Farmer, J. D. (1992). Testing for nonlinearity in time series: the method of surrogate data. Physica D, 58, 77-94. - L-moments: Hosking, J. R. M. (1990). L-moments: Analysis and estimation of distributions using linear combinations of order statistics. Journal of the Royal Statistical Society Series B, 52, 105-124. - Kappa distribution: Hosking, J. R. M. (1994). The four-parameter kappa distribution. IBM Journal of Research and Development, 38, 251-258.</p> <p>Original R implementation: Brunner, M.I. (2017). PRSim: Stochastic Simulation of Streamflow Time Series using Phase Randomization. R package. https://cran.r-project.org/package=PRSim</p> <p>SynHydro Implementation: <code>src/synhydro/methods/generation/nonparametric/phase_randomization.py</code></p> <p>Tests: <code>tests/test_phase_randomization_generator.py</code></p>"},{"location":"algorithms/phase_randomization/#usage-example","title":"Usage Example","text":"<pre><code>import pandas as pd\nfrom synhydro.methods.generation.nonparametric import PhaseRandomizationGenerator\n\n# Load daily streamflow data\nQ_daily = pd.read_csv('daily_flows.csv', index_col=0, parse_dates=True)\n\n# Initialize generator with kappa marginal\ngen = PhaseRandomizationGenerator(\n    Q_daily,\n    marginal='kappa',      # Use kappa distribution for extrapolation\n    win_h_length=15        # 31-day window for daily fitting\n)\n\n# Preprocessing: remove leap days, create day index\ngen.preprocessing()\n\n# Fit: estimate kappa parameters, compute FFT\ngen.fit()\n\n# Generate 100 realizations\nensemble = gen.generate(n_realizations=100, seed=42)\n\n# Access results\nfirst_realization = ensemble.get_realization(0)\nprint(f\"Generated {ensemble.n_realizations} realizations\")\nprint(f\"Each has {len(first_realization)} days\")\n</code></pre>"},{"location":"algorithms/phase_randomization/#verification-checklist","title":"Verification Checklist","text":"<p>When implementing or validating phase randomization:</p> <ul> <li>[ ] Marginal distributions match kappa fit (or empirical) per day</li> <li>[ ] Power spectrum of synthetic matches observed</li> <li>[ ] Autocorrelation function preserved (ensemble mean)</li> <li>[ ] Long-range dependence (Hurst coefficient) maintained</li> <li>[ ] No negative values in output</li> <li>[ ] Seasonal patterns realistic</li> <li>[ ] Drought duration distributions similar to observed</li> <li>[ ] Ensemble spread is reasonable (not too narrow/wide)</li> </ul>"},{"location":"algorithms/thomas_fiering/","title":"Thomas-Fiering (1962) with Stedinger-Taylor Normalization","text":"<p>Classification: Parametric Temporal Resolution: Monthly Site Compatibility: Univariate</p>"},{"location":"algorithms/thomas_fiering/#technical-specifications","title":"Technical Specifications","text":"Property Specification Input data Monthly streamflow, minimum 2 complete years (24 months) Output frequency MS (Month Start) Distributional assumption Normal after Stedinger-Taylor transformation Correlation structure Lag-1 serial correlation (AR(1) model) Temporal dependence Monthly autoregressive with seasonal parameters"},{"location":"algorithms/thomas_fiering/#algorithm-description","title":"Algorithm Description","text":"<p>The Thomas-Fiering method generates synthetic monthly streamflow using a first-order autoregressive (AR(1)) model with season-specific (monthly) parameters. The Stedinger-Taylor (1982) normalization improves the method by applying a lower-bound adjustment before log transformation, reducing skewness and improving normality.</p> <p>This method preserves monthly means, standard deviations, and lag-1 serial correlations, making it suitable for operational hydrology, reservoir simulation, and water supply planning at monthly resolution.</p>"},{"location":"algorithms/thomas_fiering/#preprocessing","title":"Preprocessing","text":"<ol> <li>Frequency validation</li> <li>Validate input has DatetimeIndex</li> <li> <p>If not monthly frequency ('MS'), resample:</p> <ul> <li>Daily \u2192 Monthly: sum flows within each month</li> <li>Weekly \u2192 Monthly: sum flows within each month</li> </ul> </li> <li> <p>Univariate enforcement</p> </li> <li>Thomas-Fiering is univariate (single site only)</li> <li>If DataFrame with multiple columns, use first column only</li> <li> <p>Warn user about multi-site input</p> </li> <li> <p>Stedinger-Taylor normalization</p> </li> <li>Fit lower bound parameters (\u03c4):<ul> <li>For each month m \u2208 {1, ..., 12}:</li> <li>Extract all observations for month m across years</li> <li>Compute: `\u03c4\u2098 = (Q\u2098\u2090\u2093\u00b7Q\u2098\u1d62\u2099 - Q\u00b2\u2098\u2091</li> </ul> </li> </ol> <p>dian) / (Q\u2098\u2090\u2093 + Q\u2098\u1d62\u2099 - 2\u00b7Q\u2098\u2091dian)<code>- Clip:</code>\u03c4\u2098 = max(\u03c4\u2098, 0)<code>(ensure non-negative)    - **Apply transformation**:      - For each observation in month m:        - Subtract lower bound and log-transform:</code>X\u2098 = log(Q\u2098 - \u03c4\u2098)`        - This reduces skewness and improves normality</p>"},{"location":"algorithms/thomas_fiering/#fittingcalibration","title":"Fitting/Calibration","text":"<ol> <li>Compute monthly statistics</li> <li> <p>For each month m \u2208 {1, ..., 12}, compute from normalized flows X:</p> <ul> <li>Mean: <code>\u03bc\u2098 = E[X\u2098]</code></li> <li>Standard deviation: <code>\u03c3\u2098 = std(X\u2098)</code></li> </ul> </li> <li> <p>Compute lag-1 serial correlations</p> </li> <li> <p>For each month transition m \u2192 m+1 (with Dec \u2192 Jan wraparound):</p> <ul> <li>Extract all pairs of consecutive months across years:</li> <li><code>(X\u2081\u2098, X\u2081,\u2098\u208a\u2081), (X\u2082\u2098, X\u2082,\u2098\u208a\u2081), ..., (X\u2099\u2098, X\u2099,\u2098\u208a\u2081)</code></li> <li>Filter out NaN and Inf values from transformation</li> <li>Compute Pearson correlation: <code>\u03c1\u2098 = corr(X\u2098, X\u2098\u208a\u2081)</code></li> <li>If insufficient data or zero variance, default to <code>\u03c1\u2098 = 0</code></li> </ul> </li> <li> <p>Store fitted parameters</p> </li> <li>Monthly means: <code>\u03bc = {\u03bc\u2081, \u03bc\u2082, ..., \u03bc\u2081\u2082}</code></li> <li>Monthly standard deviations: <code>\u03c3 = {\u03c3\u2081, \u03c3\u2082, ..., \u03c3\u2081\u2082}</code></li> <li>Monthly lag-1 correlations: <code>\u03c1 = {\u03c1\u2081, \u03c1\u2082, ..., \u03c1\u2081\u2082}</code></li> <li>Stedinger transformation parameters: <code>\u03c4 = {\u03c4\u2081, \u03c4\u2082, ..., \u03c4\u2081\u2082}</code></li> <li>Total: 48 parameters (12 months \u00d7 4 parameters)</li> </ol>"},{"location":"algorithms/thomas_fiering/#generation","title":"Generation","text":"<ol> <li>Initialize first month</li> <li> <p>For first month (January) of first year:      <pre><code>X\u2081,\u2081 = \u03bc\u2081 + \u03b5\u2081,\u2081 \u00b7 \u03c3\u2081\n</code></pre>      where <code>\u03b5\u2081,\u2081 ~ N(0, 1)</code> is standard normal random variate</p> </li> <li> <p>Generate subsequent months (AR(1) recursion)</p> </li> <li> <p>For each subsequent month i = 2, 3, ..., n_years \u00d7 12:</p> <ul> <li>Determine current month m (1-12) and previous month m_prev</li> <li>Generate standard normal random variate: <code>\u03b5 ~ N(0, 1)</code></li> <li>Apply AR(1) formula:    <pre><code>X\u1d62,\u2098 = \u03bc\u2098 + \u03c1\u2098 \u00b7 (\u03c3\u2098/\u03c3\u2098_prev) \u00b7 (X\u1d62\u208b\u2081,\u2098_prev - \u03bc\u2098_prev) + \u221a(1 - \u03c1\u2098\u00b2) \u00b7 \u03c3\u2098 \u00b7 \u03b5\n</code></pre></li> <li>This preserves:</li> <li>Mean: <code>E[X\u1d62,\u2098] = \u03bc\u2098</code></li> <li>Variance: <code>Var[X\u1d62,\u2098] = \u03c3\u2098\u00b2</code></li> <li>Lag-1 correlation: <code>corr(X\u1d62\u208b\u2081, X\u1d62) = \u03c1\u2098</code></li> </ul> </li> <li> <p>Inverse Stedinger transformation</p> </li> <li>For each generated normalized flow X\u1d62,\u2098:      <pre><code>Q\u1d62,\u2098 = exp(X\u1d62,\u2098) + \u03c4\u2098\n</code></pre></li> <li> <p>Back-transforms from normal space to original flow space</p> </li> <li> <p>Non-negativity enforcement</p> </li> <li>Replace negative values (rare, from transformation):      <pre><code>Q\u1d62,\u2098 = max(Q\u1d62,\u2098, Q\u2098\u1d62\u2099,observed)\n</code></pre></li> <li> <p>Fill NaN values with observed minimum for that month</p> </li> <li> <p>Time index creation</p> </li> <li>Generate monthly DatetimeIndex starting from observed data start year</li> <li>Frequency: 'MS' (month start)</li> </ol>"},{"location":"algorithms/thomas_fiering/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>Q_obs</code>: Observed streamflow data</li> <li>Type: pd.Series or pd.DataFrame (first column used if DataFrame)</li> <li> <p>Notes: Must have DatetimeIndex. If not monthly, will be resampled during preprocessing.</p> </li> <li> <p><code>debug</code>: Enable debug logging</p> </li> <li>Type: bool</li> <li>Default: False</li> </ul>"},{"location":"algorithms/thomas_fiering/#algorithmic-details","title":"Algorithmic Details","text":""},{"location":"algorithms/thomas_fiering/#ar1-model-formulation","title":"AR(1) Model Formulation","text":"<p>General AR(1) model: <pre><code>X\u209c = \u03c6\u00b7X\u209c\u208b\u2081 + \u03b5\u209c\n</code></pre></p> <p>Thomas-Fiering seasonal AR(1): <pre><code>X\u1d62,\u2098 - \u03bc\u2098 = \u03c1\u2098 \u00b7 (\u03c3\u2098/\u03c3\u2098\u208b\u2081) \u00b7 (X\u1d62\u208b\u2081,\u2098\u208b\u2081 - \u03bc\u2098\u208b\u2081) + \u221a(1 - \u03c1\u2098\u00b2) \u00b7 \u03c3\u2098 \u00b7 \u03b5\u1d62,\u2098\n</code></pre></p> <p>where: - <code>X\u1d62,\u2098</code>: Normalized flow for year i, month m - <code>\u03bc\u2098</code>: Mean for month m - <code>\u03c3\u2098</code>: Standard deviation for month m - <code>\u03c1\u2098</code>: Lag-1 correlation from month m-1 to month m - <code>\u03b5\u1d62,\u2098 ~ N(0, 1)</code>: Independent standard normal innovation</p> <p>Key properties: 1. Mean preservation: <code>E[X\u1d62,\u2098] = \u03bc\u2098</code> 2. Variance preservation: <code>Var[X\u1d62,\u2098] = \u03c3\u2098\u00b2</code> 3. Correlation preservation: <code>Cov[X\u1d62\u208b\u2081,\u2098\u208b\u2081, X\u1d62,\u2098] = \u03c1\u2098 \u00b7 \u03c3\u2098\u208b\u2081 \u00b7 \u03c3\u2098</code></p>"},{"location":"algorithms/thomas_fiering/#stedinger-taylor-normalization","title":"Stedinger-Taylor Normalization","text":"<p>Purpose: Reduce skewness in streamflow distributions to improve normality assumption.</p> <p>Lower bound estimation: <pre><code>\u03c4\u2098 = (Q\u2098\u2090\u2093 \u00b7 Q\u2098\u1d62\u2099 - Q\u2098\u2091dian\u00b2) / (Q\u2098\u2090\u2093 + Q\u2098\u1d62\u2099 - 2 \u00b7 Q\u2098\u2091dian)\n</code></pre></p> <p>Forward transformation: <pre><code>X = log(Q - \u03c4)\n</code></pre></p> <p>Inverse transformation: <pre><code>Q = exp(X) + \u03c4\n</code></pre></p> <p>Advantages over simple log: - Better handles skewness - Reduces bias in mean and variance - More robust to low flows</p>"},{"location":"algorithms/thomas_fiering/#statistical-properties-preserved","title":"Statistical Properties Preserved","text":"<p>Explicitly preserved (in normalized space): - Monthly means: <code>\u03bc\u2098</code> - Monthly standard deviations: <code>\u03c3\u2098</code> - Lag-1 serial correlations: <code>\u03c1\u2098</code></p> <p>Approximately preserved (in original space): - Monthly mean flows - Monthly flow variability - Sequential dependence structure</p> <p>Not preserved: - Higher-order (lag &gt; 1) correlations (first-order model only) - Spatial correlations (univariate method) - Exact marginal distributions (transformed to normal)</p>"},{"location":"algorithms/thomas_fiering/#algorithm-variations","title":"Algorithm Variations","text":"<ul> <li>Disaggregation: Extend to daily timestep using fragmentat ion methods (e.g., Valencia-Schaake)</li> <li>Multi-site extension: Multivariate AR models (MVAR) preserve spatial correlations</li> <li>Higher-order AR: AR(p) models capture longer memory</li> <li>Nonlinear transformations: Box-Cox instead of log</li> <li>Alternative normalization: NPLN (Normal, Log-Normal) instead of Stedinger-Taylor</li> </ul>"},{"location":"algorithms/thomas_fiering/#implementation-notes","title":"Implementation Notes","text":""},{"location":"algorithms/thomas_fiering/#computational-complexity","title":"Computational complexity","text":"<ul> <li>Time: O(n) where n = number of observations</li> <li>Single pass to compute monthly statistics</li> <li>Generation is O(n_years \u00d7 12) per realization</li> <li>Space: O(12) for monthly parameter storage</li> <li>Very efficient for typical hydrologic records (10-100 years of monthly data)</li> </ul>"},{"location":"algorithms/thomas_fiering/#limitations","title":"Limitations","text":"<ul> <li>Univariate only: Cannot model spatial correlations between sites</li> <li>First-order only: Only captures lag-1 dependence (month-to-month)</li> <li>Misses multi-month persistence and seasonality in correlation structure</li> <li>Normality assumption: Assumes flows are normal after transformation</li> <li>May not capture extreme events well (heavy tails)</li> <li>Monthly timestep: Not suitable for daily analysis</li> <li>Use disaggregation methods if daily data needed</li> <li>Stationarity: Assumes parameters are time-invariant</li> <li>Not suitable for trending or non-stationary data</li> <li>Data requirements: Needs at least 2 complete years (better with 10+)</li> <li>More data improves parameter estimation reliability</li> </ul>"},{"location":"algorithms/thomas_fiering/#special-handling","title":"Special handling","text":"<ul> <li>NaN/Inf values: From Stedinger transform when <code>Q - \u03c4 \u2264 0</code></li> <li>Filtered before correlation calculation</li> <li>Replaced with minimum observed flow in generation</li> <li>Negative generated flows: Rare but possible from transformation</li> <li>Replaced with observed minimum for that month</li> <li>First month initialization: Sampled from <code>N(\u03bc\u2081, \u03c3\u2081\u00b2)</code> without dependence</li> <li>Allows generation to start from any month</li> <li>December \u2192 January transition: Handled via modular arithmetic</li> <li>Month index wraps: <code>(m % 12) + 1</code></li> </ul>"},{"location":"algorithms/thomas_fiering/#hydrologic-properties-preserved","title":"Hydrologic properties preserved","text":"<p>Explicitly preserved (by design): - Monthly mean flows - Monthly standard deviations - Lag-1 autocorrelation</p> <p>Implicitly preserved (approximately): - Seasonal flow patterns - Year-to-year variability - Dry/wet spell persistence (via lag-1 correlation)</p> <p>Not preserved: - Multi-month droughts (&gt;1 month memory) - Spatial correlations (univariate) - Exact flow distributions (normality imposed) - Trends or non-stationarity</p>"},{"location":"algorithms/thomas_fiering/#references","title":"References","text":"<p>Primary: Thomas, H.A., and Fiering, M.B. (1962). Mathematical synthesis of streamflow sequences for the analysis of river basins by simulation. In Design of Water Resource Systems (eds. Maass et al.), pp. 459-493. Harvard University Press.</p> <p>Stedinger-Taylor Normalization: Stedinger, J.R., and Taylor, M.R. (1982). Synthetic streamflow generation: 1. Model verification and validation. Water Resources Research, 18(4), 909-918. https://doi.org/10.1029/WR018i004p00909</p> <p>Methodological foundations: - AR(1) models: Box, G.E.P., and Jenkins, G.M. (1970). Time Series Analysis: Forecasting and Control. Holden-Day. - Streamflow synthesis: Fiering, M.B. (1967). Streamflow Synthesis. Harvard University Press. - Operational hydrology: Loucks, D.P., and van Beek, E. (2017). Water Resource Systems Planning and Management. Springer.</p> <p>Extensions: - Multivariate AR: Salas, J.D., Delleur, J.W., Yevjevich, V., and Lane, W.L. (1980). Applied Modeling of Hydrologic Time Series. Water Resources Publications. - Disaggregation: Valencia, D., and Schaake, J.C. (1973). Disaggregation processes in stochastic hydrology. Water Resources Research, 9(3), 580-585.</p> <p>SynHydro Implementation: <code>src/synhydro/methods/generation/parametric/thomas_fiering.py</code></p> <p>Tests: <code>tests/test_thomas_fiering_generator.py</code></p>"},{"location":"algorithms/thomas_fiering/#usage-example","title":"Usage Example","text":"<pre><code>import pandas as pd\nfrom synhydro.methods.generation.parametric import ThomasFieringGenerator\n\n# Load monthly streamflow data\nQ_monthly = pd.read_csv('monthly_flows.csv', index_col=0, parse_dates=True)\n\n# Initialize generator\ngen = ThomasFieringGenerator(Q_monthly)\n\n# Preprocess: apply Stedinger-Taylor normalization\ngen.preprocessing()\n\n# Fit: estimate monthly parameters\ngen.fit()\n\n# Examine fitted parameters\nprint(f\"Monthly means (normalized):\\n{gen.mu_monthly}\")\nprint(f\"Monthly std devs (normalized):\\n{gen.sigma_monthly}\")\nprint(f\"Monthly lag-1 correlations:\\n{gen.rho_monthly}\")\n\n# Generate 100 realizations of 50 years each\nensemble = gen.generate(n_years=50, n_realizations=100, seed=42)\n\n# Access results\nprint(f\"Generated {ensemble.metadata.n_realizations} realizations\")\nprint(f\"Each has {len(ensemble.data_by_realization[0])} months\")\n\n# Get first realization\nfirst_real = ensemble.data_by_realization[0]\nprint(first_real.head())\n\n# Get monthly statistics from ensemble\nimport numpy as np\nall_data = pd.concat([ensemble.data_by_realization[r] for r in range(100)], axis=0)\nmonthly_stats = all_data.groupby(all_data.index.month).agg(['mean', 'std'])\nprint(monthly_stats)\n</code></pre>"},{"location":"algorithms/thomas_fiering/#advanced-usage","title":"Advanced Usage","text":""},{"location":"algorithms/thomas_fiering/#generate-from-daily-data-automatic-resampling","title":"Generate from daily data (automatic resampling)","text":"<pre><code># Daily data will be resampled to monthly\nQ_daily = pd.read_csv('daily_flows.csv', index_col=0, parse_dates=True)\n\ngen = ThomasFieringGenerator(Q_daily)\ngen.preprocessing()  # Automatically resamples to monthly\ngen.fit()\nensemble = gen.generate(n_years=20, n_realizations=50, seed=42)\n</code></pre>"},{"location":"algorithms/thomas_fiering/#generate-specific-number-of-timesteps","title":"Generate specific number of timesteps","text":"<pre><code># Generate exactly 37 months (3 years + 1 month)\nensemble = gen.generate(n_timesteps=37, n_realizations=10, seed=42)\n</code></pre>"},{"location":"algorithms/thomas_fiering/#access-fitted-parameters","title":"Access fitted parameters","text":"<pre><code>gen.preprocessing()\ngen.fit()\n\n# FittedParams object\nparams = gen.fitted_params_\n\nprint(f\"Number of parameters: {params.n_parameters_}\")  # 48 (12 months \u00d7 4)\nprint(f\"Training period: {params.training_period_}\")\nprint(f\"Sample size: {params.sample_size_}\")\n\n# Access transformation parameters\ntau_values = params.transformations_['stedinger_transform']['tau_monthly']\nprint(f\"Lower bounds by month:\\n{tau_values}\")\n</code></pre>"},{"location":"algorithms/thomas_fiering/#verification-checklist","title":"Verification Checklist","text":"<p>When implementing or validating Thomas-Fiering:</p> <ul> <li>[ ] Monthly parameters correct: 12 values for \u03bc, \u03c3, \u03c1, \u03c4</li> <li>[ ] Lag-1 correlations valid: All \u03c1\u2098 \u2208 [-1, 1]</li> <li>[ ] Non-negative flows: No negative values in output</li> <li>[ ] Reproducible: Same seed gives same results</li> <li>[ ] AR(1) formula: Correctly implements variance-adjusted correlation</li> <li>[ ] Stedinger transform: Lower bounds computed correctly</li> <li>[ ] Monthly frequency: Output has 'MS' frequency</li> <li>[ ] Ensemble structure: Returns Ensemble object with realizations</li> <li>[ ] Statistical preservation: Monthly means/stds approximately match (ensemble average)</li> <li>[ ] No NaN/Inf propagation: Invalid values handled appropriately</li> </ul>"},{"location":"algorithms/thomas_fiering/#comparison-to-other-methods","title":"Comparison to Other Methods","text":"Aspect Thomas-Fiering Multi-Site HMM Kirsch-Nowak Temporal resolution Monthly Annual Monthly Spatial Univariate Multisite Multisite Correlation Lag-1 (AR1) Full temporal + spatial Full temporal + spatial Distributional Normal (Stedinger) Log-normal mixture Normal (transformed) Seasonality Monthly parameters Implicit in states Monthly parameters Computational Very fast Moderate (EM) Fast Sample size 2+ years 20+ years 10+ years Parameters 48 (12 \u00d7 4) O(n_states \u00b7 n_sites\u00b2) O(12 \u00b7 n_sites\u00b2) Best for Single-site monthly Multi-site regimes Multi-site monthly"},{"location":"algorithms/thomas_fiering/#historical-context","title":"Historical Context","text":"<p>The Thomas-Fiering method (1962) was one of the first widely-adopted stochastic streamflow generators. It revolutionized reservoir simulation and water resources planning by:</p> <ol> <li>Enabling Monte Carlo analysis: Generate many equiprobable sequences</li> <li>Preserving key statistics: Monthly means, std devs, lag-1 correlation</li> <li>Computational simplicity: Fast generation, easy to implement</li> <li>Operational applicability: Suitable for planning horizons (months-years)</li> </ol> <p>The Stedinger-Taylor improvement (1982) addressed the main limitation: skewness in streamflow distributions. By estimating a lower bound before log transformation, it better approximates normality and reduces bias.</p> <p>Legacy: Thomas-Fiering remains widely used in: - Reservoir operation studies - Water supply reliability analysis - Hydropower planning - Educational demonstrations of stochastic hydrology</p> <p>Modern alternatives: For more complex applications (multi-site, extreme events, non-stationarity), consider: - Multivariate AR models (spatial correlations) - Hidden Markov Models (regime-dependent distributions) - Nonparametric methods (fewer assumptions) - Machine learning approaches (complex patterns)</p>"},{"location":"algorithms/warm/","title":"Wavelet Auto-Regressive Method (WARM)","text":""},{"location":"algorithms/warm/#technical-specifications","title":"Technical Specifications","text":"Property Value Method Name WARM (Wavelet Auto-Regressive Method) Implementation <code>WARMGenerator</code> Type Parametric, Stochastic Frequency Annual Sites Univariate (single site) Reference Nowak et al. (2011) Full Citation Nowak, K., Rajagopalan, B., &amp; Zagona, E. (2011). A Wavelet Auto-Regressive Method (WARM) for multi-site streamflow simulation of data with non-stationary trends. Journal of Hydrology, 410(1-2), 1-12."},{"location":"algorithms/warm/#overview","title":"Overview","text":"<p>The Wavelet Auto-Regressive Method (WARM) is an advanced stochastic generator designed for non-stationary streamflow simulation. WARM combines continuous wavelet transforms with autoregressive modeling to preserve both time-varying spectral characteristics and temporal persistence in synthetic streamflow sequences.</p> <p>Key Innovation: The Scale Averaged Wavelet Power (SAWP) enables WARM to capture and reproduce time-varying power spectral characteristics, making it particularly suitable for streamflows with non-stationary trends, regime shifts, or low-frequency variability (e.g., climate oscillations, long-term droughts).</p>"},{"location":"algorithms/warm/#algorithm-description","title":"Algorithm Description","text":"<p>WARM operates through a 4-step process that decomposes, models, and reconstructs streamflow signals using wavelet analysis and autoregressive modeling.</p>"},{"location":"algorithms/warm/#1-preprocessing","title":"1. Preprocessing","text":"<p>Objective: Prepare annual streamflow data for wavelet analysis.</p> <p>Steps: 1. Validate input data (univariate time series) 2. Resample to annual frequency if needed (monthly \u2192 annual via sum, daily \u2192 annual via sum) 3. Store observed annual flows: \\(Q_{\\text{obs}}(t)\\), where \\(t = 1, 2, \\ldots, T\\) years</p> <p>Validation: - Minimum recommended: 20 years of data - WARM designed specifically for annual streamflow - Single-site only (univariate)</p>"},{"location":"algorithms/warm/#2-fitting-training","title":"2. Fitting (Training)","text":"<p>WARM fitting consists of 4 sub-steps:</p>"},{"location":"algorithms/warm/#step-1-continuous-wavelet-transform-cwt","title":"Step 1: Continuous Wavelet Transform (CWT)","text":"<p>Objective: Decompose time series into time-frequency components.</p> <p>Apply continuous wavelet transform using mother wavelet \\(\\psi\\):</p> \\[ W(s, t) = \\int_{-\\infty}^{\\infty} Q(\\tau) \\cdot \\frac{1}{\\sqrt{s}} \\psi^*\\left(\\frac{\\tau - t}{s}\\right) d\\tau \\] <p>where: - \\(W(s, t)\\) = wavelet coefficients at scale \\(s\\) and time \\(t\\) - \\(\\psi\\) = mother wavelet function (e.g., Morlet, Mexican Hat) - \\(s\\) = scale parameter (related to frequency: larger scales = lower frequencies) - \\(*\\) denotes complex conjugate</p> <p>Implementation: <pre><code>scales = np.arange(1, n_scales + 1)\ncoefficients, frequencies = pywt.cwt(Q_obs, scales, wavelet='morl')\n# Result: coefficients with shape (n_scales, n_years)\n</code></pre></p> <p>Recommended Wavelets: - Morlet (<code>'morl'</code>): Best for hydrologic applications, good time-frequency localization - Mexican Hat (<code>'mexh'</code>): Symmetric, good for detecting peaks - Gaussian (<code>'gaus1'</code>-<code>'gaus8'</code>): Smooth, varying derivatives</p>"},{"location":"algorithms/warm/#step-2-scale-averaged-wavelet-power-sawp","title":"Step 2: Scale Averaged Wavelet Power (SAWP)","text":"<p>Objective: Compute time-varying power across all frequency scales.</p> <p>SAWP is the key innovation of WARM (Nowak et al. 2011) compared to previous methods (Kwon et al. 2007). It captures temporal variations in spectral power.</p> <p>Calculate wavelet power at each scale and time:</p> \\[ P(s, t) = |W(s, t)|^2 \\] <p>Average across all scales for each time point:</p> \\[ \\text{SAWP}(t) = \\frac{1}{S} \\sum_{s=1}^{S} P(s, t) = \\frac{1}{S} \\sum_{s=1}^{S} |W(s, t)|^2 \\] <p>where \\(S\\) = total number of scales.</p> <p>Physical Meaning: - High SAWP(t) \u2192 High energy/variability at time \\(t\\) - Low SAWP(t) \u2192 Low energy/variability at time \\(t\\) - Captures non-stationary variance structure</p> <p>Implementation: <pre><code>power = np.abs(coefficients) ** 2\nsawp = np.mean(power, axis=0)  # Average across scales\n</code></pre></p>"},{"location":"algorithms/warm/#step-3-normalize-by-sawp","title":"Step 3: Normalize by SAWP","text":"<p>Objective: Remove time-varying power to create stationary components.</p> <p>For each scale \\(s\\) and time \\(t\\):</p> \\[ W_{\\text{norm}}(s, t) = \\frac{W(s, t)}{\\sqrt{\\text{SAWP}(t) + \\epsilon}} \\] <p>where \\(\\epsilon\\) is a small constant (\\(10^{-10}\\)) to prevent division by zero.</p> <p>Result: Normalized coefficients \\(W_{\\text{norm}}(s, t)\\) are approximately stationary and suitable for AR modeling.</p>"},{"location":"algorithms/warm/#step-4-fit-ar-models-to-each-scale","title":"Step 4: Fit AR Models to Each Scale","text":"<p>Objective: Model temporal persistence at each frequency scale.</p> <p>For each scale \\(s\\), fit an AR(p) model to the normalized coefficients \\(W_{\\text{norm}}(s, \\cdot)\\):</p> \\[ W_{\\text{norm}}(s, t) = \\mu_s + \\sum_{i=1}^{p} \\phi_{s,i} \\left[W_{\\text{norm}}(s, t-i) - \\mu_s\\right] + \\epsilon_s(t) \\] <p>where: - \\(\\mu_s\\) = mean of normalized coefficients at scale \\(s\\) - \\(\\phi_{s,i}\\) = AR coefficient for lag \\(i\\) at scale \\(s\\) - \\(\\epsilon_s(t) \\sim N(0, \\sigma_s^2)\\) = white noise innovation - \\(p\\) = AR order (typically 1 or 2)</p> <p>Parameter Estimation: Yule-Walker equations</p> <p>Given autocorrelation function \\(\\rho(k)\\), solve:</p> \\[ \\begin{bmatrix} 1 &amp; \\rho(1) &amp; \\cdots &amp; \\rho(p-1) \\\\ \\rho(1) &amp; 1 &amp; \\cdots &amp; \\rho(p-2) \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\rho(p-1) &amp; \\rho(p-2) &amp; \\cdots &amp; 1 \\end{bmatrix} \\begin{bmatrix} \\phi_1 \\\\ \\phi_2 \\\\ \\vdots \\\\ \\phi_p \\end{bmatrix} = \\begin{bmatrix} \\rho(1) \\\\ \\rho(2) \\\\ \\vdots \\\\ \\rho(p) \\end{bmatrix} \\] <p>Innovation variance:</p> \\[ \\sigma^2 = \\gamma(0) \\left(1 - \\sum_{i=1}^{p} \\phi_i \\rho(i)\\right) \\] <p>where \\(\\gamma(0)\\) is the variance of the normalized coefficients.</p> <p>Stored Parameters: - For each scale \\(s\\): \\(\\{\\mu_s, \\phi_{s,1}, \\ldots, \\phi_{s,p}, \\sigma_s\\}\\) - SAWP time series: \\(\\text{SAWP}(1), \\ldots, \\text{SAWP}(T)\\) - Wavelet parameters: wavelet type, scales array</p>"},{"location":"algorithms/warm/#3-generation-synthesis","title":"3. Generation (Synthesis)","text":"<p>Objective: Generate synthetic annual streamflow sequences.</p>"},{"location":"algorithms/warm/#step-1-generate-normalized-coefficients","title":"Step 1: Generate Normalized Coefficients","text":"<p>For each scale \\(s\\) and each synthetic year \\(t\\):</p> <ol> <li> <p>Initialize: \\(W_{\\text{syn,norm}}(s, 0) = \\mu_s\\) (or use historical values)</p> </li> <li> <p>Generate AR process:    $$    W_{\\text{syn,norm}}(s, t) = \\mu_s + \\sum_{i=1}^{p} \\phi_{s,i} \\left[W_{\\text{syn,norm}}(s, t-i) - \\mu_s\\right] + \\epsilon_s(t)    $$</p> </li> </ol> <p>where \\(\\epsilon_s(t) \\sim N(0, \\sigma_s^2)\\) are independent random innovations.</p> <p>Result: Normalized synthetic coefficients for all scales and times.</p>"},{"location":"algorithms/warm/#step-2-resample-sawp","title":"Step 2: Resample SAWP","text":"<p>Objective: Create time-varying power for synthetic sequence.</p> <p>Resample SAWP from historical record with replacement:</p> \\[ \\text{SAWP}_{\\text{syn}}(t) = \\text{SAWP}_{\\text{obs}}(k_t) \\] <p>where \\(k_t\\) is a randomly selected time index from \\(\\{1, 2, \\ldots, T\\}\\).</p> <p>Purpose: Preserve the distribution and range of power variations while allowing different temporal patterns.</p>"},{"location":"algorithms/warm/#step-3-rescale-coefficients","title":"Step 3: Rescale Coefficients","text":"<p>Objective: Restore time-varying power to synthetic coefficients.</p> <p>For each scale \\(s\\) and time \\(t\\):</p> \\[ W_{\\text{syn}}(s, t) = W_{\\text{syn,norm}}(s, t) \\cdot \\sqrt{\\text{SAWP}_{\\text{syn}}(t) + \\epsilon} \\] <p>Result: Synthetic wavelet coefficients with time-varying power.</p>"},{"location":"algorithms/warm/#step-4-inverse-wavelet-transform","title":"Step 4: Inverse Wavelet Transform","text":"<p>Objective: Reconstruct synthetic streamflow time series.</p> <p>The inverse CWT is approximated by weighted summation across scales:</p> \\[ Q_{\\text{syn}}(t) = C \\sum_{s=1}^{S} \\frac{\\Re[W_{\\text{syn}}(s, t)]}{\\sqrt{s}} \\cdot w_s \\] <p>where: - \\(\\Re[\\cdot]\\) = real part - \\(w_s\\) = scale-dependent weights (typically \\(w_s = 1/\\sqrt{s}\\)) - \\(C\\) = normalization constant</p> <p>Adjustment: After reconstruction, adjust mean and variance to match observed:</p> \\[ Q_{\\text{syn,adjusted}}(t) = \\sigma_{\\text{obs}} \\cdot \\frac{Q_{\\text{syn}}(t) - \\bar{Q}_{\\text{syn}}}{\\sigma_{\\text{syn}}} + \\bar{Q}_{\\text{obs}} \\] <p>Non-negativity: Ensure \\(Q_{\\text{syn}}(t) \\geq 0\\) (set negative values to 0).</p>"},{"location":"algorithms/warm/#mathematical-formulation-summary","title":"Mathematical Formulation Summary","text":""},{"location":"algorithms/warm/#input","title":"Input","text":"<ul> <li>Historical annual flows: \\(Q_{\\text{obs}}(t)\\), \\(t = 1, \\ldots, T\\)</li> </ul>"},{"location":"algorithms/warm/#parameters","title":"Parameters","text":"<ul> <li>Wavelet type: \\(\\psi\\) (e.g., Morlet)</li> <li>Number of scales: \\(S\\) (e.g., 64)</li> <li>AR order: \\(p\\) (e.g., 1)</li> </ul>"},{"location":"algorithms/warm/#fitted-quantities","title":"Fitted Quantities","text":"<ul> <li>Wavelet coefficients: \\(W(s, t)\\) for \\(s = 1, \\ldots, S\\) and \\(t = 1, \\ldots, T\\)</li> <li>SAWP: \\(\\text{SAWP}(t)\\) for \\(t = 1, \\ldots, T\\)</li> <li>AR parameters for each scale: \\(\\{\\mu_s, \\phi_{s,1}, \\ldots, \\phi_{s,p}, \\sigma_s\\}\\) for \\(s = 1, \\ldots, S\\)</li> </ul>"},{"location":"algorithms/warm/#output","title":"Output","text":"<ul> <li>Synthetic annual flows: \\(Q_{\\text{syn}}(t)\\), \\(t = 1, \\ldots, T_{\\text{syn}}\\)</li> </ul>"},{"location":"algorithms/warm/#key-parameters-and-tuning","title":"Key Parameters and Tuning","text":""},{"location":"algorithms/warm/#wavelet-selection","title":"Wavelet Selection","text":"Wavelet Code Characteristics Use Case Morlet <code>'morl'</code> Complex, good time-frequency localization Recommended for streamflow (default) Mexican Hat <code>'mexh'</code> Symmetric, second derivative of Gaussian Detecting peaks/oscillations Gaussian (1st-8th) <code>'gaus1'</code>-<code>'gaus8'</code> Smooth, varying smoothness Experimental/smoothing <p>Recommendation: Use Morlet wavelet (<code>'morl'</code>) as it provides the best balance between time and frequency localization for hydrologic signals.</p>"},{"location":"algorithms/warm/#number-of-scales","title":"Number of Scales","text":"<p>Parameter: <code>scales</code> (default: 64)</p> <p>Guidelines: - Low (8-16): Faster computation, captures only major frequencies - Medium (32-64): Recommended, good frequency resolution - High (128+): Very detailed, computationally expensive, may overfit</p> <p>Rule of thumb: Use \\(S \\approx T/2\\) to \\(T\\), where \\(T\\) = number of years.</p> <p>Example: - 50 years of data \u2192 32-64 scales - 100 years of data \u2192 64-128 scales</p>"},{"location":"algorithms/warm/#ar-order","title":"AR Order","text":"<p>Parameter: <code>ar_order</code> (default: 1)</p> <p>Guidelines: - AR(1): Captures first-order temporal persistence, recommended for most cases - AR(2): Captures additional lag structure, use if data shows strong 2-year memory - AR(3+): Rarely needed, risk of overfitting</p> <p>Selection: Use information criteria (AIC/BIC) or cross-validation if uncertain. Default AR(1) works well for annual streamflow.</p>"},{"location":"algorithms/warm/#computational-complexity","title":"Computational Complexity","text":"Operation Complexity Notes CWT \\(O(S \\cdot T)\\) \\(S\\) = scales, \\(T\\) = years SAWP Calculation \\(O(S \\cdot T)\\) Simple averaging AR Fitting \\(O(S \\cdot T \\cdot p^2)\\) \\(p\\) = AR order, Yule-Walker solution Generation \\(O(S \\cdot T_{\\text{syn}})\\) Per realization Inverse CWT \\(O(S \\cdot T_{\\text{syn}})\\) Weighted summation <p>Total Fitting: \\(O(S \\cdot T \\cdot p^2)\\)</p> <p>Total Generation (per realization): \\(O(S \\cdot T_{\\text{syn}})\\)</p> <p>Memory: \\(O(S \\cdot T)\\) for storing wavelet coefficients.</p> <p>Typical Performance (64 scales, 50 years, AR(1)): - Fitting: &lt; 1 second - Generation (100 realizations \u00d7 100 years): ~ 2-5 seconds</p>"},{"location":"algorithms/warm/#limitations-and-special-handling","title":"Limitations and Special Handling","text":""},{"location":"algorithms/warm/#1-annual-frequency-only","title":"1. Annual Frequency Only","text":"<p>Limitation: WARM is designed for annual streamflow.</p> <p>Reason: Wavelet decomposition for capturing multi-year oscillations (e.g., ENSO, PDO) works best at annual scale.</p> <p>Workaround: For monthly/daily generation, consider: - Use WARM for annual totals - Disaggregate to finer resolution using separate method (e.g., K-NN, HMM)</p>"},{"location":"algorithms/warm/#2-univariate-single-site","title":"2. Univariate (Single Site)","text":"<p>Current Implementation: Single site only.</p> <p>Extension: Nowak et al. (2011) describes multi-site extension: - Generate multiple sites using WARM independently - Apply spatial disaggregation method to impose spatial correlation - Preserve historical spatial correlation structure</p> <p>Future Work: Multi-site version could use: - Coupled AR models at each scale (VAR instead of AR) - Joint wavelet analysis with cross-wavelet transforms</p>"},{"location":"algorithms/warm/#3-edge-effects","title":"3. Edge Effects","text":"<p>Issue: CWT has edge effects (cone of influence) at start/end of time series.</p> <p>Handling: - PyWavelets pads signal automatically - WARM resamples SAWP, which mitigates edge effect impact - For very short series (&lt; 20 years), edge effects may be noticeable</p> <p>Recommendation: Use at least 30 years of data for robust results.</p>"},{"location":"algorithms/warm/#4-non-stationary-mean-trends","title":"4. Non-stationary Mean Trends","text":"<p>Handling: WARM preserves non-stationary spectral characteristics (via SAWP).</p> <p>Strong Linear Trends: If data has strong deterministic trend: - Option 1: Detrend before WARM, re-trend after generation - Option 2: Use WARM as-is if trend is part of low-frequency variability</p> <p>Recommendation: Analyze whether trend is deterministic or stochastic before deciding.</p>"},{"location":"algorithms/warm/#5-zeronear-zero-flows","title":"5. Zero/Near-Zero Flows","text":"<p>Handling: WARM can generate negative values (since AR model has Gaussian innovations).</p> <p>Correction: Post-processing in <code>_generate()</code>: <pre><code>Q_syn = np.maximum(Q_syn, 0)  # Truncate to non-negative\n</code></pre></p> <p>Limitation: For intermittent streams with frequent zeros, consider: - Two-stage model (occurrence + magnitude) - Non-parametric methods (K-NN, phase randomization)</p>"},{"location":"algorithms/warm/#6-reconstruction-accuracy","title":"6. Reconstruction Accuracy","text":"<p>Approximation: Inverse CWT is approximate (PyWavelets doesn't provide exact inverse for CWT).</p> <p>Adjustment: WARM applies mean/variance adjustment after reconstruction: - Preserves observed mean and standard deviation - Small reconstruction error is acceptable for stochastic generation</p>"},{"location":"algorithms/warm/#hydrologic-properties-preserved","title":"Hydrologic Properties Preserved","text":""},{"location":"algorithms/warm/#temporal-properties","title":"Temporal Properties","text":"Property Preserved? Method Mean \u2705 Exactly Post-reconstruction adjustment Variance \u2705 Exactly Post-reconstruction adjustment Lag-1 autocorrelation \u2705 Approximately AR models at each scale Multi-year persistence \u2705 Strong Low-frequency wavelet components + AR Non-stationary variance \u2705 Strong SAWP resampling"},{"location":"algorithms/warm/#frequency-domain-properties","title":"Frequency-Domain Properties","text":"Property Preserved? Method Power spectrum \u2705 Strong Wavelet decomposition Time-varying spectrum \u2705 Strong SAWP innovation Low-frequency oscillations \u2705 Strong Large-scale wavelet components High-frequency variability \u2705 Moderate Small-scale wavelet components + AR noise"},{"location":"algorithms/warm/#distributional-properties","title":"Distributional Properties","text":"Property Preserved? Notes Marginal distribution \u26a0\ufe0f Approximate Mean/variance preserved, but shape may differ Skewness \u26a0\ufe0f Moderate Not explicitly preserved Extremes \u26a0\ufe0f Moderate AR innovations are Gaussian <p>Note: For better preservation of marginal distribution, consider: - Log-transformation before WARM - Post-processing to match observed distribution (e.g., quantile mapping)</p>"},{"location":"algorithms/warm/#comparison-with-other-methods","title":"Comparison with Other Methods","text":""},{"location":"algorithms/warm/#warm-vs-traditional-ar-models","title":"WARM vs. Traditional AR Models","text":"Aspect WARM AR(1) / ARMA Non-stationarity \u2705 Handles via SAWP \u274c Assumes stationarity Low-frequency persistence \u2705 Strong (wavelet scales) \u26a0\ufe0f Weak (limited memory) Computation Moderate (CWT) Fast Interpretability Moderate High"},{"location":"algorithms/warm/#warm-vs-kwon-et-al-2007-wavelet-ar","title":"WARM vs. Kwon et al. (2007) Wavelet-AR","text":"<p>Key Difference: SAWP normalization</p> Feature WARM (Nowak 2011) Kwon et al. (2007) Time-varying power \u2705 SAWP captures \u274c Not captured Non-stationary variance \u2705 Strong \u26a0\ufe0f Moderate Complexity Moderate Moderate <p>Advantage: WARM better preserves non-stationary spectral characteristics.</p>"},{"location":"algorithms/warm/#warm-vs-hmm","title":"WARM vs. HMM","text":"Aspect WARM HMM Regime changes \u26a0\ufe0f Implicit (via SAWP) \u2705 Explicit (states) Multi-site \u274c Univariate (current) \u2705 Native multi-site Frequency Annual Annual or Monthly Low-frequency persistence \u2705 Strong \u26a0\ufe0f Depends on state design"},{"location":"algorithms/warm/#usage-examples","title":"Usage Examples","text":""},{"location":"algorithms/warm/#basic-usage","title":"Basic Usage","text":"<pre><code>import pandas as pd\nfrom synhydro.methods.generation.parametric.warm import WARMGenerator\n\n# Load annual streamflow data\nQ_annual = pd.read_csv('annual_flows.csv', index_col=0, parse_dates=True)\n\n# Initialize WARM generator with default parameters\nwarm = WARMGenerator(Q_annual.iloc[:, 0])\n\n# Preprocess\nwarm.preprocessing()\n\n# Fit model to historical data\nwarm.fit()\n\n# Generate 100 realizations of 100 years each\nensemble = warm.generate(n_years=100, n_realizations=100, seed=42)\n\n# Access realizations\nQ_syn_r0 = ensemble.data_by_realization[0]  # First realization\n</code></pre>"},{"location":"algorithms/warm/#custom-parameters","title":"Custom Parameters","text":"<pre><code># Use Mexican Hat wavelet, 32 scales, AR(2) model\nwarm = WARMGenerator(\n    Q_annual,\n    wavelet='mexh',    # Mexican Hat wavelet\n    scales=32,          # 32 frequency scales\n    ar_order=2,         # AR(2) model for temporal persistence\n    debug=True          # Enable debug logging\n)\n\nwarm.preprocessing()\nwarm.fit()\nensemble = warm.generate(n_years=50, n_realizations=50, seed=123)\n</code></pre>"},{"location":"algorithms/warm/#analyzing-sawp","title":"Analyzing SAWP","text":"<pre><code>import matplotlib.pyplot as plt\n\n# Fit model\nwarm = WARMGenerator(Q_annual, scales=64)\nwarm.preprocessing()\nwarm.fit()\n\n# Plot SAWP time series\nplt.figure(figsize=(12, 4))\nplt.plot(warm.Q_obs_annual.index, warm.sawp_)\nplt.xlabel('Year')\nplt.ylabel('SAWP')\nplt.title('Scale Averaged Wavelet Power - Captures Time-Varying Energy')\nplt.grid(True)\nplt.show()\n\n# SAWP reveals periods of high/low variability\n</code></pre>"},{"location":"algorithms/warm/#comparing-wavelets","title":"Comparing Wavelets","text":"<pre><code>wavelets = ['morl', 'mexh', 'gaus4']\n\nfor wavelet in wavelets:\n    warm = WARMGenerator(Q_annual, wavelet=wavelet, scales=32)\n    warm.preprocessing()\n    warm.fit()\n    ensemble = warm.generate(n_years=100, n_realizations=10, seed=42)\n\n    print(f\"\\n{wavelet} wavelet:\")\n    print(f\"  Generated mean: {ensemble.data_by_realization[0].mean().values[0]:.2f}\")\n    print(f\"  Generated std:  {ensemble.data_by_realization[0].std().values[0]:.2f}\")\n</code></pre>"},{"location":"algorithms/warm/#references","title":"References","text":""},{"location":"algorithms/warm/#primary-reference","title":"Primary Reference","text":"<p>Nowak, K., Rajagopalan, B., &amp; Zagona, E. (2011). A Wavelet Auto-Regressive Method (WARM) for multi-site streamflow simulation of data with non-stationary trends. Journal of Hydrology, 410(1-2), 1-12. - https://doi.org/10.1016/j.jhydrol.2011.08.049</p>"},{"location":"algorithms/warm/#related-work","title":"Related Work","text":"<p>Kwon, H.-H., Lall, U., &amp; Khalil, A. F. (2007). Stochastic simulation model for nonstationary time series using an autoregressive wavelet decomposition: Applications to rainfall and temperature. Water Resources Research, 43(5). - Precursor to WARM, introduced wavelet-AR methodology - WARM extends this with SAWP for time-varying power</p> <p>Torrence, C., &amp; Compo, G. P. (1998). A Practical Guide to Wavelet Analysis. Bulletin of the American Meteorological Society, 79(1), 61-78. - Comprehensive guide to wavelet analysis - Foundational reference for continuous wavelet transform</p> <p>Box, G. E. P., Jenkins, G. M., Reinsel, G. C., &amp; Ljung, G. M. (2015). Time Series Analysis: Forecasting and Control (5th ed.). Wiley. - Yule-Walker equations for AR parameter estimation - Theoretical foundation for autoregressive models</p>"},{"location":"algorithms/warm/#software","title":"Software","text":"<p>PyWavelets: Wavelet transforms in Python - https://pywavelets.readthedocs.io/ - Used for continuous wavelet transform (CWT)</p>"},{"location":"algorithms/warm/#version-history","title":"Version History","text":"<ul> <li>v0.0.1 (2024): Initial implementation</li> <li>Univariate (single-site) WARM</li> <li>Morlet, Mexican Hat, Gaussian wavelets supported</li> <li>AR(1) through AR(p) models</li> <li>SAWP-based time-varying power preservation</li> <li>Full test coverage (39 tests)</li> </ul>"},{"location":"algorithms/warm/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Multi-Site Extension</li> <li>Implement VAR (Vector AR) models at each scale</li> <li> <p>Spatial correlation preservation via coupled wavelets</p> </li> <li> <p>Distribution Preservation</p> </li> <li>Optional log-transformation for skewed flows</li> <li> <p>Quantile mapping post-processing</p> </li> <li> <p>Automatic Parameter Selection</p> </li> <li>AIC/BIC for AR order selection</li> <li> <p>Cross-validation for scale selection</p> </li> <li> <p>Monthly/Daily Disaggregation</p> </li> <li>Couple WARM (annual) with K-NN or HMM (monthly/daily)</li> <li> <p>Preserve both annual structure (WARM) and seasonal patterns</p> </li> <li> <p>Computational Optimization</p> </li> <li>Parallel AR fitting across scales</li> <li>GPU-accelerated wavelet transforms for large datasets</li> </ol>"},{"location":"api/core/","title":"Core Data Structures","text":""},{"location":"api/core/#ensemble","title":"Ensemble","text":""},{"location":"api/core/#synhydro.core.ensemble.Ensemble","title":"Ensemble","text":"<pre><code>Ensemble(data: Dict[Union[int, str], DataFrame], metadata: Optional[EnsembleMetadata] = None)\n</code></pre> <p>Manage ensemble timeseries data with dual representations.</p> <p>The Ensemble class stores synthetic timeseries data in two complementary formats:</p> <ol> <li>By Realization: <code>{realization_id: DataFrame[sites \u00d7 time]}</code></li> <li>Keys are realization numbers (int)</li> <li> <p>Values are DataFrames with sites as columns</p> </li> <li> <p>By Site: <code>{site_name: DataFrame[realizations \u00d7 time]}</code></p> </li> <li>Keys are site names (str)</li> <li>Values are DataFrames with realizations as columns</li> </ol> <p>Both representations are maintained automatically and provide efficient access for different analysis workflows.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[Union[int, str], DataFrame]</code> <p>Ensemble data in either format. Structure is automatically detected.</p> required <code>metadata</code> <code>EnsembleMetadata</code> <p>Metadata about the ensemble. If None, creates default metadata.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>data_by_realization</code> <code>Dict[int, DataFrame]</code> <p>Data organized by realization number.</p> <code>data_by_site</code> <code>Dict[str, DataFrame]</code> <p>Data organized by site name.</p> <code>realization_ids</code> <code>List[int]</code> <p>List of all realization IDs.</p> <code>site_names</code> <code>List[str]</code> <p>List of all site names.</p> <code>metadata</code> <code>EnsembleMetadata</code> <p>Ensemble metadata and provenance information.</p> <p>Examples:</p> <p>Create ensemble from generator output:</p> <pre><code>&gt;&gt;&gt; from synhydro import ThomasFieringGenerator, Ensemble\n&gt;&gt;&gt; gen = ThomasFieringGenerator(Q_hist)\n&gt;&gt;&gt; gen.fit()\n&gt;&gt;&gt; Q_syn = gen.generate(n_years=50, n_realizations=100)\n&gt;&gt;&gt; ensemble = Ensemble.from_generator(gen, n_years=50, n_realizations=100)\n</code></pre> <p>Save and load ensemble:</p> <pre><code>&gt;&gt;&gt; ensemble.to_hdf5('synthetic_flows.h5')\n&gt;&gt;&gt; ensemble_loaded = Ensemble.from_hdf5('synthetic_flows.h5')\n</code></pre> <p>Access data by site or realization:</p> <pre><code>&gt;&gt;&gt; site_data = ensemble.data_by_site['site_A']  # All realizations for site A\n&gt;&gt;&gt; real_data = ensemble.data_by_realization[0]  # All sites for realization 0\n</code></pre> <p>Compute statistics:</p> <pre><code>&gt;&gt;&gt; stats = ensemble.summary(by='site')\n&gt;&gt;&gt; percentiles = ensemble.percentile([10, 50, 90], by='site')\n</code></pre> <p>Initialize Ensemble with data and optional metadata.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[Union[int, str], DataFrame]</code> <p>Ensemble data dictionary. Structure is auto-detected.</p> required <code>metadata</code> <code>EnsembleMetadata</code> <p>Metadata about the ensemble.</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If data is not a dictionary.</p> <code>ValueError</code> <p>If data structure cannot be determined.</p>"},{"location":"api/core/#synhydro.core.ensemble.Ensemble.frequency","title":"frequency  <code>property</code>","text":"<pre><code>frequency: Optional[str]\n</code></pre> <p>Get the time frequency/resolution of the ensemble data.</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Time frequency (e.g., 'D', 'MS', 'YS') from metadata.</p>"},{"location":"api/core/#synhydro.core.ensemble.Ensemble.sites","title":"sites  <code>property</code>","text":"<pre><code>sites: List[str]\n</code></pre> <p>Get list of site names (alias for site_names).</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of site names in the ensemble.</p>"},{"location":"api/core/#synhydro.core.ensemble.Ensemble.from_hdf5","title":"from_hdf5  <code>classmethod</code>","text":"<pre><code>from_hdf5(filename: str, realization_subset: Optional[List[int]] = None, stored_by_node: bool = True) -&gt; Ensemble\n</code></pre> <p>Load ensemble from HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to HDF5 file.</p> required <code>realization_subset</code> <code>List[int]</code> <p>Load only specified realizations. If None, loads all.</p> <code>None</code> <code>stored_by_node</code> <code>bool</code> <p>If True, data is stored with sites as top-level groups.</p> <code>True</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>Loaded ensemble object.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ensemble = Ensemble.from_hdf5('synthetic_flows.h5')\n&gt;&gt;&gt; ensemble = Ensemble.from_hdf5('flows.h5', realization_subset=[0, 1, 2])\n</code></pre>"},{"location":"api/core/#synhydro.core.ensemble.Ensemble.to_hdf5","title":"to_hdf5","text":"<pre><code>to_hdf5(filename: str, compression: Optional[str] = 'gzip', stored_by_node: bool = True)\n</code></pre> <p>Save ensemble to HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to output HDF5 file.</p> required <code>compression</code> <code>str</code> <p>Compression algorithm ('gzip', 'lzf', None). Default is 'gzip'.</p> <code>'gzip'</code> <code>stored_by_node</code> <code>bool</code> <p>If True, store data with sites as top-level groups.</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; ensemble.to_hdf5('synthetic_flows.h5')\n&gt;&gt;&gt; ensemble.to_hdf5('flows.h5', compression='lzf')\n</code></pre>"},{"location":"api/core/#synhydro.core.ensemble.Ensemble.from_generator","title":"from_generator  <code>classmethod</code>","text":"<pre><code>from_generator(generator, n_years: int, n_realizations: int, **gen_kwargs) -&gt; Ensemble\n</code></pre> <p>Create ensemble directly from a fitted Generator.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>Generator</code> <p>A fitted generator instance.</p> required <code>n_years</code> <code>int</code> <p>Number of years to generate.</p> required <code>n_realizations</code> <code>int</code> <p>Number of realizations to generate.</p> required <code>**gen_kwargs</code> <p>Additional keyword arguments passed to generator.generate().</p> <code>{}</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>New ensemble with metadata from generator.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from synhydro import ThomasFieringGenerator, Ensemble\n&gt;&gt;&gt; gen = ThomasFieringGenerator(Q_hist)\n&gt;&gt;&gt; gen.fit()\n&gt;&gt;&gt; ensemble = Ensemble.from_generator(gen, n_years=50, n_realizations=100)\n</code></pre>"},{"location":"api/core/#synhydro.core.ensemble.Ensemble.summary","title":"summary","text":"<pre><code>summary(by: str = 'site') -&gt; pd.DataFrame\n</code></pre> <p>Compute statistical summary across realizations or sites.</p> <p>Parameters:</p> Name Type Description Default <code>by</code> <code>(site, realization)</code> <p>Compute statistics by site or by realization.</p> <code>'site'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Summary statistics (mean, std, min, max) for each site or realization.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; stats = ensemble.summary(by='site')\n&gt;&gt;&gt; print(stats)\n</code></pre>"},{"location":"api/core/#synhydro.core.ensemble.Ensemble.percentile","title":"percentile","text":"<pre><code>percentile(q: Union[float, List[float]], by: str = 'site') -&gt; Dict[str, pd.DataFrame]\n</code></pre> <p>Compute percentiles across realizations.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>float or List[float]</code> <p>Percentile(s) to compute (0-100).</p> required <code>by</code> <code>(site, realization)</code> <p>Compute percentiles by site or realization.</p> <code>'site'</code> <p>Returns:</p> Type Description <code>Dict[str, DataFrame]</code> <p>Dictionary mapping site/realization to DataFrame of percentiles over time.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; p = ensemble.percentile([10, 50, 90], by='site')\n&gt;&gt;&gt; site_a_percentiles = p['site_A']\n</code></pre>"},{"location":"api/core/#synhydro.core.ensemble.Ensemble.subset","title":"subset","text":"<pre><code>subset(sites: Optional[List[str]] = None, realizations: Optional[List[int]] = None, start_date: Optional[str] = None, end_date: Optional[str] = None) -&gt; Ensemble\n</code></pre> <p>Create subset of ensemble by sites, realizations, or time period.</p> <p>Parameters:</p> Name Type Description Default <code>sites</code> <code>List[str]</code> <p>Site names to include.</p> <code>None</code> <code>realizations</code> <code>List[int]</code> <p>Realization IDs to include.</p> <code>None</code> <code>start_date</code> <code>str</code> <p>Start date (ISO format or pandas-parseable).</p> <code>None</code> <code>end_date</code> <code>str</code> <p>End date (ISO format or pandas-parseable).</p> <code>None</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>New ensemble containing only the subset.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; subset = ensemble.subset(sites=['site_A', 'site_B'],\n...                          start_date='2000-01-01',\n...                          end_date='2010-12-31')\n</code></pre>"},{"location":"api/core/#synhydro.core.ensemble.Ensemble.resample","title":"resample","text":"<pre><code>resample(freq: str) -&gt; Ensemble\n</code></pre> <p>Resample time series to different frequency.</p> <p>Parameters:</p> Name Type Description Default <code>freq</code> <code>str</code> <p>Pandas frequency string ('D', 'W', 'MS', 'AS', etc.).</p> required <p>Returns:</p> Type Description <code>Ensemble</code> <p>New ensemble with resampled data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; monthly_ensemble = daily_ensemble.resample('MS')\n</code></pre>"},{"location":"api/core/#ensemblemetadata","title":"EnsembleMetadata","text":""},{"location":"api/core/#synhydro.core.ensemble.EnsembleMetadata","title":"EnsembleMetadata  <code>dataclass</code>","text":"<pre><code>EnsembleMetadata(generator_class: Optional[str] = None, generator_params: Optional[Dict[str, Any]] = None, creation_timestamp: str = (lambda: datetime.now().isoformat())(), n_realizations: int = 0, n_sites: int = 0, time_resolution: Optional[str] = None, time_period: Optional[Tuple[str, str]] = None, description: Optional[str] = None, custom_attrs: Optional[Dict[str, Any]] = dict())\n</code></pre> <p>Store metadata about an ensemble.</p> <p>Attributes:</p> Name Type Description <code>generator_class</code> <code>(str, optional)</code> <p>Name of the generator class that created this ensemble.</p> <code>generator_params</code> <code>(Dict, optional)</code> <p>Parameters used to configure the generator.</p> <code>creation_timestamp</code> <code>str</code> <p>ISO format timestamp of when ensemble was created.</p> <code>n_realizations</code> <code>int</code> <p>Number of realizations in the ensemble.</p> <code>n_sites</code> <code>int</code> <p>Number of sites/locations in the ensemble.</p> <code>time_resolution</code> <code>(str, optional)</code> <p>Time resolution of data ('daily', 'monthly', etc.).</p> <code>time_period</code> <code>(Tuple[str, str], optional)</code> <p>Start and end dates of time series (ISO format strings).</p> <code>description</code> <code>(str, optional)</code> <p>User-provided description of the ensemble.</p> <code>custom_attrs</code> <code>(Dict, optional)</code> <p>Additional user-defined metadata attributes.</p>"},{"location":"api/core/#synhydro.core.ensemble.EnsembleMetadata.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert metadata to dictionary.</p>"},{"location":"api/core/#parameter-containers","title":"Parameter Containers","text":""},{"location":"api/core/#synhydro.core.base.FittedParams","title":"FittedParams  <code>dataclass</code>","text":"<pre><code>FittedParams(means_: Optional[Union[Series, DataFrame]] = None, stds_: Optional[Union[Series, DataFrame]] = None, correlations_: Optional[Union[ndarray, Dict[str, ndarray]]] = None, distributions_: Optional[Dict[str, Any]] = None, transformations_: Optional[Dict[str, Any]] = None, fitted_models_: Optional[Dict[str, Any]] = None, n_parameters_: int = 0, sample_size_: int = 0, n_sites_: int = 0, training_period_: Optional[Tuple[str, str]] = None)\n</code></pre> <p>Store parameters learned from data during fit().</p> <p>Following scikit-learn convention, parameter names end with underscore.</p>"},{"location":"api/core/#synhydro.core.base.FittedParams.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to dictionary, handling numpy/pandas types.</p>"},{"location":"api/core/#synhydro.core.base.GeneratorState","title":"GeneratorState  <code>dataclass</code>","text":"<pre><code>GeneratorState(is_preprocessed: bool = False, is_fitted: bool = False, preprocessing_params: Dict[str, Any] = dict(), fit_params: Dict[str, Any] = dict(), fit_timestamp: Optional[str] = None)\n</code></pre> <p>Track generator preprocessing and fitting state.</p>"},{"location":"api/core/#synhydro.core.base.GeneratorParams","title":"GeneratorParams  <code>dataclass</code>","text":"<pre><code>GeneratorParams(random_seed: Optional[int] = None, verbose: bool = False, debug: bool = False, algorithm_params: Dict[str, Any] = dict(), transformation_params: Dict[str, Any] = dict(), computational_params: Dict[str, Any] = dict())\n</code></pre> <p>Store initialization/configuration parameters for generators.</p> <p>These are user-specified settings that control algorithm behavior, not learned from data.</p>"},{"location":"api/core/#synhydro.core.base.GeneratorParams.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert to flat dictionary.</p>"},{"location":"api/disaggregators/","title":"Disaggregators &amp; Pipelines","text":""},{"location":"api/disaggregators/#base-class","title":"Base Class","text":""},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator","title":"Disaggregator","text":"<pre><code>Disaggregator(Q_obs: Union[Series, DataFrame], name: Optional[str] = None, debug: bool = False)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for all temporal disaggregation methods.</p> <p>Disaggregators transform synthetic flows from one temporal resolution to a finer resolution (e.g., monthly to daily).</p> <p>All disaggregator implementations should inherit from this class.</p> <p>Initialize the disaggregator base class.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>Series or DataFrame</code> <p>Observed historical flow data used to train disaggregation patterns. Should be at the finer temporal resolution (output resolution).</p> required <code>name</code> <code>str</code> <p>Name identifier for this disaggregator instance</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging</p> <code>False</code>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.is_fitted","title":"is_fitted  <code>property</code>","text":"<pre><code>is_fitted: bool\n</code></pre> <p>Check if disaggregator is fitted.</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.is_preprocessed","title":"is_preprocessed  <code>property</code>","text":"<pre><code>is_preprocessed: bool\n</code></pre> <p>Check if preprocessing is complete.</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.n_sites","title":"n_sites  <code>property</code>","text":"<pre><code>n_sites: int\n</code></pre> <p>Number of sites in the disaggregator.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of sites.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If preprocessing not yet run.</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.sites","title":"sites  <code>property</code>","text":"<pre><code>sites: List[str]\n</code></pre> <p>List of site names.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>Site identifiers.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If preprocessing not yet run.</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.input_frequency","title":"input_frequency  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>input_frequency: str\n</code></pre> <p>Expected temporal frequency of input ensemble.</p> <p>Returns:</p> Type Description <code>str</code> <p>Pandas frequency string (e.g., 'MS' for monthly, 'W' for weekly).</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.output_frequency","title":"output_frequency  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>output_frequency: str\n</code></pre> <p>Temporal frequency of disaggregated output.</p> <p>Returns:</p> Type Description <code>str</code> <p>Pandas frequency string (e.g., 'D' for daily, 'H' for hourly).</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.validate_input_data","title":"validate_input_data","text":"<pre><code>validate_input_data(data: Union[Series, DataFrame]) -&gt; pd.DataFrame\n</code></pre> <p>Validate and standardize input data format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Series or DataFrame</code> <p>Input time series data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Validated and standardized data</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid</p> <code>TypeError</code> <p>If data type is unsupported</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.validate_preprocessing","title":"validate_preprocessing","text":"<pre><code>validate_preprocessing() -&gt; None\n</code></pre> <p>Check if preprocessing has been completed.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If preprocessing() has not been run.</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.validate_fit","title":"validate_fit","text":"<pre><code>validate_fit() -&gt; None\n</code></pre> <p>Check if disaggregator has been fitted.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If fit() has not been run.</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.update_state","title":"update_state","text":"<pre><code>update_state(preprocessed: Optional[bool] = None, fitted: Optional[bool] = None) -&gt; None\n</code></pre> <p>Update disaggregator state flags.</p> <p>Parameters:</p> Name Type Description Default <code>preprocessed</code> <code>bool</code> <p>Set preprocessing state.</p> <code>None</code> <code>fitted</code> <code>bool</code> <p>Set fitted state.</p> <code>None</code>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.validate_input_ensemble","title":"validate_input_ensemble","text":"<pre><code>validate_input_ensemble(ensemble: Ensemble) -&gt; None\n</code></pre> <p>Validate that input ensemble is compatible with disaggregator.</p> <p>Checks temporal frequency and site consistency.</p> <p>Parameters:</p> Name Type Description Default <code>ensemble</code> <code>Ensemble</code> <p>Input ensemble to validate</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If ensemble is incompatible with disaggregator</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.get_params","title":"get_params","text":"<pre><code>get_params(deep: bool = True) -&gt; Dict[str, Any]\n</code></pre> <p>Get initialization parameters (scikit-learn style).</p> <p>Returns only constructor/configuration parameters, not fitted values.</p> <p>Parameters:</p> Name Type Description Default <code>deep</code> <code>bool</code> <p>If True, return deep copy of parameters.</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of initialization parameters.</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.get_fitted_params","title":"get_fitted_params","text":"<pre><code>get_fitted_params() -&gt; Dict[str, Any]\n</code></pre> <p>Get parameters learned from data during fit().</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of fitted parameters (all keys end with underscore).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If disaggregator has not been fitted yet.</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.summary","title":"summary","text":"<pre><code>summary(show_fitted: bool = True) -&gt; str\n</code></pre> <p>Generate comprehensive summary of disaggregator configuration and fit.</p> <p>Parameters:</p> Name Type Description Default <code>show_fitted</code> <code>bool</code> <p>Whether to include fitted parameters in summary.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted summary string.</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.save","title":"save","text":"<pre><code>save(filepath: str) -&gt; None\n</code></pre> <p>Save fitted disaggregator to file using pickle.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to save the disaggregator.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If disaggregator is not fitted.</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(filepath: str) -&gt; Disaggregator\n</code></pre> <p>Load fitted disaggregator from file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to saved disaggregator file.</p> required <p>Returns:</p> Type Description <code>Disaggregator</code> <p>Loaded disaggregator instance.</p>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.preprocessing","title":"preprocessing  <code>abstractmethod</code>","text":"<pre><code>preprocessing(**kwargs: Any) -&gt; None\n</code></pre> <p>Preprocess and validate observed flow data.</p> <p>Implementations should: 1. Call validate_input_data() to validate self._Q_obs_raw 2. Store preprocessed data as instance attributes 3. Call update_state(preprocessed=True) at end</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Additional preprocessing parameters.</p> <code>{}</code>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.fit","title":"fit  <code>abstractmethod</code>","text":"<pre><code>fit(**kwargs: Any) -&gt; None\n</code></pre> <p>Fit the disaggregator to observed flow data.</p> <p>Implementations should: 1. Call validate_preprocessing() at start 2. Learn disaggregation patterns from historic data 3. Store fitted parameters as instance attributes 4. Call update_state(fitted=True) at end</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Additional fitting parameters.</p> <code>{}</code>"},{"location":"api/disaggregators/#synhydro.core.base.Disaggregator.disaggregate","title":"disaggregate  <code>abstractmethod</code>","text":"<pre><code>disaggregate(ensemble: Ensemble, **kwargs: Any) -&gt; Ensemble\n</code></pre> <p>Disaggregate synthetic flows from coarser to finer temporal resolution.</p> <p>Implementations should: 1. Call validate_fit() at start 2. Call validate_input_ensemble() to check compatibility 3. Disaggregate each realization in the ensemble 4. Return new Ensemble with finer temporal resolution</p> <p>Parameters:</p> Name Type Description Default <code>ensemble</code> <code>Ensemble</code> <p>Input ensemble at coarser temporal resolution</p> required <code>**kwargs</code> <code>Any</code> <p>Additional disaggregation parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>Disaggregated ensemble at finer temporal resolution</p>"},{"location":"api/disaggregators/#nowakdisaggregator","title":"NowakDisaggregator","text":""},{"location":"api/disaggregators/#synhydro.methods.disaggregation.temporal.nowak.NowakDisaggregator","title":"NowakDisaggregator","text":"<pre><code>NowakDisaggregator(Q_obs, n_neighbors=5, max_month_shift=7, name=None, debug=False)\n</code></pre> <p>               Bases: <code>Disaggregator</code></p> <p>Temporal disaggregation from monthly to daily as described in Nowak et al. (2010).</p> <p>Supports both single-site and multisite disaggregation from monthly to daily streamflows.</p> <p>For each month in synthetic data, finds the N historic monthly flow profiles which have similar total flow at the index gauge (sum of all sites).</p> <p>Then, randomly selects one of the N profiles and uses the daily flow proportions from that month to disaggregate the synthetic monthly flow at all sites.</p> <p>When disaggregating a month, only considers historic profiles from the same month of interest, with +/- max_month_shift days around each month.</p> References <p>Nowak, K., Prairie, J., Rajagopalan, B., &amp; Lall, U. (2010). A nonparametric stochastic approach for multisite disaggregation of annual to daily streamflow. Water Resources Research, 46(8).</p> <p>Initialize the Nowak Disaggregator.</p> <p>Supports both single site (Series) and multi-site (DataFrame) disaggregation.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>Series or DataFrame</code> <p>Daily streamflow data for the historic period. Must have DatetimeIndex with daily frequency. If DataFrame, columns represent different sites.</p> required <code>n_neighbors</code> <code>int</code> <p>Number of K-nearest neighbors to consider for disaggregation.</p> <code>5</code> <code>max_month_shift</code> <code>int</code> <p>Maximum number of days to shift around each month center when creating historic monthly flow profiles.</p> <code>7</code> <code>name</code> <code>str</code> <p>Name for this disaggregator instance.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code>"},{"location":"api/disaggregators/#synhydro.methods.disaggregation.temporal.nowak.NowakDisaggregator.input_frequency","title":"input_frequency  <code>property</code>","text":"<pre><code>input_frequency: str\n</code></pre> <p>Nowak disaggregator expects monthly input.</p>"},{"location":"api/disaggregators/#synhydro.methods.disaggregation.temporal.nowak.NowakDisaggregator.output_frequency","title":"output_frequency  <code>property</code>","text":"<pre><code>output_frequency: str\n</code></pre> <p>Nowak disaggregator produces daily output.</p>"},{"location":"api/disaggregators/#synhydro.methods.disaggregation.temporal.nowak.NowakDisaggregator.preprocessing","title":"preprocessing","text":"<pre><code>preprocessing(**kwargs)\n</code></pre> <p>Preprocess observed daily flow data.</p> <p>Validates input data and detects single-site vs multisite configuration.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional preprocessing parameters (currently unused).</p> <code>{}</code>"},{"location":"api/disaggregators/#synhydro.methods.disaggregation.temporal.nowak.NowakDisaggregator.fit","title":"fit","text":"<pre><code>fit(**kwargs)\n</code></pre> <p>Fit the Nowak Disaggregator to the data.</p> <p>Creates a dataset of candidate monthly flow profiles for each month, and trains KNN models for each month.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional fitting parameters (currently unused).</p> <code>{}</code>"},{"location":"api/disaggregators/#synhydro.methods.disaggregation.temporal.nowak.NowakDisaggregator.disaggregate","title":"disaggregate","text":"<pre><code>disaggregate(ensemble: Ensemble, n_neighbors=None, sample_method='distance_weighted', **kwargs) -&gt; Ensemble\n</code></pre> <p>Disaggregate monthly ensemble to daily flows using the Nowak method.</p> <p>Parameters:</p> Name Type Description Default <code>ensemble</code> <code>Ensemble</code> <p>Monthly streamflow ensemble to disaggregate. Must have frequency 'MS' (monthly start).</p> required <code>n_neighbors</code> <code>int</code> <p>Number of neighbors to use for disaggregation. If None, uses the value from initialization.</p> <code>None</code> <code>sample_method</code> <code>str</code> <p>Method to use for sampling the K nearest neighbors.</p> <code>'distance_weighted'</code> <code>**kwargs</code> <p>Additional disaggregation parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>Disaggregated daily streamflow ensemble.</p>"},{"location":"api/disaggregators/#synhydro.methods.disaggregation.temporal.nowak.NowakDisaggregator.find_knn_indices","title":"find_knn_indices","text":"<pre><code>find_knn_indices(Qs_monthly_array, month, n_neighbors=None)\n</code></pre> <p>Given cumulative monthly flow values, find the K nearest neighbors from the historic dataset.</p> <p>Parameters:</p> Name Type Description Default <code>Qs_monthly_array</code> <code>array</code> <p>The cumulative monthly flow values for the month to disaggregate.</p> required <code>month</code> <code>int</code> <p>The calendar month which is being disaggregated (1-12).</p> required <code>n_neighbors</code> <code>int</code> <p>The number of neighbors to find.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>distances</code> <code>array</code> <p>The distances to the K nearest neighbors.</p> <code>indices</code> <code>array</code> <p>The indices of the K nearest neighbors in the historic dataset.</p>"},{"location":"api/disaggregators/#synhydro.methods.disaggregation.temporal.nowak.NowakDisaggregator.sample_knn_monthly_flows","title":"sample_knn_monthly_flows","text":"<pre><code>sample_knn_monthly_flows(Qs_monthly_array, month, n_neighbors=None, sample_method='distance_weighted')\n</code></pre> <p>Given cumulative monthly flow values, sample K nearest neighbors from the historic dataset.</p> <p>Parameters:</p> Name Type Description Default <code>Qs_monthly_array</code> <code>array</code> <p>The cumulative monthly flow values for the month to disaggregate.</p> required <code>month</code> <code>int</code> <p>The calendar month which is being disaggregated (1-12).</p> required <code>n_neighbors</code> <code>int</code> <p>The number of neighbors to sample.</p> <code>None</code> <code>sample_method</code> <code>str</code> <p>The sampling method to use.</p> <code>'distance_weighted'</code> <p>Returns:</p> Name Type Description <code>sampled_indices</code> <code>array</code> <p>The sampled indices from the historic dataset.</p>"},{"location":"api/disaggregators/#synhydro.methods.disaggregation.temporal.nowak.NowakDisaggregator.disaggregate_monthly_flows","title":"disaggregate_monthly_flows","text":"<pre><code>disaggregate_monthly_flows(Qs_monthly, n_neighbors=None, sample_method='distance_weighted')\n</code></pre> <p>Disaggregate monthly to daily flows using the Nowak method.</p> <p>Parameters:</p> Name Type Description Default <code>Qs_monthly</code> <code>Series or DataFrame</code> <p>Monthly streamflow data for the synthetic period.  The index should be a datetime index. For multisite, should be DataFrame with same columns as historic data.</p> required <code>n_neighbors</code> <code>int</code> <p>The number of neighbors to use for disaggregation.</p> <code>None</code> <code>sample_method</code> <code>str</code> <p>The method to use for sampling the K nearest neighbors.</p> <code>'distance_weighted'</code> <p>Returns:</p> Name Type Description <code>Qs_daily</code> <code>Series or DataFrame</code> <p>Daily streamflow data for the synthetic period.  The index will be a datetime index. For multisite, returns DataFrame with same columns as input.</p>"},{"location":"api/disaggregators/#pipelines","title":"Pipelines","text":""},{"location":"api/disaggregators/#synhydro.core.pipeline.GeneratorDisaggregatorPipeline","title":"GeneratorDisaggregatorPipeline","text":"<pre><code>GeneratorDisaggregatorPipeline(generator: Generator, disaggregator: Disaggregator, name: Optional[str] = None, debug: bool = False)\n</code></pre> <p>Pipeline for composing a generator with a disaggregator.</p> <p>This class orchestrates the flow from generation to disaggregation, ensuring compatibility between components and managing the complete workflow.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>Generator</code> <p>A fitted or unfitted generator instance.</p> required <code>disaggregator</code> <code>Disaggregator</code> <p>A fitted or unfitted disaggregator instance.</p> required <code>name</code> <code>str</code> <p>Name for this pipeline instance.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from synhydro.methods.generate.nonparametric.kirsch import KirschGenerator\n&gt;&gt;&gt; from synhydro.methods.disaggregate.temporal.nowak import NowakDisaggregator\n&gt;&gt;&gt; from synhydro.core.pipeline import GeneratorDisaggregatorPipeline\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create components\n&gt;&gt;&gt; generator = KirschGenerator(Q_daily)\n&gt;&gt;&gt; disaggregator = NowakDisaggregator(Q_daily)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create pipeline\n&gt;&gt;&gt; pipeline = GeneratorDisaggregatorPipeline(generator, disaggregator)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Fit and generate\n&gt;&gt;&gt; pipeline.preprocessing()\n&gt;&gt;&gt; pipeline.fit()\n&gt;&gt;&gt; daily_ensemble = pipeline.generate(n_realizations=10, n_years=50)\n</code></pre> <p>Initialize the pipeline with generator and disaggregator components.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>Generator</code> <p>Generator instance for producing synthetic flows.</p> required <code>disaggregator</code> <code>Disaggregator</code> <p>Disaggregator instance for temporal disaggregation.</p> required <code>name</code> <code>str</code> <p>Name for this pipeline.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If components are not proper Generator/Disaggregator instances.</p> <code>ValueError</code> <p>If generator output frequency doesn't match disaggregator input frequency.</p>"},{"location":"api/disaggregators/#synhydro.core.pipeline.GeneratorDisaggregatorPipeline.is_preprocessed","title":"is_preprocessed  <code>property</code>","text":"<pre><code>is_preprocessed: bool\n</code></pre> <p>Check if both components are preprocessed.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if both generator and disaggregator are preprocessed.</p>"},{"location":"api/disaggregators/#synhydro.core.pipeline.GeneratorDisaggregatorPipeline.is_fitted","title":"is_fitted  <code>property</code>","text":"<pre><code>is_fitted: bool\n</code></pre> <p>Check if both components are fitted.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if both generator and disaggregator are fitted.</p>"},{"location":"api/disaggregators/#synhydro.core.pipeline.GeneratorDisaggregatorPipeline.output_frequency","title":"output_frequency  <code>property</code>","text":"<pre><code>output_frequency: str\n</code></pre> <p>Get the final output frequency of the pipeline.</p> <p>Returns:</p> Type Description <code>str</code> <p>Pandas frequency string (e.g., 'D' for daily).</p>"},{"location":"api/disaggregators/#synhydro.core.pipeline.GeneratorDisaggregatorPipeline.validate_compatibility","title":"validate_compatibility","text":"<pre><code>validate_compatibility() -&gt; None\n</code></pre> <p>Validate that generator and disaggregator are compatible.</p> <p>Checks that the generator's output frequency matches the disaggregator's input frequency.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If frequencies are incompatible.</p>"},{"location":"api/disaggregators/#synhydro.core.pipeline.GeneratorDisaggregatorPipeline.preprocessing","title":"preprocessing","text":"<pre><code>preprocessing(**kwargs) -&gt; None\n</code></pre> <p>Preprocess both generator and disaggregator.</p> <p>Calls preprocessing() on both components in sequence.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional preprocessing parameters passed to both components.</p> <code>{}</code>"},{"location":"api/disaggregators/#synhydro.core.pipeline.GeneratorDisaggregatorPipeline.fit","title":"fit","text":"<pre><code>fit(**kwargs) -&gt; None\n</code></pre> <p>Fit both generator and disaggregator.</p> <p>Calls fit() on both components in sequence. Validates that preprocessing has been completed first.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional fitting parameters passed to both components.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If preprocessing has not been completed.</p>"},{"location":"api/disaggregators/#synhydro.core.pipeline.GeneratorDisaggregatorPipeline.generate","title":"generate","text":"<pre><code>generate(n_realizations: int = 1, n_years: Optional[int] = None, n_timesteps: Optional[int] = None, seed: Optional[int] = None, **kwargs) -&gt; Ensemble\n</code></pre> <p>Generate and disaggregate synthetic flows through the pipeline.</p> <p>This method orchestrates the complete workflow: 1. Generate monthly (or other coarse) synthetic flows using the generator 2. Disaggregate to finer temporal resolution using the disaggregator 3. Return the final ensemble</p> <p>Parameters:</p> Name Type Description Default <code>n_realizations</code> <code>int</code> <p>Number of synthetic realizations to generate.</p> <code>1</code> <code>n_years</code> <code>int</code> <p>Number of years to generate.</p> <code>None</code> <code>n_timesteps</code> <code>int</code> <p>Number of timesteps to generate explicitly.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>None</code> <code>**kwargs</code> <p>Additional parameters passed to generator and disaggregator.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>Final disaggregated ensemble at the output frequency.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If pipeline has not been fitted.</p>"},{"location":"api/disaggregators/#synhydro.core.pipeline.GeneratorDisaggregatorPipeline.summary","title":"summary","text":"<pre><code>summary() -&gt; str\n</code></pre> <p>Generate a summary of the pipeline configuration and status.</p> <p>Returns:</p> Type Description <code>str</code> <p>Formatted summary string.</p>"},{"location":"api/disaggregators/#synhydro.core.pipeline.GeneratorDisaggregatorPipeline.save","title":"save","text":"<pre><code>save(filepath: str) -&gt; None\n</code></pre> <p>Save the entire pipeline to file.</p> <p>Saves both the generator and disaggregator, preserving their fitted state.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to save the pipeline.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If pipeline is not fitted.</p>"},{"location":"api/disaggregators/#synhydro.core.pipeline.GeneratorDisaggregatorPipeline.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(filepath: str) -&gt; GeneratorDisaggregatorPipeline\n</code></pre> <p>Load a pipeline from file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to saved pipeline file.</p> required <p>Returns:</p> Type Description <code>GeneratorDisaggregatorPipeline</code> <p>Loaded pipeline instance.</p>"},{"location":"api/disaggregators/#kirschnowakpipeline","title":"KirschNowakPipeline","text":""},{"location":"api/disaggregators/#synhydro.pipelines.prebuilt.KirschNowakPipeline","title":"KirschNowakPipeline","text":"<pre><code>KirschNowakPipeline(Q_obs: DataFrame, generate_using_log_flow: bool = True, matrix_repair_method: str = 'spectral', n_neighbors: int = 5, max_month_shift: int = 7, name: Optional[str] = None, debug: bool = False)\n</code></pre> <p>               Bases: <code>GeneratorDisaggregatorPipeline</code></p> <p>Pre-configured pipeline combining Kirsch generator with Nowak disaggregator.</p> <p>This pipeline generates monthly synthetic flows using the Kirsch nonparametric bootstrap method, then disaggregates them to daily flows using the Nowak KNN-based temporal disaggregation method.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>DataFrame</code> <p>Daily observed streamflow data with DatetimeIndex. Used to train both the generator (aggregated to monthly) and disaggregator (used as daily).</p> required <code>generate_using_log_flow</code> <code>bool</code> <p>Whether to generate in log-space (Kirsch parameter).</p> <code>True</code> <code>matrix_repair_method</code> <code>str</code> <p>Method for repairing correlation matrices (Kirsch parameter).</p> <code>'spectral'</code> <code>n_neighbors</code> <code>int</code> <p>Number of KNN neighbors for disaggregation (Nowak parameter).</p> <code>5</code> <code>max_month_shift</code> <code>int</code> <p>Maximum day shift for monthly profiles (Nowak parameter).</p> <code>7</code> <code>name</code> <code>str</code> <p>Name for this pipeline instance.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from synhydro.pipelines import KirschNowakPipeline\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load daily historic flows\n&gt;&gt;&gt; Q_daily = pd.read_csv('daily_flows.csv', index_col=0, parse_dates=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create pipeline\n&gt;&gt;&gt; pipeline = KirschNowakPipeline(Q_daily)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Fit and generate\n&gt;&gt;&gt; pipeline.preprocessing()\n&gt;&gt;&gt; pipeline.fit()\n&gt;&gt;&gt; daily_ensemble = pipeline.generate(n_realizations=100, n_years=50)\n</code></pre> Notes <p>This pipeline is equivalent to creating: <pre><code>generator = KirschGenerator(Q_obs, generate_using_log_flow=True)\ndisaggregator = NowakDisaggregator(Q_obs, n_neighbors=5)\npipeline = GeneratorDisaggregatorPipeline(generator, disaggregator)\n</code></pre></p> References <p>Kirsch generator: Nonparametric bootstrap with correlation preservation Nowak disaggregator: KNN-based temporal disaggregation (Nowak et al., 2010)</p> <p>Initialize the Kirsch-Nowak pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>DataFrame</code> <p>Daily observed streamflow data.</p> required <code>generate_using_log_flow</code> <code>bool</code> <p>Generate in log-space for Kirsch.</p> <code>True</code> <code>matrix_repair_method</code> <code>str</code> <p>Correlation matrix repair method for Kirsch.</p> <code>'spectral'</code> <code>n_neighbors</code> <code>int</code> <p>Number of KNN neighbors for Nowak.</p> <code>5</code> <code>max_month_shift</code> <code>int</code> <p>Day shift for Nowak monthly profiles.</p> <code>7</code> <code>name</code> <code>str</code> <p>Pipeline name.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code>"},{"location":"api/disaggregators/#thomasfieringnowakpipeline","title":"ThomasFieringNowakPipeline","text":""},{"location":"api/disaggregators/#synhydro.pipelines.prebuilt.ThomasFieringNowakPipeline","title":"ThomasFieringNowakPipeline","text":"<pre><code>ThomasFieringNowakPipeline(Q_obs, n_neighbors: int = 5, max_month_shift: int = 7, name: Optional[str] = None, debug: bool = False)\n</code></pre> <p>               Bases: <code>GeneratorDisaggregatorPipeline</code></p> <p>Pre-configured pipeline combining Thomas-Fiering generator with Nowak disaggregator.</p> <p>This pipeline generates monthly synthetic flows using the Thomas-Fiering AR(1) parametric method with Stedinger-Taylor normalization, then disaggregates them to daily flows using the Nowak KNN-based temporal disaggregation method.</p> <p>Note: Thomas-Fiering is a univariate method, so only single-site generation is supported. For multisite, use KirschNowakPipeline instead.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>Series or DataFrame</code> <p>Daily observed streamflow data with DatetimeIndex. If DataFrame, only the first column is used (Thomas-Fiering is univariate). Used to train both the generator (aggregated to monthly) and disaggregator (used as daily).</p> required <code>n_neighbors</code> <code>int</code> <p>Number of KNN neighbors for disaggregation (Nowak parameter).</p> <code>5</code> <code>max_month_shift</code> <code>int</code> <p>Maximum day shift for monthly profiles (Nowak parameter).</p> <code>7</code> <code>name</code> <code>str</code> <p>Name for this pipeline instance.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from synhydro.pipelines import ThomasFieringNowakPipeline\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load daily historic flows (single site)\n&gt;&gt;&gt; Q_daily = pd.read_csv('daily_flows.csv', index_col=0, parse_dates=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Create pipeline\n&gt;&gt;&gt; pipeline = ThomasFieringNowakPipeline(Q_daily['site_1'])\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Fit and generate\n&gt;&gt;&gt; pipeline.preprocessing()\n&gt;&gt;&gt; pipeline.fit()\n&gt;&gt;&gt; daily_ensemble = pipeline.generate(n_realizations=100, n_years=50)\n</code></pre> Notes <p>This pipeline is equivalent to creating: <pre><code>generator = ThomasFieringGenerator(Q_obs)\ndisaggregator = NowakDisaggregator(Q_obs, n_neighbors=5)\npipeline = GeneratorDisaggregatorPipeline(generator, disaggregator)\n</code></pre></p> References <p>Thomas-Fiering: AR(1) with Stedinger-Taylor normalization Nowak disaggregator: KNN-based temporal disaggregation (Nowak et al., 2010)</p> <p>Initialize the Thomas-Fiering-Nowak pipeline.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>Series or DataFrame</code> <p>Daily observed streamflow data. If DataFrame with multiple columns, only the first column is used (Thomas-Fiering is univariate).</p> required <code>n_neighbors</code> <code>int</code> <p>Number of KNN neighbors for Nowak.</p> <code>5</code> <code>max_month_shift</code> <code>int</code> <p>Day shift for Nowak monthly profiles.</p> <code>7</code> <code>name</code> <code>str</code> <p>Pipeline name.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code>"},{"location":"api/drought/","title":"Drought Metrics","text":""},{"location":"api/drought/#ssidroughtmetrics","title":"SSIDroughtMetrics","text":""},{"location":"api/drought/#synhydro.droughts.ssi.SSIDroughtMetrics","title":"SSIDroughtMetrics","text":"<pre><code>SSIDroughtMetrics(timescale: str = 'M', window: int = 12, dist: Union[str, ContinuousDist] = 'gamma', data=None)\n</code></pre> <p>Class to calculate and store drought metrics based on the Standardized Streamflow Index (SSI).</p> <p>Attributes:     timescale (str): Temporal scale ('D' for daily, 'M' for monthly).     window (int): Rolling window size for aggregation.     dist (ContinuousDist): Probability distribution for SSI calculation (default: gamma).     ssi (pd.Series): Series of SSI values.     drought_metrics (pd.DataFrame): DataFrame containing drought metrics.</p> <p>Initialize the SSIDroughtMetrics class.</p> <p>Parameters:</p> Name Type Description Default <code>timescale</code> <code>str</code> <p>Temporal scale: 'D' for daily, 'M' for monthly.</p> <code>'M'</code> <code>window</code> <code>int</code> <p>Rolling window size for aggregation before SSI calculation.</p> <code>12</code> <code>dist</code> <code>str or ContinuousDist</code> <p>Probability distribution to use for SSI calculation. Can be string name from registry or scipy distribution object. Common string options: 'gamma', 'lognorm', 'pearson3', 'weibull' Or pass scipy object directly: scs.gamma, scs.lognorm, etc.</p> <code>'gamma'</code> <code>data</code> <code>Series or DataFrame</code> <p>Initial data to set.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Using string name (recommended)\n&gt;&gt;&gt; ssi = SSIDroughtMetrics(dist='gamma')\n&gt;&gt;&gt; # Using scipy object directly\n&gt;&gt;&gt; import scipy.stats as scs\n&gt;&gt;&gt; ssi = SSIDroughtMetrics(dist=scs.lognorm)\n</code></pre>"},{"location":"api/drought/#synhydro.droughts.ssi.SSIDroughtMetrics.calculate_ssi","title":"calculate_ssi","text":"<pre><code>calculate_ssi(data=None)\n</code></pre> <p>Calculate the Standardized Streamflow Index (SSI).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Series or DataFrame</code> <p>Data to calculate SSI for. If None, uses previously set data.</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>SSI values.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no data is provided and no data was previously set.</p>"},{"location":"api/drought/#ssi","title":"SSI","text":""},{"location":"api/drought/#synhydro.droughts.ssi.SSI","title":"SSI  <code>dataclass</code>","text":"<pre><code>SSI(dist: Union[str, ContinuousDist] = 'gamma', timescale: int = 12, fit_freq: str | None = None, fit_window: int = 0, prob_zero: bool = False, normal_scores_transform: bool = False, agg_func: Literal['sum', 'mean'] = 'sum')\n</code></pre> <p>Independent SSI calculator that separates training and scoring phases.</p> <p>Uses the original spei.SI class internally for distribution fitting, then applies those fitted distributions to new data.</p> <p>Parameters:</p> Name Type Description Default <code>dist</code> <code>str or ContinuousDist</code> <p>Probability distribution for SSI calculation. Can be string name: 'gamma', 'lognorm', 'pearson3', 'weibull', etc. Or scipy distribution object.</p> <code>'gamma'</code> <code>timescale</code> <code>int</code> <p>Rolling window size for temporal aggregation.</p> <code>12</code> <code>fit_freq</code> <code>str</code> <p>Frequency for seasonal fitting ('M' for monthly, 'D' for daily). If None, fits single distribution to entire dataset.</p> <code>None</code> <code>fit_window</code> <code>int</code> <p>Moving window for distribution fitting.</p> <code>0</code> <code>prob_zero</code> <code>bool</code> <p>Whether to handle zero probability separately.</p> <code>False</code> <code>normal_scores_transform</code> <code>bool</code> <p>Whether to use normal scores transform instead of parametric fitting.</p> <code>False</code> <code>agg_func</code> <code>(sum, mean)</code> <p>Aggregation function for rolling window.</p> <code>'sum'</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage with default gamma distribution\n&gt;&gt;&gt; ssi = SSI()\n&gt;&gt;&gt; ssi.fit(training_data)\n&gt;&gt;&gt; ssi_values = ssi.transform(new_data)\n</code></pre> <pre><code>&gt;&gt;&gt; # Using different distribution\n&gt;&gt;&gt; ssi = SSI(dist='lognorm', timescale=6)\n&gt;&gt;&gt; ssi.fit(training_data)\n</code></pre>"},{"location":"api/drought/#synhydro.droughts.ssi.SSI.fitted_distributions","title":"fitted_distributions  <code>property</code>","text":"<pre><code>fitted_distributions: dict\n</code></pre> <p>Access to fitted distributions (read-only).</p>"},{"location":"api/drought/#synhydro.droughts.ssi.SSI.fit","title":"fit","text":"<pre><code>fit(training_series: Series) -&gt; SSI\n</code></pre> <p>Fit distributions using training data.</p> <p>Parameters:</p> Name Type Description Default <code>training_series</code> <code>Series</code> <p>Time series data for fitting distributions</p> required <p>Returns:</p> Type Description <code>SSI</code> <p>Self for method chaining</p>"},{"location":"api/drought/#synhydro.droughts.ssi.SSI.transform","title":"transform","text":"<pre><code>transform(new_series: Series) -&gt; Series\n</code></pre> <p>Calculate SSI values for new data using fitted distributions.</p> <p>Parameters:</p> Name Type Description Default <code>new_series</code> <code>Series</code> <p>New time series data to transform</p> required <p>Returns:</p> Type Description <code>Series</code> <p>SSI values for the new series</p>"},{"location":"api/drought/#synhydro.droughts.ssi.SSI.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(training_series: Series, new_series: Series = None) -&gt; Series\n</code></pre> <p>Fit on training data and transform new data in one step.</p> <p>Parameters:</p> Name Type Description Default <code>training_series</code> <code>Series</code> <p>Data for fitting distributions</p> required <code>new_series</code> <code>Series</code> <p>Data to transform. If None, transforms training_series.</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>SSI values</p>"},{"location":"api/drought/#synhydro.droughts.ssi.SSI.get_training_ssi","title":"get_training_ssi","text":"<pre><code>get_training_ssi() -&gt; Series\n</code></pre> <p>Get SSI values for the training data.</p> <p>Returns:</p> Type Description <code>Series</code> <p>SSI values for training data</p>"},{"location":"api/drought/#functions","title":"Functions","text":""},{"location":"api/drought/#synhydro.droughts.ssi.get_drought_metrics","title":"get_drought_metrics","text":"<pre><code>get_drought_metrics(ssi, end_drought_threshold_months=3)\n</code></pre> <p>Calculate drought metrics from standardized supply index (SSI) time series.</p> <p>Parameters:</p> Name Type Description Default <code>ssi</code> <code>Series</code> <p>Time series of standardized supply index values</p> required <code>end_drought_threshold_months</code> <code>int</code> <p>Number of consecutive days with SSI &gt; 0 required to end a critical drought</p> <code>3</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing drought metrics for each identified drought event</p>"},{"location":"api/drought/#distribution-utilities","title":"Distribution Utilities","text":""},{"location":"api/drought/#synhydro.droughts.distributions","title":"distributions","text":"<p>Distribution management for drought analysis.</p> <p>This module provides utilities for working with probability distributions in drought analysis, including a registry of common distributions and helper functions for distribution selection.</p>"},{"location":"api/drought/#synhydro.droughts.distributions.get_distribution","title":"get_distribution","text":"<pre><code>get_distribution(name: Union[str, ContinuousDist]) -&gt; ContinuousDist\n</code></pre> <p>Get a distribution object by name or pass through if already a distribution.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str or ContinuousDist</code> <p>Distribution name (e.g., 'gamma') or scipy distribution object.</p> required <p>Returns:</p> Type Description <code>ContinuousDist</code> <p>Scipy continuous distribution object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If distribution name is not recognized.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dist = get_distribution('gamma')\n&gt;&gt;&gt; dist = get_distribution(scs.gamma)  # Pass through\n</code></pre>"},{"location":"api/drought/#synhydro.droughts.distributions.list_distributions","title":"list_distributions","text":"<pre><code>list_distributions(include_info: bool = False) -&gt; Union[List[str], Dict[str, Dict[str, str]]]\n</code></pre> <p>List available distributions for drought analysis.</p> <p>Parameters:</p> Name Type Description Default <code>include_info</code> <code>bool</code> <p>If True, returns detailed information about each distribution. If False, returns only distribution names.</p> <code>False</code> <p>Returns:</p> Type Description <code>list or dict</code> <p>List of distribution names or dict with detailed information.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; distributions = list_distributions()\n&gt;&gt;&gt; print(distributions)\n['gamma', 'lognorm', 'pearson3', ...]\n</code></pre> <pre><code>&gt;&gt;&gt; info = list_distributions(include_info=True)\n&gt;&gt;&gt; print(info['gamma']['description'])\n</code></pre>"},{"location":"api/drought/#synhydro.droughts.distributions.get_distribution_info","title":"get_distribution_info","text":"<pre><code>get_distribution_info(name: str) -&gt; Dict[str, str]\n</code></pre> <p>Get detailed information about a specific distribution.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Distribution name.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with keys: name, description, best_for, parameters.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If distribution name is not recognized.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; info = get_distribution_info('gamma')\n&gt;&gt;&gt; print(info['description'])\n</code></pre>"},{"location":"api/drought/#synhydro.droughts.distributions.print_distribution_guide","title":"print_distribution_guide","text":"<pre><code>print_distribution_guide()\n</code></pre> <p>Print a user-friendly guide to available distributions.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; print_distribution_guide()\n</code></pre>"},{"location":"api/drought/#synhydro.droughts.distributions.validate_distribution","title":"validate_distribution","text":"<pre><code>validate_distribution(dist: Union[str, ContinuousDist]) -&gt; ContinuousDist\n</code></pre> <p>Validate and normalize a distribution specification.</p> <p>Parameters:</p> Name Type Description Default <code>dist</code> <code>str or ContinuousDist</code> <p>Distribution name or scipy distribution object.</p> required <p>Returns:</p> Type Description <code>ContinuousDist</code> <p>Validated scipy distribution object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If distribution is invalid.</p> <code>TypeError</code> <p>If distribution type is not supported.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dist = validate_distribution('gamma')\n&gt;&gt;&gt; dist = validate_distribution(scs.lognorm)\n</code></pre>"},{"location":"api/generators/","title":"Generators","text":""},{"location":"api/generators/#base-class","title":"Base Class","text":""},{"location":"api/generators/#synhydro.core.base.Generator","title":"Generator","text":"<pre><code>Generator(Q_obs: Union[Series, DataFrame], name: Optional[str] = None, debug: bool = False)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for all synthetic generation methods.</p> <p>All generator implementations should inherit from this class.</p> <p>Initialize the generator base class.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>Series or DataFrame</code> <p>Observed historical flow data for training the generator.</p> required <code>name</code> <code>str</code> <p>Name identifier for this generator instance</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging</p> <code>False</code>"},{"location":"api/generators/#synhydro.core.base.Generator.is_fitted","title":"is_fitted  <code>property</code>","text":"<pre><code>is_fitted: bool\n</code></pre> <p>Check if generator is fitted.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.is_preprocessed","title":"is_preprocessed  <code>property</code>","text":"<pre><code>is_preprocessed: bool\n</code></pre> <p>Check if preprocessing is complete.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.n_sites","title":"n_sites  <code>property</code>","text":"<pre><code>n_sites: int\n</code></pre> <p>Number of sites in the generator.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of sites.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If preprocessing not yet run.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.sites","title":"sites  <code>property</code>","text":"<pre><code>sites: List[str]\n</code></pre> <p>List of site names.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>Site identifiers.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If preprocessing not yet run.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.output_frequency","title":"output_frequency  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>output_frequency: str\n</code></pre> <p>Temporal frequency of generated output.</p> <p>Returns:</p> Type Description <code>str</code> <p>Pandas frequency string (e.g., 'MS' for monthly, 'D' for daily).</p>"},{"location":"api/generators/#synhydro.core.base.Generator.validate_input_data","title":"validate_input_data","text":"<pre><code>validate_input_data(data: Union[Series, DataFrame]) -&gt; pd.DataFrame\n</code></pre> <p>Validate and standardize input data format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Series or DataFrame</code> <p>Input time series data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Validated and standardized data</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid</p> <code>TypeError</code> <p>If data type is unsupported</p>"},{"location":"api/generators/#synhydro.core.base.Generator.validate_preprocessing","title":"validate_preprocessing","text":"<pre><code>validate_preprocessing() -&gt; None\n</code></pre> <p>Check if preprocessing has been completed.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If preprocessing() has not been run.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.validate_fit","title":"validate_fit","text":"<pre><code>validate_fit() -&gt; None\n</code></pre> <p>Check if generator has been fitted.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If fit() has not been run.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.update_state","title":"update_state","text":"<pre><code>update_state(preprocessed: Optional[bool] = None, fitted: Optional[bool] = None) -&gt; None\n</code></pre> <p>Update generator state flags.</p> <p>Parameters:</p> Name Type Description Default <code>preprocessed</code> <code>bool</code> <p>Set preprocessing state.</p> <code>None</code> <code>fitted</code> <code>bool</code> <p>Set fitted state.</p> <code>None</code>"},{"location":"api/generators/#synhydro.core.base.Generator.get_params","title":"get_params","text":"<pre><code>get_params(deep: bool = True) -&gt; Dict[str, Any]\n</code></pre> <p>Get initialization parameters (scikit-learn style).</p> <p>Returns only constructor/configuration parameters, not fitted values. Following scikit-learn convention for compatibility.</p> <p>Parameters:</p> Name Type Description Default <code>deep</code> <code>bool</code> <p>If True, return deep copy of parameters.</p> <code>True</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of initialization parameters.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.get_fitted_params","title":"get_fitted_params","text":"<pre><code>get_fitted_params() -&gt; Dict[str, Any]\n</code></pre> <p>Get parameters learned from data during fit().</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary of fitted parameters (all keys end with underscore).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If generator has not been fitted yet.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.summary","title":"summary","text":"<pre><code>summary(show_fitted: bool = True) -&gt; str\n</code></pre> <p>Generate comprehensive summary of generator configuration and fit.</p> <p>Parameters:</p> Name Type Description Default <code>show_fitted</code> <code>bool</code> <p>Whether to include fitted parameters in summary.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted summary string.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.get_state_info","title":"get_state_info","text":"<pre><code>get_state_info() -&gt; Dict[str, Any]\n</code></pre> <p>Get complete state information including params and metadata.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary containing all generator state, parameters, and metadata.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.save","title":"save","text":"<pre><code>save(filepath: str) -&gt; None\n</code></pre> <p>Save fitted generator to file using pickle.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to save the generator.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If generator is not fitted.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(filepath: str) -&gt; Generator\n</code></pre> <p>Load fitted generator from file.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str</code> <p>Path to saved generator file.</p> required <p>Returns:</p> Type Description <code>Generator</code> <p>Loaded generator instance.</p>"},{"location":"api/generators/#synhydro.core.base.Generator.preprocessing","title":"preprocessing  <code>abstractmethod</code>","text":"<pre><code>preprocessing(sites: Optional[List[str]] = None, **kwargs: Any) -&gt; None\n</code></pre> <p>Preprocess and validate observed flow data.</p> <p>Implementations should: 1. Call validate_input_data() to validate self._Q_obs_raw 2. Store preprocessed data as instance attributes 3. Call update_state(preprocessed=True) at end</p> <p>Parameters:</p> Name Type Description Default <code>sites</code> <code>List[str]</code> <p>List of site names to use. If None, uses all columns.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional preprocessing parameters.</p> <code>{}</code>"},{"location":"api/generators/#synhydro.core.base.Generator.fit","title":"fit  <code>abstractmethod</code>","text":"<pre><code>fit(**kwargs: Any) -&gt; None\n</code></pre> <p>Fit the generator to observed flow data.</p> <p>Implementations should: 1. Call validate_preprocessing() at start 2. Fit model parameters from preprocessed data 3. Store fitted parameters as instance attributes 4. Call update_state(fitted=True) at end</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Additional fitting parameters.</p> <code>{}</code>"},{"location":"api/generators/#synhydro.core.base.Generator.generate","title":"generate  <code>abstractmethod</code>","text":"<pre><code>generate(n_realizations: int = 1, n_years: Optional[int] = None, n_timesteps: Optional[int] = None, seed: Optional[int] = None, **kwargs: Any) -&gt; Ensemble\n</code></pre> <p>Generate synthetic streamflow realizations.</p> <p>Implementations should: 1. Call validate_fit() at start 2. Set random seed if provided 3. Generate synthetic flows 4. Return Ensemble object containing all realizations</p> <p>Parameters:</p> Name Type Description Default <code>n_realizations</code> <code>int</code> <p>Number of synthetic realizations to generate.</p> <code>1</code> <code>n_years</code> <code>int</code> <p>Number of years to generate (alternative to n_timesteps).</p> <code>None</code> <code>n_timesteps</code> <code>int</code> <p>Number of timesteps to generate explicitly.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional generation parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>Generated synthetic flows as an Ensemble object.</p>"},{"location":"api/generators/#kirschgenerator","title":"KirschGenerator","text":""},{"location":"api/generators/#synhydro.methods.generation.nonparametric.kirsch.KirschGenerator","title":"KirschGenerator","text":"<pre><code>KirschGenerator(Q_obs: DataFrame, generate_using_log_flow=True, matrix_repair_method='spectral', name=None, debug=False, **kwargs)\n</code></pre> <p>               Bases: <code>Generator</code></p> <p>Kirsch nonparametric bootstrap generator for monthly streamflow synthesis.</p> <p>Generates monthly synthetic flows using bootstrap resampling with correlation preservation.</p> <p>Initialize Kirsch generator.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>DataFrame</code> <p>Observed historical flow data with DatetimeIndex.</p> required <code>generate_using_log_flow</code> <code>bool</code> <p>If True, generates in log-space for better handling of skewed distributions.</p> <code>True</code> <code>matrix_repair_method</code> <code>str</code> <p>Method for repairing non-positive-definite correlation matrices.</p> <code>'spectral'</code> <code>name</code> <code>str</code> <p>Name for this generator instance.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code>"},{"location":"api/generators/#synhydro.methods.generation.nonparametric.kirsch.KirschGenerator.output_frequency","title":"output_frequency  <code>property</code>","text":"<pre><code>output_frequency: str\n</code></pre> <p>Kirsch generator produces monthly output.</p>"},{"location":"api/generators/#synhydro.methods.generation.nonparametric.kirsch.KirschGenerator.Q_obs_monthly","title":"Q_obs_monthly  <code>property</code>","text":"<pre><code>Q_obs_monthly\n</code></pre> <p>Get observed monthly data (alias for Qm for consistency with other generators).</p>"},{"location":"api/generators/#synhydro.methods.generation.nonparametric.kirsch.KirschGenerator.preprocessing","title":"preprocessing","text":"<pre><code>preprocessing(sites=None, timestep='monthly', **kwargs)\n</code></pre> <p>Preprocess observed data for Kirsch generation.</p> <p>Parameters:</p> Name Type Description Default <code>sites</code> <code>list</code> <p>Sites to use. If None, uses all sites.</p> <code>None</code> <code>timestep</code> <code>str</code> <p>Currently only 'monthly' is supported.</p> <code>'monthly'</code> <code>**kwargs</code> <p>Additional preprocessing parameters.</p> <code>{}</code>"},{"location":"api/generators/#synhydro.methods.generation.nonparametric.kirsch.KirschGenerator.fit","title":"fit","text":"<pre><code>fit(**kwargs)\n</code></pre> <p>Fit Kirsch generator to preprocessed data.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional fitting parameters.</p> <code>{}</code>"},{"location":"api/generators/#synhydro.methods.generation.nonparametric.kirsch.KirschGenerator.generate_single_series","title":"generate_single_series","text":"<pre><code>generate_single_series(n_years, M=None, as_array=True, synthetic_index=None)\n</code></pre> <p>Generate a single synthetic time series.</p> <p>Parameters:</p> Name Type Description Default <code>n_years</code> <code>int</code> <p>Number of years for the synthetic time series.</p> required <code>M</code> <code>ndarray</code> <p>Bootstrap indices for the synthetic time series. If None, random indices will be generated.</p> <code>None</code> <code>as_array</code> <code>bool</code> <p>If True, returns a numpy array; if False, returns a pandas DataFrame.</p> <code>True</code> <code>synthetic_index</code> <code>DatetimeIndex</code> <p>Custom index for the synthetic time series. If None, a default index will be generated.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray or DataFrame</code> <p>Synthetic time series data.</p>"},{"location":"api/generators/#synhydro.methods.generation.nonparametric.kirsch.KirschGenerator.generate","title":"generate","text":"<pre><code>generate(n_realizations=1, n_years=None, n_timesteps=None, seed=None, **kwargs)\n</code></pre> <p>Generate an ensemble of synthetic monthly flows.</p> <p>Parameters:</p> Name Type Description Default <code>n_realizations</code> <code>int</code> <p>Number of synthetic time series to generate.</p> <code>1</code> <code>n_years</code> <code>int</code> <p>Number of years for each synthetic time series. If None, uses the number of historic years.</p> <code>None</code> <code>n_timesteps</code> <code>int</code> <p>Not used (Kirsch generates by years, not timesteps).</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>None</code> <code>**kwargs</code> <p>Additional generation parameters.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>Ensemble object containing all generated realizations.</p>"},{"location":"api/generators/#phaserandomizationgenerator","title":"PhaseRandomizationGenerator","text":""},{"location":"api/generators/#synhydro.methods.generation.nonparametric.phase_randomization.PhaseRandomizationGenerator","title":"PhaseRandomizationGenerator","text":"<pre><code>PhaseRandomizationGenerator(Q_obs: Union[Series, DataFrame], marginal: str = 'kappa', win_h_length: int = 15, name: Optional[str] = None, debug: bool = False, **kwargs)\n</code></pre> <p>               Bases: <code>Generator</code></p> <p>Phase randomization generator for synthetic streamflow using Brunner et al. (2019).</p> <p>Generates synthetic daily streamflow time series using Fourier transform phase randomization combined with the four-parameter kappa distribution. The method preserves both short- and long-range temporal dependence by conserving the power spectrum while randomizing phases.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>Series or DataFrame</code> <p>Observed daily streamflow data with DatetimeIndex. If DataFrame with multiple columns, only first column is used (with warning).</p> required <code>marginal</code> <code>str</code> <p>Marginal distribution type for back-transformation: - 'kappa': Four-parameter kappa distribution (default, allows extrapolation) - 'empirical': Empirical distribution (no extrapolation beyond observed)</p> <code>'kappa'</code> <code>win_h_length</code> <code>int</code> <p>Half-window length for daily distribution fitting. Values within \u00b1win_h_length days are used, giving a total window of 2*win_h_length+1 days.</p> <code>15</code> <code>name</code> <code>str</code> <p>Name identifier for this generator instance.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>par_day_</code> <code>dict</code> <p>Fitted kappa distribution parameters for each day of year (1-365). Each entry contains {'xi', 'alfa', 'k', 'h'}.</p> <code>modulus_</code> <code>ndarray</code> <p>Amplitude spectrum (modulus of FFT) from fitted data.</p> <code>phases_</code> <code>ndarray</code> <p>Phase spectrum from fitted data.</p> <code>norm_</code> <code>ndarray</code> <p>Normalized/deseasonalized data after normal score transform.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from synhydro.methods.generation.nonparametric import PhaseRandomizationGenerator\n&gt;&gt;&gt; Q_daily = pd.read_csv('daily_flows.csv', index_col=0, parse_dates=True)\n&gt;&gt;&gt; gen = PhaseRandomizationGenerator(Q_daily, marginal='kappa')\n&gt;&gt;&gt; gen.preprocessing()\n&gt;&gt;&gt; gen.fit()\n&gt;&gt;&gt; ensemble = gen.generate(n_realizations=100, seed=42)\n</code></pre> Notes <ul> <li>Requires at least 2 years (730 days) of daily data</li> <li>February 29 observations are removed to ensure consistent 365-day years</li> <li>The method generates series of the same length as the observed data</li> </ul> <p>Initialize the PhaseRandomizationGenerator.</p>"},{"location":"api/generators/#synhydro.methods.generation.nonparametric.phase_randomization.PhaseRandomizationGenerator.output_frequency","title":"output_frequency  <code>property</code>","text":"<pre><code>output_frequency: str\n</code></pre> <p>Phase randomization generates daily output.</p>"},{"location":"api/generators/#synhydro.methods.generation.nonparametric.phase_randomization.PhaseRandomizationGenerator.preprocessing","title":"preprocessing","text":"<pre><code>preprocessing(sites: Optional[list] = None, **kwargs) -&gt; None\n</code></pre> <p>Preprocess observed data for phase randomization generation.</p> <p>Validates input data, removes leap days, and creates day-of-year index.</p> <p>Parameters:</p> Name Type Description Default <code>sites</code> <code>list</code> <p>Not used (phase randomization is univariate).</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Additional preprocessing parameters (currently unused).</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data has fewer than 730 days or has missing days.</p>"},{"location":"api/generators/#synhydro.methods.generation.nonparametric.phase_randomization.PhaseRandomizationGenerator.fit","title":"fit","text":"<pre><code>fit(**kwargs) -&gt; None\n</code></pre> <p>Fit the phase randomization model to observed data.</p> <p>This method: 1. Fits kappa distribution parameters for each day of year (if marginal='kappa') 2. Applies normal score transform per day of year 3. Computes FFT and extracts modulus/phases</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Additional fitting parameters (currently unused).</p> <code>{}</code>"},{"location":"api/generators/#synhydro.methods.generation.nonparametric.phase_randomization.PhaseRandomizationGenerator.generate","title":"generate","text":"<pre><code>generate(n_realizations: int = 1, n_years: Optional[int] = None, n_timesteps: Optional[int] = None, seed: Optional[int] = None, **kwargs) -&gt; Ensemble\n</code></pre> <p>Generate synthetic streamflow realizations using phase randomization.</p> <p>Parameters:</p> Name Type Description Default <code>n_realizations</code> <code>int</code> <p>Number of synthetic realizations to generate.</p> <code>1</code> <code>n_years</code> <code>int</code> <p>Not used (generates same length as observed data).</p> <code>None</code> <code>n_timesteps</code> <code>int</code> <p>Not used (generates same length as observed data).</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Additional generation parameters (currently unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>Generated synthetic flows as an Ensemble object.</p>"},{"location":"api/generators/#thomasfieringgenerator","title":"ThomasFieringGenerator","text":""},{"location":"api/generators/#synhydro.methods.generation.parametric.thomas_fiering.ThomasFieringGenerator","title":"ThomasFieringGenerator","text":"<pre><code>ThomasFieringGenerator(Q_obs: Union[Series, DataFrame], name: Optional[str] = None, debug: bool = False, **kwargs)\n</code></pre> <p>               Bases: <code>Generator</code></p> <p>Thomas-Fiering autoregressive model for monthly streamflow generation.</p> <p>Generates synthetic monthly streamflows using a lag-1 autoregressive model with Stedinger-Taylor normalization. Preserves monthly means, standard deviations, and lag-1 serial correlations.</p> <p>Note: Thomas-Fiering is a univariate method (single site only).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from synhydro.methods.generate.parametric.thomas_fiering import ThomasFieringGenerator\n&gt;&gt;&gt; Q_monthly = pd.read_csv('monthly_flows.csv', index_col=0, parse_dates=True)\n&gt;&gt;&gt; tf = ThomasFieringGenerator(Q_monthly.iloc[:, 0])\n&gt;&gt;&gt; tf.preprocessing()\n&gt;&gt;&gt; tf.fit()\n&gt;&gt;&gt; ensemble = tf.generate(n_years=10, n_realizations=5)\n</code></pre> References <p>Thomas, H.A., and Fiering, M.B. (1962). Mathematical synthesis of streamflow sequences for the analysis of river basins by simulation.</p> <p>Stedinger, J.R., and Taylor, M.R. (1982). Synthetic streamflow generation: 1. Model verification and validation. Water Resources Research, 18(4), 909-918.</p> <p>Initialize the ThomasFieringGenerator.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>Series or DataFrame</code> <p>Streamflow data with DatetimeIndex. Must be single site. If not monthly frequency, will be resampled during preprocessing.</p> required <code>name</code> <code>str</code> <p>Name for this generator instance.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code> <code>**kwargs</code> <code>dict</code> <p>Additional parameters (currently unused).</p> <code>{}</code>"},{"location":"api/generators/#synhydro.methods.generation.parametric.thomas_fiering.ThomasFieringGenerator.output_frequency","title":"output_frequency  <code>property</code>","text":"<pre><code>output_frequency: str\n</code></pre> <p>Thomas-Fiering generator produces monthly output.</p>"},{"location":"api/generators/#synhydro.methods.generation.parametric.thomas_fiering.ThomasFieringGenerator.preprocessing","title":"preprocessing","text":"<pre><code>preprocessing(sites: Optional[list] = None, **kwargs) -&gt; None\n</code></pre> <p>Preprocess observed data for Thomas-Fiering generation.</p> <p>Validates input, resamples to monthly if needed, and applies Stedinger-Taylor normalization.</p> <p>Parameters:</p> Name Type Description Default <code>sites</code> <code>list</code> <p>Not used (Thomas-Fiering is univariate).</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Additional parameters (currently unused).</p> <code>{}</code>"},{"location":"api/generators/#synhydro.methods.generation.parametric.thomas_fiering.ThomasFieringGenerator.fit","title":"fit","text":"<pre><code>fit(**kwargs) -&gt; None\n</code></pre> <p>Estimate Thomas-Fiering model parameters from normalized flows.</p> <p>Calculates monthly means, standard deviations, and lag-1 serial correlations from normalized flows.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Additional parameters (currently unused).</p> <code>{}</code>"},{"location":"api/generators/#synhydro.methods.generation.parametric.thomas_fiering.ThomasFieringGenerator.generate","title":"generate","text":"<pre><code>generate(n_years: Optional[int] = None, n_realizations: int = 1, n_timesteps: Optional[int] = None, seed: Optional[int] = None, **kwargs) -&gt; Ensemble\n</code></pre> <p>Generate synthetic monthly streamflows.</p> <p>Parameters:</p> Name Type Description Default <code>n_years</code> <code>int</code> <p>Number of years to generate per realization. If None, uses the length of historic data.</p> <code>None</code> <code>n_realizations</code> <code>int</code> <p>Number of synthetic realizations to generate.</p> <code>1</code> <code>n_timesteps</code> <code>int</code> <p>Number of monthly timesteps to generate. If provided, overrides n_years.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Additional parameters (currently unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>Ensemble object containing all realizations.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither n_years nor n_timesteps is provided.</p>"},{"location":"api/generators/#matalasgenerator","title":"MATALASGenerator","text":""},{"location":"api/generators/#synhydro.methods.generation.parametric.matalas.MATALASGenerator","title":"MATALASGenerator","text":"<pre><code>MATALASGenerator(Q_obs, log_transform: bool = True, name: Optional[str] = None, debug: bool = False, **kwargs)\n</code></pre> <p>               Bases: <code>Generator</code></p> <p>Matalas (1967) multi-site monthly lag-1 autoregressive (MAR(1)) model.</p> <p>The standard classical baseline for parametric multi-site stochastic generation. Extends the Thomas-Fiering univariate model to n sites using matrix autoregression, preserving contemporaneous cross-site correlations and lag-1 temporal structure at each site.</p> <p>For each monthly transition m \u2192 m+1, generates:</p> <pre><code>Z(t+1) = A(m) \u00b7 Z(t) + B(m) \u00b7 \u03b5(t+1)\n</code></pre> <p>where Z are standardized flows across all sites, \u03b5 ~ N(0, I), and A, B are coefficient matrices fitted from observed cross-correlations.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>DataFrame or Series</code> <p>Monthly streamflow with DatetimeIndex. If Series, treated as single site (equivalent to Thomas-Fiering). Columns are sites.</p> required <code>log_transform</code> <code>bool</code> <p>Apply log(Q + 1) transformation before standardization to reduce skewness and improve normality assumption.</p> <code>True</code> <code>name</code> <code>str</code> <p>Name for this generator instance.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code> Notes <p>The coefficient matrices are derived from the lag-0 and lag-1 cross-correlation matrices of the standardized flows:</p> <pre><code>A(m) = S\u2081(m) \u00b7 S\u2080(m)\u207b\u00b9\nB(m) \u00b7 B(m)\u1d40 = S\u2080(m+1) - A(m) \u00b7 S\u2080(m) \u00b7 A(m)\u1d40\n</code></pre> <p>where S\u2080(m) is the contemporaneous correlation matrix at month m and S\u2081(m) is the lag-1 cross-correlation between months m+1 and m. B(m) is the lower Cholesky factor of the residual covariance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gen = MATALASGenerator(Q_monthly)\n&gt;&gt;&gt; gen.preprocessing()\n&gt;&gt;&gt; gen.fit()\n&gt;&gt;&gt; ensemble = gen.generate(n_years=100, n_realizations=50, seed=42)\n</code></pre> References <p>Matalas, N. C. (1967). Mathematical assessment of synthetic hydrology. Water Resources Research, 3(4), 937\u2013945.</p> <p>Salas, J. D., Delleur, J. W., Yevjevich, V., &amp; Lane, W. L. (1980). Applied Modeling of Hydrologic Time Series. Water Resources Publications.</p>"},{"location":"api/generators/#synhydro.methods.generation.parametric.matalas.MATALASGenerator.preprocessing","title":"preprocessing","text":"<pre><code>preprocessing(sites: Optional[list] = None, **kwargs) -&gt; None\n</code></pre> <p>Validate input and resample to monthly frequency.</p> <p>Parameters:</p> Name Type Description Default <code>sites</code> <code>list</code> <p>Subset of site columns to use. Uses all columns if None.</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Unused.</p> <code>{}</code>"},{"location":"api/generators/#synhydro.methods.generation.parametric.matalas.MATALASGenerator.fit","title":"fit","text":"<pre><code>fit(**kwargs) -&gt; None\n</code></pre> <p>Estimate MAR(1) coefficient matrices from observed monthly flows.</p> <p>For each of the 12 monthly transitions, computes lag-0 (S0) and lag-1 (S1) cross-correlation matrices then solves for A and B.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Unused.</p> <code>{}</code>"},{"location":"api/generators/#synhydro.methods.generation.parametric.matalas.MATALASGenerator.generate","title":"generate","text":"<pre><code>generate(n_years: Optional[int] = None, n_realizations: int = 1, n_timesteps: Optional[int] = None, seed: Optional[int] = None, **kwargs) -&gt; Ensemble\n</code></pre> <p>Generate synthetic monthly streamflows at all sites.</p> <p>Parameters:</p> Name Type Description Default <code>n_years</code> <code>int</code> <p>Years per realization. Defaults to length of historic record.</p> <code>None</code> <code>n_realizations</code> <code>int</code> <p>Number of independent synthetic sequences.</p> <code>1</code> <code>n_timesteps</code> <code>int</code> <p>Total monthly timesteps; overrides n_years when provided.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Unused.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>Collection of synthetic realizations.</p>"},{"location":"api/generators/#multisitehmmgenerator","title":"MultiSiteHMMGenerator","text":""},{"location":"api/generators/#synhydro.methods.generation.parametric.multisite_hmm.MultiSiteHMMGenerator","title":"MultiSiteHMMGenerator","text":"<pre><code>MultiSiteHMMGenerator(Q_obs: Union[Series, DataFrame], n_states: int = 2, offset: float = 1.0, max_iterations: int = 1000, covariance_type: str = 'full', name: Optional[str] = None, debug: bool = False, **kwargs)\n</code></pre> <p>               Bases: <code>Generator</code></p> <p>Multi-site Hidden Markov Model generator for synthetic streamflow.</p> <p>Generates synthetic streamflow using a Gaussian Mixture Model HMM that models temporal dependencies through hidden states and spatial correlations through multivariate Gaussian emissions with state-specific covariance matrices.</p> <p>The method is particularly suited for capturing drought dynamics across multiple sites/basins simultaneously.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>Series or DataFrame</code> <p>Observed streamflow data with DatetimeIndex. Must be DataFrame for multi-site generation (multiple columns = multiple sites).</p> required <code>n_states</code> <code>int</code> <p>Number of hidden states. Default is 2 (dry/wet states).</p> <code>2</code> <code>offset</code> <code>float</code> <p>Small value added before log transformation to handle zeros. Recommended: 1.0 for flows in standard units.</p> <code>1.0</code> <code>max_iterations</code> <code>int</code> <p>Maximum iterations for HMM fitting convergence.</p> <code>1000</code> <code>covariance_type</code> <code>str</code> <p>Type of covariance matrix: - 'full': Full covariance matrix (captures all correlations) - 'diag': Diagonal covariance (independent sites) - 'spherical': Single variance for all dimensions</p> <code>'full'</code> <code>name</code> <code>str</code> <p>Name identifier for this generator instance.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>means_</code> <code>ndarray</code> <p>State means for each site. Shape: (n_states, n_sites).</p> <code>covariances_</code> <code>ndarray</code> <p>Covariance matrices for each state. Shape: (n_states, n_sites, n_sites).</p> <code>transition_matrix_</code> <code>ndarray</code> <p>State transition probability matrix. Shape: (n_states, n_states).</p> <code>stationary_distribution_</code> <code>ndarray</code> <p>Stationary distribution of states. Shape: (n_states,).</p> <code>Q_log_</code> <code>ndarray</code> <p>Log-transformed observed flows used for fitting.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from synhydro.methods.generation.parametric import MultiSiteHMMGenerator\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Load multi-site annual flows\n&gt;&gt;&gt; Q_annual = pd.read_csv('annual_flows.csv', index_col=0, parse_dates=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Initialize generator\n&gt;&gt;&gt; gen = MultiSiteHMMGenerator(Q_annual, n_states=2)\n&gt;&gt;&gt; gen.preprocessing()\n&gt;&gt;&gt; gen.fit()\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Generate 100 realizations of 50 years each\n&gt;&gt;&gt; ensemble = gen.generate(n_realizations=100, n_years=50, seed=42)\n</code></pre> Notes <ul> <li>Designed for annual timestep data (can handle other frequencies)</li> <li>Log transformation ensures positive emissions</li> <li>Full covariance preserves spatial correlations between sites</li> <li>State ordering: states sorted by mean (low mean = dry state)</li> </ul> <p>Initialize the MultiSiteHMMGenerator.</p>"},{"location":"api/generators/#synhydro.methods.generation.parametric.multisite_hmm.MultiSiteHMMGenerator.output_frequency","title":"output_frequency  <code>property</code>","text":"<pre><code>output_frequency: str\n</code></pre> <p>Output frequency matches input frequency.</p> <p>Typically used for annual data ('YS' or 'AS'), but flexible.</p>"},{"location":"api/generators/#synhydro.methods.generation.parametric.multisite_hmm.MultiSiteHMMGenerator.preprocessing","title":"preprocessing","text":"<pre><code>preprocessing(sites: Optional[List[str]] = None, **kwargs) -&gt; None\n</code></pre> <p>Preprocess observed data for HMM fitting.</p> <p>Applies offset and log transformation to handle zeros and ensure positive values for fitting.</p> <p>Parameters:</p> Name Type Description Default <code>sites</code> <code>List[str]</code> <p>Subset of sites to use. If None, uses all columns.</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Additional preprocessing parameters (currently unused).</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data has fewer than 2 sites for multi-site modeling.</p>"},{"location":"api/generators/#synhydro.methods.generation.parametric.multisite_hmm.MultiSiteHMMGenerator.fit","title":"fit","text":"<pre><code>fit(random_state: Optional[int] = None, **kwargs) -&gt; None\n</code></pre> <p>Fit the multi-site HMM to observed data.</p> <p>Estimates hidden states, transition probabilities, state-specific means, and covariance matrices using the GMMHMM algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>random_state</code> <code>int</code> <p>Random seed for reproducible fitting. If None, fitting may vary.</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Additional fitting parameters (currently unused).</p> <code>{}</code> Notes <p>States are automatically ordered by mean (ascending), so state 0 represents the dry state and higher-numbered states represent progressively wetter states.</p>"},{"location":"api/generators/#synhydro.methods.generation.parametric.multisite_hmm.MultiSiteHMMGenerator.generate","title":"generate","text":"<pre><code>generate(n_realizations: int = 1, n_years: Optional[int] = None, n_timesteps: Optional[int] = None, seed: Optional[int] = None, **kwargs) -&gt; Ensemble\n</code></pre> <p>Generate synthetic streamflow realizations.</p> <p>Parameters:</p> Name Type Description Default <code>n_realizations</code> <code>int</code> <p>Number of synthetic realizations to generate.</p> <code>1</code> <code>n_years</code> <code>int</code> <p>Number of years to generate. If provided with annual data, this equals n_timesteps.</p> <code>None</code> <code>n_timesteps</code> <code>int</code> <p>Number of timesteps to generate explicitly. Takes precedence over n_years if both provided.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Additional generation parameters (currently unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>Generated synthetic flows as an Ensemble object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither n_years nor n_timesteps is provided.</p>"},{"location":"api/generators/#warmgenerator","title":"WARMGenerator","text":""},{"location":"api/generators/#synhydro.methods.generation.parametric.warm.WARMGenerator","title":"WARMGenerator","text":"<pre><code>WARMGenerator(Q_obs: Union[Series, DataFrame], wavelet: str = 'morl', scales: int = 64, ar_order: int = 1, name: Optional[str] = None, debug: bool = False, **kwargs)\n</code></pre> <p>               Bases: <code>Generator</code></p> <p>Wavelet Auto-Regressive Method (WARM) for non-stationary streamflow generation.</p> <p>Implements the 4-step WARM methodology: 1. Wavelet transform decomposition into periodic components 2. Scale Averaged Wavelet Power (SAWP) calculation for time-varying normalization 3. AR model fitting to scaled wavelet coefficients 4. Stochastic generation with inverse wavelet transform</p> <p>The SAWP approach enables preservation of non-stationary spectral characteristics and time-varying variability in synthetic sequences.</p> <p>Note: WARM is designed for annual streamflow generation (univariate).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from synhydro.methods.generation.parametric.warm import WARMGenerator\n&gt;&gt;&gt; Q_annual = pd.read_csv('annual_flows.csv', index_col=0, parse_dates=True)\n&gt;&gt;&gt; warm = WARMGenerator(Q_annual.iloc[:, 0], wavelet='morlet', scales=64)\n&gt;&gt;&gt; warm.preprocessing()\n&gt;&gt;&gt; warm.fit()\n&gt;&gt;&gt; ensemble = warm.generate(n_years=100, n_realizations=50, seed=42)\n</code></pre> References <p>Nowak, K., Rajagopalan, B., &amp; Zagona, E. (2011). A Wavelet Auto-Regressive Method (WARM) for multi-site streamflow simulation of data with non-stationary trends. Journal of Hydrology, 410(1-2), 1-12.</p> <p>Kwon, H.-H., Lall, U., &amp; Khalil, A. F. (2007). Stochastic simulation model for nonstationary time series using an autoregressive wavelet decomposition: Applications to rainfall and temperature. Water Resources Research, 43(5).</p> <p>Initialize the WARM Generator.</p> <p>Parameters:</p> Name Type Description Default <code>Q_obs</code> <code>Series or DataFrame</code> <p>Annual streamflow data with DatetimeIndex. Must be single site. If DataFrame provided, will use first column only.</p> required <code>wavelet</code> <code>str</code> <p>Wavelet type for continuous wavelet transform. Options: 'morl' (Morlet), 'mexh' (Mexican Hat), 'gaus1'-'gaus8'. Morlet wavelet recommended for hydrologic applications.</p> <code>'morl'</code> <code>scales</code> <code>int</code> <p>Number of scales for wavelet decomposition. Higher values capture more frequency components but increase computational cost.</p> <code>64</code> <code>ar_order</code> <code>int</code> <p>Order of autoregressive model for each wavelet scale. Default AR(1) preserves temporal persistence.</p> <code>1</code> <code>name</code> <code>str</code> <p>Name for this generator instance.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable debug logging.</p> <code>False</code> <code>**kwargs</code> <code>dict</code> <p>Additional parameters (currently unused).</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If scales &lt; 2 or ar_order &lt; 1.</p>"},{"location":"api/generators/#synhydro.methods.generation.parametric.warm.WARMGenerator.output_frequency","title":"output_frequency  <code>property</code>","text":"<pre><code>output_frequency: str\n</code></pre> <p>WARM generator produces annual output.</p>"},{"location":"api/generators/#synhydro.methods.generation.parametric.warm.WARMGenerator.preprocessing","title":"preprocessing","text":"<pre><code>preprocessing(sites: Optional[list] = None, **kwargs) -&gt; None\n</code></pre> <p>Preprocess observed data for WARM generation.</p> <p>Validates input data and ensures annual frequency. WARM is designed for annual streamflow generation.</p> <p>Parameters:</p> Name Type Description Default <code>sites</code> <code>list</code> <p>Not used (WARM is univariate).</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Additional parameters (currently unused).</p> <code>{}</code>"},{"location":"api/generators/#synhydro.methods.generation.parametric.warm.WARMGenerator.fit","title":"fit","text":"<pre><code>fit(**kwargs) -&gt; None\n</code></pre> <p>Fit WARM model to observed annual flows.</p> <p>Implements the 4-step WARM methodology: 1. Continuous wavelet transform 2. Scale Averaged Wavelet Power (SAWP) calculation 3. Normalization by SAWP 4. AR model fitting to scaled coefficients</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>dict</code> <p>Additional parameters (currently unused).</p> <code>{}</code>"},{"location":"api/generators/#synhydro.methods.generation.parametric.warm.WARMGenerator.generate","title":"generate","text":"<pre><code>generate(n_years: Optional[int] = None, n_realizations: int = 1, n_timesteps: Optional[int] = None, seed: Optional[int] = None, **kwargs) -&gt; Ensemble\n</code></pre> <p>Generate synthetic annual streamflows using WARM.</p> <p>Parameters:</p> Name Type Description Default <code>n_years</code> <code>int</code> <p>Number of years to generate per realization. If None, uses the length of historic data.</p> <code>None</code> <code>n_realizations</code> <code>int</code> <p>Number of synthetic realizations to generate.</p> <code>1</code> <code>n_timesteps</code> <code>int</code> <p>Number of annual timesteps to generate. If provided, overrides n_years. For WARM, n_timesteps = n_years (annual data).</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Additional parameters (currently unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Ensemble</code> <p>Ensemble object containing all realizations.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither n_years nor n_timesteps is provided.</p>"},{"location":"references/references/","title":"References","text":""},{"location":"references/references/#references","title":"References","text":"<p>Kirsch, B. R., Characklis, G. W., &amp; Zeff, H. B. (2013). Evaluating the impact of alternative hydro-climate scenarios on transfer agreements: Practical improvement for generating synthetic streamflows. Journal of Water Resources Planning and Management, 139(4), 396-406. https://doi.org/10.1061/(ASCE)WR.1943-5452.0000287</p> <p>Nowak, K., Prairie, J., Rajagopalan, B., &amp; Lall, U. (2010). A nonparametric stochastic approach for multisite disaggregation of annual to daily streamflow. Water resources research, 46(8). https://doi.org/10.1029/2009WR008530Digital </p> <p>Erkyihun, S. T., Rajagopalan, B., Zagona, E., Lall, U., &amp; Nowak, K. (2016). Wavelet\u2010based time series bootstrap model for multidecadal streamflow simulation using climate indicators. Water Resources Research, 52(5), 4061-4077.</p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>Concise examples covering the core SynHydro workflows.</p> Tutorial Generator Description Quickstart <code>ThomasFieringGenerator</code> Single-site monthly generation Multi-Site Monthly <code>KirschGenerator</code> Multi-site nonparametric bootstrap Monthly\u2192Daily Pipeline <code>KirschNowakPipeline</code> Full monthly-to-daily workflow Drought Analysis <code>SSIDroughtMetrics</code> SSI calculation and drought metrics <p>All examples use <code>synhydro.load_example_data()</code>, which returns a multi-site daily streamflow <code>DataFrame</code>.</p>"},{"location":"tutorials/01_quickstart/","title":"Quickstart: Single-Site Monthly Generation","text":"<p>The <code>ThomasFieringGenerator</code> fits a seasonal AR(1) model to single-site monthly streamflow.</p> <pre><code>import synhydro\n\n# Load example data and extract a single site\nQ_daily = synhydro.load_example_data()\nQ_monthly = Q_daily.resample(\"MS\").mean().iloc[:, [0]]   # single-site monthly\n\n# Fit and generate\ngen = synhydro.ThomasFieringGenerator(Q_monthly)\ngen.preprocessing()\ngen.fit()\nensemble = gen.generate(n_realizations=10, n_years=30, seed=42)\n</code></pre> <p>The returned <code>ensemble</code> object contains 10 synthetic 30-year monthly timeseries.</p> <pre><code># Access realizations\nQ_syn_0 = ensemble.data_by_realization[0]    # first realization (DataFrame)\nprint(Q_syn_0.shape)                          # (360, 1) \u2014 360 months \u00d7 1 site\n\n# Summary of fitted parameters\ngen.summary()\n</code></pre> <p>Seed reproducibility</p> <p>Passing the same <code>seed</code> value to <code>generate()</code> always produces identical results.</p> <p>Algorithm details: Thomas-Fiering AR(1)</p>"},{"location":"tutorials/02_multisite/","title":"Multi-Site Monthly Generation","text":"<p><code>KirschGenerator</code> uses nonparametric bootstrap with Cholesky decomposition to preserve cross-site correlations in monthly streamflow.</p> <pre><code>import synhydro\n\n# Multi-site monthly data\nQ_daily = synhydro.load_example_data()\nQ_monthly = Q_daily.resample(\"MS\").mean()\n\ngen = synhydro.KirschGenerator(Q_monthly)\ngen.preprocessing()\ngen.fit()\nensemble = gen.generate(n_realizations=50, n_years=30, seed=42)\n</code></pre> <pre><code># Access by realization or by site\nQ_syn_0 = ensemble.data_by_realization[0]      # shape: (360, n_sites)\nQ_site_A = ensemble.data_by_site[Q_monthly.columns[0]]\n\n# Cross-site correlations are preserved\nprint(Q_syn_0.corr())\n</code></pre> <p>Algorithm details: Kirsch Bootstrap</p>"},{"location":"tutorials/03_pipeline/","title":"Monthly\u2192Daily Pipeline","text":"<p><code>KirschNowakPipeline</code> combines the Kirsch monthly generator with the Nowak KNN disaggregator. It accepts only daily observed data and handles internal aggregation.</p> <pre><code>import synhydro\n\nQ_daily = synhydro.load_example_data()                     # daily observed flows\n\npipeline = synhydro.KirschNowakPipeline(Q_daily)\npipeline.preprocessing()\npipeline.fit()\ndaily_ensemble = pipeline.generate(n_realizations=10, n_years=30, seed=42)\n</code></pre> <p>The output ensemble contains daily synthetic flows, preserving both the monthly statistical structure (from Kirsch) and within-month daily patterns (from Nowak).</p> <pre><code># First realization \u2014 daily DataFrame\nQ_syn_daily = daily_ensemble.data_by_realization[0]\nprint(Q_syn_daily.shape)                                 # (~10957 days \u00d7 n_sites)\n</code></pre> <p>Thomas-Fiering + Nowak</p> <p>A single-site monthly\u2192daily pipeline is also available: <pre><code>pipeline = synhydro.ThomasFieringNowakPipeline(Q_daily)\n</code></pre></p> <p>Algorithm details: Kirsch Bootstrap \u00b7 Nowak Disaggregation</p>"},{"location":"tutorials/04_drought_analysis/","title":"Drought Analysis","text":"<p>SynHydro provides Standardized Streamflow Index (SSI) calculation and drought metric extraction via <code>SSIDroughtMetrics</code>.</p>"},{"location":"tutorials/04_drought_analysis/#ssi-calculation","title":"SSI Calculation","text":"<pre><code>import synhydro\n\nQ_daily = synhydro.load_example_data()\nQ_monthly = Q_daily.resample(\"MS\").mean()\nsite = Q_monthly.columns[0]\n\n# Calculate 12-month SSI using gamma distribution\nssi_calc = synhydro.SSIDroughtMetrics(timescale=\"M\", window=12, dist=\"gamma\")\nssi = ssi_calc.calculate_ssi(Q_monthly[site])\n</code></pre> <p>The SSI series has mean \u2248 0 and std \u2248 1. Values below \u22121 indicate moderate-to-severe drought.</p>"},{"location":"tutorials/04_drought_analysis/#drought-metrics","title":"Drought Metrics","text":"<pre><code>metrics = synhydro.get_drought_metrics(ssi)\nprint(metrics.head())\n</code></pre> <p>Returned columns include: <code>duration</code>, <code>magnitude</code>, <code>severity</code> (minimum SSI), and <code>avg_severity</code> for each identified drought event.</p>"},{"location":"tutorials/04_drought_analysis/#comparing-observed-vs-synthetic","title":"Comparing Observed vs. Synthetic","text":"<pre><code>gen = synhydro.KirschGenerator(Q_monthly)\ngen.preprocessing()\ngen.fit()\nensemble = gen.generate(n_realizations=20, n_years=30, seed=42)\n\n# Compute SSI for each realization\nsyn_ssi_list = []\nfor i, Q_syn in ensemble.data_by_realization.items():\n    ssi_syn = ssi_calc.calculate_ssi(Q_syn.iloc[:, 0])\n    syn_ssi_list.append(ssi_syn)\n</code></pre> <p>Algorithm details: Thomas-Fiering AR(1) \u00b7 Kirsch Bootstrap</p>"}]}